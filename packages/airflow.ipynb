{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airflow\n",
    "\n",
    "Airflow is a tool that allows to schedule a set of processes commonly used in ETL pipelines and sometimes in ML automation. This section considers typical ways to use Airflow.\n",
    "\n",
    "We typically are typically run airflow in the Docker container to make sure that we are working in a clean environment. Use following command to run the container.\n",
    "\n",
    "Build the docker image described in the `airflow_files/dockerfile` and run it with the `standalone` command.\n",
    "\n",
    "```bash\n",
    "docker build -f packages/airflow_files/dockerfile .\n",
    "docker run -d --rm --name airflow -p 8080:8080 -v ./:/knowledge airflow standalone\n",
    "```\n",
    "\n",
    "Image that is used as an example configured in such way to create default user with login `user` and password `user` that will be used as credentials for the airflow server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration file\n",
    "\n",
    "The global configuration of the airflow is stored in the special file: `airflow.cfg`. Different installations put this file in different places (as usual). Typical locations are `/opt/airflow/airflow.cfg` and `~/airflow/airflow.cfg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Any way use following command to find the location of the `airflow.cfg` on your disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/airflow/airflow.cfg\n"
     ]
    }
   ],
   "source": [
    "!find / -name airflow.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a dag\n",
    "\n",
    "This section shows the minimal actions needed to create an airflow dag. It is based on the [Fundamental conceptse official tutorial](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/fundamentals.html), but shows only the minimal command to add a dag and verify that it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "First you need to identify the folder containing dags. This folder is specified by the `dogs_folder` parameter of the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dags_folder = /opt/airflow/dags\n"
     ]
    }
   ],
   "source": [
    "!cat /opt/airflow/airflow.cfg | grep dags_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell adds typical dag as it is supposed to be by the airflow develepers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /opt/airflow/dags/tutorial.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /opt/airflow/dags/tutorial.py\n",
    "import textwrap\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# The DAG object; we'll need this to instantiate a DAG\n",
    "from airflow.models.dag import DAG\n",
    "\n",
    "# Operators; we need this to operate!\n",
    "from airflow.operators.bash import BashOperator\n",
    "with DAG(\n",
    "    \"tutorial\",\n",
    "    default_args={\n",
    "        \"depends_on_past\": False,\n",
    "        \"email\": [\"airflow@example.com\"],\n",
    "        \"email_on_failure\": False,\n",
    "        \"email_on_retry\": False,\n",
    "        \"retries\": 1,\n",
    "        \"retry_delay\": timedelta(minutes=5),\n",
    "    },\n",
    "    description=\"A simple tutorial DAG\",\n",
    "    schedule=timedelta(days=1),\n",
    "    start_date=datetime(2021, 1, 1),\n",
    "    catchup=False,\n",
    "    tags=[\"example\"],\n",
    ") as dag:\n",
    "\n",
    "    # t1, t2 and t3 are examples of tasks created by instantiating operators\n",
    "    t1 = BashOperator(\n",
    "        task_id=\"print_date\",\n",
    "        bash_command=\"date\",\n",
    "    )\n",
    "\n",
    "    t2 = BashOperator(\n",
    "        task_id=\"sleep\",\n",
    "        depends_on_past=False,\n",
    "        bash_command=\"sleep 5\",\n",
    "        retries=3,\n",
    "    )\n",
    "    t1.doc_md = textwrap.dedent(\n",
    "        \"\"\"\\\n",
    "    #### Task Documentation\n",
    "    You can document your task using the attributes `doc_md` (markdown),\n",
    "    `doc` (plain text), `doc_rst`, `doc_json`, `doc_yaml` which gets\n",
    "    rendered in the UI's Task Instance Details page.\n",
    "    ![img](https://imgs.xkcd.com/comics/fixing_problems.png)\n",
    "    **Image Credit:** Randall Munroe, [XKCD](https://xkcd.com/license.html)\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    dag.doc_md = __doc__  # providing that you have a docstring at the beginning of the DAG; OR\n",
    "    dag.doc_md = \"\"\"\n",
    "    This is a documentation placed anywhere\n",
    "    \"\"\"  # otherwise, type it like this\n",
    "    templated_command = textwrap.dedent(\n",
    "        \"\"\"\n",
    "    {% for i in range(5) %}\n",
    "        echo \"{{ ds }}\"\n",
    "        echo \"{{ macros.ds_add(ds, 7)}}\"\n",
    "    {% endfor %}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    t3 = BashOperator(\n",
    "        task_id=\"templated\",\n",
    "        depends_on_past=False,\n",
    "        bash_command=templated_command,\n",
    "    )\n",
    "\n",
    "    t1 >> [t2, t3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command causes airflow to add DAG to its databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB: sqlite:////opt/airflow/airflow.db\n",
      "Performing upgrade to the metadata database sqlite:////opt/airflow/airflow.db\n",
      "[\u001b[34m2025-03-22T13:23:48.784+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2025-03-22T13:23:48.785+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2025-03-22T13:23:48.787+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2025-03-22T13:23:48.787+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2025-03-22T13:23:48.788+0000\u001b[0m] {\u001b[34mdb.py:\u001b[0m1675} INFO\u001b[0m - Creating tables\u001b[0m\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Database migrating done!\n"
     ]
    }
   ],
   "source": [
    "!airflow db migrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `airflow dags list` you can show DAGs that are seen by the airflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdag_id  \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mfileloc                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mowners \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mis_paused\u001b[0m\n",
      "=========+===============================+=========+==========\n",
      "tutorial | /opt/airflow/dags/tutorial.py | airflow | True     \n",
      "\u001b[2;3m                                                              \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!airflow dags list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result there is a dag we have added below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
