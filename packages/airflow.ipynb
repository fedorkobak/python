{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airflow\n",
    "\n",
    "Airflow is a tool that allows to schedule a set of processes commonly used in ETL pipelines and sometimes in ML automation. This section considers typical ways to use Airflow.\n",
    "\n",
    "We typically are typically run airflow in the Docker container to make sure that we are working in a clean environment. Use following command to run the container.\n",
    "\n",
    "Build the docker image described in the `airflow_files/dockerfile` and run it with the `standalone` command.\n",
    "\n",
    "```bash\n",
    "docker build -f packages/airflow_files/dockerfile .\n",
    "docker run -d --rm --name airflow -p 8080:8080 -v ./:/knowledge airflow standalone\n",
    "```\n",
    "\n",
    "Image that is used as an example configured in such way to create default user with login `user` and password `user` that will be used as credentials for the airflow server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration file\n",
    "\n",
    "The global configuration of the airflow is stored in the special file: `airflow.cfg`. Different installations put this file in different places (as usual). Typical locations are `/opt/airflow/airflow.cfg` and `~/airflow/airflow.cfg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Any way use following command to find the location of the `airflow.cfg` on your disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/airflow/airflow.cfg\n"
     ]
    }
   ],
   "source": [
    "!find / -name airflow.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a dag\n",
    "\n",
    "This section shows the minimal actions needed to create an airflow dag. It is based on the [Fundamental conceptse official tutorial](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/fundamentals.html), but shows only the minimal command to add a dag and verify that it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "First you need to identify the folder containing dags. This folder is specified by the `dogs_folder` parameter of the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dags_folder = /opt/airflow/dags\n"
     ]
    }
   ],
   "source": [
    "!cat /opt/airflow/airflow.cfg | grep dags_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAG must be implemented by the special DAG file. This is the file that contains `airflow.models.DAG` object. It takes a lot of settings that determine it's behavior but in general it needs only `dag_id` to be specified. The following cell defines a dag with id `tutorial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /opt/airflow/dags/tutorial.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /opt/airflow/dags/tutorial.py\n",
    "from airflow.models.dag import DAG\n",
    "\n",
    "with DAG(\"tutorial\") as dag:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command causes airflow to add DAG to its databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB: sqlite:////opt/airflow/airflow.db\n",
      "Performing upgrade to the metadata database sqlite:////opt/airflow/airflow.db\n",
      "[\u001b[34m2025-03-22T14:14:21.698+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2025-03-22T14:14:21.700+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2025-03-22T14:14:21.704+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2025-03-22T14:14:21.704+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2025-03-22T14:14:21.705+0000\u001b[0m] {\u001b[34mdb.py:\u001b[0m1675} INFO\u001b[0m - Creating tables\u001b[0m\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Database migrating done!\n"
     ]
    }
   ],
   "source": [
    "!airflow db migrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `airflow dags list` you can show DAGs that are seen by the airflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdag_id  \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mfileloc                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mowners\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mis_paused\u001b[0m\n",
      "=========+===============================+========+==========\n",
      "tutorial | /opt/airflow/dags/tutorial.py |        | True     \n",
      "\u001b[2;3m                                                             \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!airflow dags list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result there is a dag we have added below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
