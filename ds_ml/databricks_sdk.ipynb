{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86382367",
   "metadata": {},
   "source": [
    "# Databricks SDK\n",
    "\n",
    "This page considers details on working with databricks SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d134a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a86fd0",
   "metadata": {},
   "source": [
    "## Workspace client\n",
    "\n",
    "The most popular way to communicate with databricks workspace is through a `databricks.sdk.WorkspaceClient`. To create it, you must set up Databricks authentification:\n",
    "\n",
    "- Through setting `~/.databrickscfg` file. It may look like this:\n",
    "- Through defining environment variables. The most popular are:\n",
    "    - `DATABRICKS_HOST`: set your databricks host.\n",
    "    - `DATABRICKS_TOKEN`: set your access token.\n",
    "\n",
    "The default `.databrickscfg` file may look like this: \n",
    "\n",
    "```\n",
    "[DEFAULT]\n",
    "host = https:////dbc-<some unique for workspace>.cloud.databricks.com\n",
    "token = <here is your token>\n",
    "```\n",
    "\n",
    "- The profile name `DEFAULT` is important. You can specify a different name, but this will be used by default.\n",
    "- The `host` you can copy from the browser url line (just host, without path).\n",
    "- The `token` you can get through databricks UI: settings->developer->Access tokens->Manage.\n",
    "\n",
    "**Note.** If you have problems with authentication, check the environment variables. Some tools, such as the VSCode Databricks extension, may define some default values starting with `DATABRICKS_...`. Also, check the `~/.ipython/profile_default/startup` if there are some startup scripts that can invisibly change the behavior of the IPython."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959306b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If everything cofigured correctly, the following cell shold be runned without any issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = WorkspaceClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a504b",
   "metadata": {},
   "source": [
    "## Spark session\n",
    "\n",
    "You can get a databricks session that will have access to your databricks workspace by using `databricks.connect.DatabricksSession.builder.remote().getOrCreate` method.\n",
    "\n",
    "- You cannnot create crate a `DatabricksSession` if you have a regular `pyspark` installed on your system. You must run this code from a different Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816627d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates a Spark session that attched to the Databricks environment runned in the \"serverless\" mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5861762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "spark = DatabricksSession.builder.remote(serverless=True).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea131633",
   "metadata": {},
   "source": [
    "The following cell displays the list of the tables that are available in my Databricks workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24a75b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|  telco_churn_bronze|      false|\n",
      "| default|telco_churn_features|      false|\n",
      "+--------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef4687",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "The `databricks.feature_engineering` module allows to manipulate feature storage in databricks.\n",
    "\n",
    "The `databricks.feature_engineering.FeatureEngineeringClient` object provides methods:\n",
    "\n",
    "| Method                                                                       | Description                                                                                                                           |\n",
    "| ---------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `create_feature_table(...)`                                                  | Creates a feature table in Unity Catalog, defining its primary keys, schema, timestamp column, and metadata.                          |\n",
    "| `create_training_set(...)`                                                   | Joins features (via `FeatureLookup` or `FeatureSpec`) to a DataFrame to form a training set with metadata.                            |\n",
    "| `log_model(...)`                                                             | Logs an MLflow model together with feature metadata so the required features can be fetched automatically at inference.               |\n",
    "| `score_batch(...)`                                                           | Runs batch inference: given a model URI and a DataFrame, automatically fetches missing features, joins them, and returns predictions. |\n",
    "| `create_feature_spec(...)`                                                   | Defines a feature spec (collection of `FeatureLookup`/`FeatureFunction`) for use in training sets or feature serving.                 |\n",
    "| `create_feature_serving_endpoint(...)`                                       | Creates an endpoint for real-time / online feature serving.                                                                           |\n",
    "| `get_feature_serving_endpoint(...)` / `delete_feature_serving_endpoint(...)` | Manage (retrieve or delete) feature serving endpoints.                                                                                |\n",
    "| `publish_table(...)`                                                         | Publishes an offline feature table to an online store for low-latency feature access.                                                 |\n",
    "| `read_table(...)`                                                            | Reads the contents of a feature table into a Spark DataFrame.                                                                         |\n",
    "| `write_table(...)`                                                           | Inserts or upserts data into a feature table; supports streaming DataFrames.                                                          |\n",
    "| `set_feature_table_tag(...)` / `delete_feature_table_tag(...)`               | Manage tags (set or delete) on feature tables for governance and organization.                                                        |\n",
    "| `drop_online_table(...)`                                                     | Removes a published feature table from an online store.                                                                               |\n",
    "\n",
    "For more details and examples check the [Feature engineering](databricks_sdk/feature_engineering.ipynb) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09592996",
   "metadata": {},
   "source": [
    "## OpenAI client\n",
    "\n",
    "The method `serving_endpoints.get_open_ai_client.get_open_ai_client` returns the  `openai.OpenAI` client, which you can use to requiest some served models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0baad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates the `open_ai_client` and shows that it is really open ai client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d07862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.OpenAI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()\n",
    "\n",
    "open_ai_client = w.serving_endpoints.get_open_ai_client()\n",
    "type(open_ai_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bc96d",
   "metadata": {},
   "source": [
    "The following cell illustrates the invocation of the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.create_embedding_response.CreateEmbeddingResponse"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "embedding = open_ai_client.embeddings.create(\n",
    "   model=\"databricks-gte-large-en\",\n",
    "   input=\"hello\"\n",
    ")\n",
    "type(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d90e4f",
   "metadata": {},
   "source": [
    "The result is an `openai` embedding response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d08c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9521484375,\n",
       " -0.7998046875,\n",
       " -0.79931640625,\n",
       " -0.138427734375,\n",
       " -0.79150390625,\n",
       " -0.31787109375,\n",
       " -0.55810546875,\n",
       " 0.392333984375,\n",
       " -0.36767578125,\n",
       " 0.4013671875,\n",
       " -0.0791015625,\n",
       " -0.78515625,\n",
       " -0.4599609375,\n",
       " 0.4189453125,\n",
       " 0.418212890625,\n",
       " -0.36767578125,\n",
       " -0.587890625,\n",
       " -0.466796875,\n",
       " 0.159423828125,\n",
       " -0.359130859375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding.data[0].embedding[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d445f48",
   "metadata": {},
   "source": [
    "## Serving endpoint\n",
    "\n",
    "With Databricks, you can launch an endpoint with a registered model. You can do this through the UI Databricks interface, but here we show the option of using the Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6598b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell registers the simple function that is logged as an ML model in MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3375088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.knowledge.serving_example' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db37474964f04d149059dfccf5f7038f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'workspace.knowledge.serving_example'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run whimsical-smelt-614 at: https://dbc-6bc9e7c2-e867.cloud.databricks.com/ml/experiments/2555847948754149/runs/f2ecb60bae784c7f8fea0e9bf1c6c456\n",
      "🧪 View experiment at: https://dbc-6bc9e7c2-e867.cloud.databricks.com/ml/experiments/2555847948754149\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "experiment_name = \"/Users/fedor.kobak@innowise.com/serving_tests\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "@mlflow.pyfunc.utils.pyfunc\n",
    "def model(model_input: list[float]) -> list[float]:\n",
    "    return [x * 2 for x in model_input]\n",
    "\n",
    "model_name = \"workspace.knowledge.serving_example\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        name=\"model\",\n",
    "        python_model=model,\n",
    "        pip_requirements=[],\n",
    "        registered_model_name=model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349e807e",
   "metadata": {},
   "source": [
    "The following cell defines the endpoint configuration and endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd3de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EndpointCoreConfigInput(auto_capture_config=None, name=None, served_entities=[], served_models=[ServedModelInput(scale_to_zero_enabled=True, model_name='workspace.knowledge.serving_example', model_version=1, environment_vars=None, instance_profile_arn=None, max_provisioned_concurrency=None, max_provisioned_throughput=None, min_provisioned_concurrency=None, min_provisioned_throughput=None, name=None, provisioned_model_units=None, workload_size='Small', workload_type=None)], traffic_config=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from databricks.sdk.service.serving import EndpointCoreConfigInput\n",
    "config = EndpointCoreConfigInput.from_dict({\n",
    "    \"served_models\": [\n",
    "        {\n",
    "            \"model_name\": model_name,\n",
    "            \"model_version\": 1,\n",
    "            \"scale_to_zero_enabled\": True,\n",
    "            \"workload_size\": \"Small\"\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "endpoint_name = \"serving-example\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8591302",
   "metadata": {},
   "source": [
    "Use  `WorkspaceClient.serving_endpoitns.create_and_wait` method to create the endpoint, as shown in the following cell.\n",
    "\n",
    "**Note.** This cell may take some time to be executed ~10 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dff5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ServingEndpointDetailed(ai_gateway=None, budget_policy_id=None, config=EndpointCoreConfigOutput(auto_capture_config=None, config_version=1, served_entities=[ServedEntityOutput(creation_timestamp=1759322561000, creator='fedor.kobak@innowise.com', entity_name='workspace.knowledge.serving_example', entity_version='1', environment_vars=None, external_model=None, foundation_model=None, instance_profile_arn=None, max_provisioned_concurrency=None, max_provisioned_throughput=None, min_provisioned_concurrency=None, min_provisioned_throughput=None, name='serving_example-1', provisioned_model_units=None, scale_to_zero_enabled=True, state=ServedModelState(deployment=<ServedModelStateDeployment.DEPLOYMENT_READY: 'DEPLOYMENT_READY'>, deployment_state_message=''), workload_size='Small', workload_type=<ServingModelWorkloadType.CPU: 'CPU'>)], served_models=[ServedModelOutput(creation_timestamp=1759322561000, creator='fedor.kobak@innowise.com', environment_vars=None, instance_profile_arn=None, max_provisioned_concurrency=None, min_provisioned_concurrency=None, model_name='workspace.knowledge.serving_example', model_version='1', name='serving_example-1', provisioned_model_units=None, scale_to_zero_enabled=True, state=ServedModelState(deployment=<ServedModelStateDeployment.DEPLOYMENT_READY: 'DEPLOYMENT_READY'>, deployment_state_message=''), workload_size='Small', workload_type=<ServingModelWorkloadType.CPU: 'CPU'>)], traffic_config=TrafficConfig(routes=[Route(traffic_percentage=100, served_entity_name='serving_example-1', served_model_name='serving_example-1')])), creation_timestamp=1759322561000, creator='fedor.kobak@innowise.com', data_plane_info=None, description='', email_notifications=None, endpoint_url=None, id='a4b755e5064c430dba1ef294b40e5010', last_updated_timestamp=1759322561000, name='serving-example', pending_config=None, permission_level=<ServingEndpointDetailedPermissionLevel.CAN_MANAGE: 'CAN_MANAGE'>, route_optimized=False, state=EndpointState(config_update=<EndpointStateConfigUpdate.NOT_UPDATING: 'NOT_UPDATING'>, ready=<EndpointStateReady.READY: 'READY'>), tags=[], task=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = WorkspaceClient()\n",
    "w.serving_endpoints.create_and_wait(\n",
    "    name=endpoint_name,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68630291",
   "metadata": {},
   "source": [
    "After that your endpoint is awailable in the internet. The following cell throws `curl` to it.\n",
    "\n",
    "To use it you must create the environment variables `DATABRICKS_HOST` and `DATABRICKS_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c094c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [10.0, 20.0]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s\\\n",
    "  -u token:$DATABRICKS_TOKEN \\\n",
    "  -X POST \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"inputs\": [5.0, 10.0]}'\\\n",
    "  $DATABRICKS_HOST/serving-endpoints/serving-example/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb6aa3",
   "metadata": {},
   "source": [
    "The outputs, just as was specified in \"model\", are twice inputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
