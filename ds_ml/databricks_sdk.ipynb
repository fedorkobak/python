{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86382367",
   "metadata": {},
   "source": [
    "# Databricks SDK\n",
    "\n",
    "This page considers details on working with databricks SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a86fd0",
   "metadata": {},
   "source": [
    "## Workspace client\n",
    "\n",
    "The most popular way to communicate with databricks workspace is through a `databricks.sdk.WorkspaceClient`. To create it, you must set up Databricks authentification:\n",
    "\n",
    "- Through setting `~/.databrickscfg` file. It may look like this:\n",
    "- Through defining environment variables. The most popular are:\n",
    "    - `DATABRICKS_HOST`: set your databricks host.\n",
    "    - `DATABRICKS_TOKEN`: set your access token.\n",
    "\n",
    "The default `.databrickscfg` file may look like this: \n",
    "\n",
    "```\n",
    "[DEFAULT]\n",
    "host = https:////dbc-<some unique for workspace>.cloud.databricks.com\n",
    "token = <here is your token>\n",
    "```\n",
    "\n",
    "- The profile name `DEFAULT` is important. You can specify a different name, but this will be used by default.\n",
    "- The `host` you can copy from the browser url line (just host, without path).\n",
    "- The `token` you can get through databricks UI: settings->developer->Access tokens->Manage.\n",
    "\n",
    "**Note.** If you have problems with authentication, check the environment variables. Some tools, such as the VSCode Databricks extension, may define some default values starting with `DATABRICKS_...`. Also, check the `~/.ipython/profile_default/startup` if there are some startup scripts that can invisibly change the behavior of the IPython."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959306b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If everything cofigured correctly, the following cell shold be runned without any issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f108317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a504b",
   "metadata": {},
   "source": [
    "## Spark session\n",
    "\n",
    "You can get a databricks session that will have access to your databricks workspace by using `databricks.connect.DatabricksSession.builder.remote().getOrCreate` method.\n",
    "\n",
    "- You cannnot create crate a `DatabricksSession` if you have a regular `pyspark` installed on your system. You must run this code from a different Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816627d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates a Spark session that attched to the Databricks environment runned in the \"serverless\" mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5861762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "spark = DatabricksSession.builder.remote(serverless=True).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea131633",
   "metadata": {},
   "source": [
    "The following cell displays the list of the tables that are available in my Databricks workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24a75b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|  telco_churn_bronze|      false|\n",
      "| default|telco_churn_features|      false|\n",
      "+--------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef4687",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "The `databricks.feature_engineering` module allows to manipulate feature storage in databricks.\n",
    "\n",
    "The `databricks.feature_engineering.FeatureEngineeringClient` object provides methods:\n",
    "\n",
    "| Method                                                                       | Description                                                                                                                           |\n",
    "| ---------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `create_feature_table(...)`                                                  | Creates a feature table in Unity Catalog, defining its primary keys, schema, timestamp column, and metadata.                          |\n",
    "| `create_training_set(...)`                                                   | Joins features (via `FeatureLookup` or `FeatureSpec`) to a DataFrame to form a training set with metadata.                            |\n",
    "| `log_model(...)`                                                             | Logs an MLflow model together with feature metadata so the required features can be fetched automatically at inference.               |\n",
    "| `score_batch(...)`                                                           | Runs batch inference: given a model URI and a DataFrame, automatically fetches missing features, joins them, and returns predictions. |\n",
    "| `create_feature_spec(...)`                                                   | Defines a feature spec (collection of `FeatureLookup`/`FeatureFunction`) for use in training sets or feature serving.                 |\n",
    "| `create_feature_serving_endpoint(...)`                                       | Creates an endpoint for real-time / online feature serving.                                                                           |\n",
    "| `get_feature_serving_endpoint(...)` / `delete_feature_serving_endpoint(...)` | Manage (retrieve or delete) feature serving endpoints.                                                                                |\n",
    "| `publish_table(...)`                                                         | Publishes an offline feature table to an online store for low-latency feature access.                                                 |\n",
    "| `read_table(...)`                                                            | Reads the contents of a feature table into a Spark DataFrame.                                                                         |\n",
    "| `write_table(...)`                                                           | Inserts or upserts data into a feature table; supports streaming DataFrames.                                                          |\n",
    "| `set_feature_table_tag(...)` / `delete_feature_table_tag(...)`               | Manage tags (set or delete) on feature tables for governance and organization.                                                        |\n",
    "| `drop_online_table(...)`                                                     | Removes a published feature table from an online store.                                                                               |\n",
    "\n",
    "For more details and examples check the [Feature engineering](databricks_sdk/feature_engineering.ipynb) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09592996",
   "metadata": {},
   "source": [
    "## OpenAI client\n",
    "\n",
    "The method `serving_endpoints.get_open_ai_client.get_open_ai_client` returns the  `openai.OpenAI` client, which you can use to requiest some served models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0baad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates the `open_ai_client` and shows that it is really open ai client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d07862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.OpenAI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()\n",
    "\n",
    "open_ai_client = w.serving_endpoints.get_open_ai_client()\n",
    "type(open_ai_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bc96d",
   "metadata": {},
   "source": [
    "The following cell illustrates the invocation of the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.create_embedding_response.CreateEmbeddingResponse"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "embedding = open_ai_client.embeddings.create(\n",
    "   model=\"databricks-gte-large-en\",\n",
    "   input=\"hello\"\n",
    ")\n",
    "type(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d90e4f",
   "metadata": {},
   "source": [
    "The result is an `openai` embedding response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d08c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9521484375,\n",
       " -0.7998046875,\n",
       " -0.79931640625,\n",
       " -0.138427734375,\n",
       " -0.79150390625,\n",
       " -0.31787109375,\n",
       " -0.55810546875,\n",
       " 0.392333984375,\n",
       " -0.36767578125,\n",
       " 0.4013671875,\n",
       " -0.0791015625,\n",
       " -0.78515625,\n",
       " -0.4599609375,\n",
       " 0.4189453125,\n",
       " 0.418212890625,\n",
       " -0.36767578125,\n",
       " -0.587890625,\n",
       " -0.466796875,\n",
       " 0.159423828125,\n",
       " -0.359130859375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding.data[0].embedding[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
