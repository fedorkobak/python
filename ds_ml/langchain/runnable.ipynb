{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09e0c2f-835f-4214-b152-fb8fd750721e",
   "metadata": {},
   "source": [
    "# Runnable\n",
    "\n",
    "A Runnable is a LangChain concept representing an object with `invoke`, `stream` and `batch` methods. Runnables can sometimes can be combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bfce2c-a0c9-49f3-8634-ba7ad66ed97d",
   "metadata": {},
   "source": [
    "## Invoke\n",
    "\n",
    "The `invoke` method triggers the request to LLM.\n",
    "\n",
    "In most cases, it returns an `AIMessage`, but in some special cases, it can return some special output. For example, structured output langchain object return `dict` or `Pydantic.BaseModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645b2eb-5f1b-4e86-a088-27b78eefe999",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell shows the kind of object `langchain_core.language_models.BaseChatModel` heir returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327d4ccd-5cbe-4531-9658-04f8f04140ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2026-01-06T14:39:17.313641499Z', 'done': True, 'done_reason': 'stop', 'total_duration': 23004167206, 'load_duration': 22818871591, 'prompt_eval_count': 12, 'prompt_eval_duration': 27074996, 'eval_count': 10, 'eval_duration': 141396789, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--fe6d8bde-d9c8-4e4c-a7f2-df3839f539a6-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4361c-338e-47a8-a7ea-6ffb04fd0066",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "You can modify the behaviour of your Runnable using a callback. Extend the `langchain_core.callbacks.BaseCallbackHandler` with special methods and specify that Runnable have to use the callback handler during the infvocation in the \"callbacks\" attribute of the `config`.\n",
    "\n",
    "The following table shows some of the methods that can be defined in the callback handler.\n",
    "\n",
    "|      Method      |           Triggered When...          |                  Useful For...                 |\n",
    "| :--------------: | :----------------------------------: | :--------------------------------------------: |\n",
    "|  on_chain_start  |      A Chain (or Agent) begins.      |              Logging user inputs.              |\n",
    "|   on_llm_start   |  The LLM API is about to be called.  | Inspecting the exact prompt sent to the model. |\n",
    "|   on_llm_end     |  The LLM API returned the result.    | Logging the information about model outputs.   |\n",
    "| on_llm_new_token | A token streams in (streaming only). |      Real-time UI updates (typing effect).     |\n",
    "|   on_tool_start  |    An Agent decides to use a tool.   |     Debugging which tools are being picked.    |\n",
    "|  on_chain_error  |         An exception happens.        | Capturing stack traces or alerting developers. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5850547-e718-4842-8b11-2cb9ef3a4f4e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell defines the `MyCustomTracer`, which extends the behaviour of the runnable associated with invoking LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df7408fa-92a7-4541-bb54-0bf8701d2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.outputs import LLMResult\n",
    "\n",
    "\n",
    "class MyCustomTracer(BaseCallbackHandler):\n",
    "    def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"\\n[MY-TRACER] LLM Started with prompt: {prompts[0][:50]}...\")\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> Any:\n",
    "        content = response.generations[0][0].text\n",
    "        print(f\"[MY-TRACER] LLM Finished. Output: {content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc36af5-bc3c-4655-998c-1016d6b28b12",
   "metadata": {},
   "source": [
    "The following cell illustrates the invocation of the model with attached callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb66a91-88fe-4d81-9bf4-80019834aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MY-TRACER] LLM Started with prompt: Human: Hello, I'm Fedor...\n",
      "[MY-TRACER] LLM Finished. Output: Nice to meet you, Fedor! Is there something I can ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model=\"llama3.1\")\n",
    "ans = model.invoke(\n",
    "    \"Hello, I'm Fedor\",\n",
    "    config={\"callbacks\": [MyCustomTracer()]}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
