{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4fad77b",
   "metadata": {},
   "source": [
    "# Texts transforming\n",
    "\n",
    "Langchain contains a set of tools for texts transforming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2eb54",
   "metadata": {},
   "source": [
    "## Text splitters\n",
    "\n",
    "Langchain contains module `text_splitter` which contains implementations of approaches to split texts into pieces. Can be usefull, for example for chunking in RAG pipeline.\n",
    "\n",
    "The following table shows the awailable text splitters.\n",
    "\n",
    "| Class Name | Description | Common Use Case |\n",
    "| :--- | :--- | :--- |\n",
    "| `CharacterTextSplitter` | Splits text based on a specified character (e.g., `\\n`, ` `). | Simple, quick splitting where structural integrity is not a major concern. |\n",
    "| `RecursiveCharacterTextSplitter` | The recommended default. Splits text based on a list of characters in a hierarchical order (e.g., `[\"\\n\\n\", \"\\n\", \" \"]`) to maintain logical chunks. | General-purpose text, such as articles, essays, and unstructured documents. |\n",
    "| `TokenTextSplitter` | Splits text based on the number of tokens, using a specific tokenizer (e.g., `tiktoken` for OpenAI models). | Preparing text to fit within a specific LLM's context window. |\n",
    "| `HTMLHeaderTextSplitter` | Splits HTML documents based on specified header tags (`h1`, `h2`, etc.). | Processing HTML content where you want to preserve sections defined by headers. |\n",
    "| `MarkdownTextSplitter` | Splits Markdown documents based on Markdown syntax, such as headers and code blocks. | Processing Markdown files while keeping logical sections together. |\n",
    "| `SentenceTransformersTokenTextSplitter` | Splits text using a tokenizer from the `sentence-transformers` library, based on a token count. | Working with models from the `sentence-transformers` library. |\n",
    "| `NLTKTextSplitter` | Splits text into sentences using the `NLTK` library's sentence tokenizer. | Splitting a document into individual sentences for fine-grained processing. |\n",
    "| `SpacyTextSplitter` | Splits text into sentences using the `spaCy` library. | Similar to NLTK, but leverages `spaCy` for sentence boundary detection, which can be more robust for some languages. |\n",
    "| `SemanticChunker` | A more advanced splitter that uses an embedding model to identify semantic breakpoints (topic shifts) in the text. | Creating semantically coherent chunks for more effective retrieval-augmented generation. |\n",
    "| `Language-specific Code Splitters` | A family of splitters for various programming languages (e.g., `PythonCodeTextSplitter`, `JavaScriptCodeTextSplitter`). | Processing code files to keep functions, classes, and other logical blocks intact. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48197aca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "After initializing the splitter, use the `sprit_text` method to split the given text. The following cell demonstrates the application of the recursive text splitter to a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last people\n",
      "you’d expect to be involved in anything strange or mysterious, because they just\n",
      "didn’t hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did have a\n",
      "very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the\n",
      "usual amount of neck, which came in very useful as she spent so much of her\n",
      "time craning over garden fences, spying on the neighbors. The Dursleys had a\n",
      "small son called Dudley and in their opinion there was no finer boy anywhere.\n",
      "\n",
      "The Dursleys had everything they wanted, but they also had a secret, and\n",
      "their greatest fear was that somebody would discover it. They didn’t think they\n",
      "could bear it if anyone found out about the Potters. Mrs. Potter was Mrs.\n",
      "Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley\n",
      "pretended she didn’t have a sister, because her sister and her good-for-nothing\n",
      "husband were as unDursleyish as it was possible to be. The Dursleys shuddered\n",
      "\n",
      "to think what the neighbors would say if the Potters arrived in the street. The\n",
      "Dursleys knew that the Potters had a small son, too, but they had never even\n",
      "seen him. This boy was another good reason for keeping the Potters away; they\n",
      "didn’t want Dudley mixing with a child like that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "data = \"\"\"M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
    "that they were perfectly normal, thank you very much. They were the last people\n",
    "you’d expect to be involved in anything strange or mysterious, because they just\n",
    "didn’t hold with such nonsense.\n",
    "\n",
    "Mr. Dursley was the director of a firm called Grunnings, which made\n",
    "drills. He was a big, beefy man with hardly any neck, although he did have a\n",
    "very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the\n",
    "usual amount of neck, which came in very useful as she spent so much of her\n",
    "time craning over garden fences, spying on the neighbors. The Dursleys had a\n",
    "small son called Dudley and in their opinion there was no finer boy anywhere.\n",
    "\n",
    "The Dursleys had everything they wanted, but they also had a secret, and\n",
    "their greatest fear was that somebody would discover it. They didn’t think they\n",
    "could bear it if anyone found out about the Potters. Mrs. Potter was Mrs.\n",
    "Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley\n",
    "pretended she didn’t have a sister, because her sister and her good-for-nothing\n",
    "husband were as unDursleyish as it was possible to be. The Dursleys shuddered\n",
    "to think what the neighbors would say if the Potters arrived in the street. The\n",
    "Dursleys knew that the Potters had a small son, too, but they had never even\n",
    "seen him. This boy was another good reason for keeping the Potters away; they\n",
    "didn’t want Dudley mixing with a child like that.\"\"\"\n",
    "\n",
    "out = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=20\n",
    ").split_text(data)\n",
    "\n",
    "for t in out:\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e971a",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "LangChain porvides interfaces for interacting with embedding models. The core class here is `langchain_core.embeddings.Embeddings`, the api reference [here](https://api.python.langchain.com/en/latest/embeddings/langchain_core.embeddings.Embeddings.html).\n",
    "\n",
    "The following table shows the classes that implement the different embeddings model interfaces.\n",
    "\n",
    "| Class Name | Package |\n",
    "| :--- | :--- |\n",
    "| **`Embeddings`** | `langchain_core.embeddings` |\n",
    "| **`OpenAIEmbeddings`** | `langchain_openai` |\n",
    "| **`AzureOpenAIEmbeddings`** | `langchain_openai` |\n",
    "| **`HuggingFaceEmbeddings`** | `langchain_community.embeddings.huggingface` |\n",
    "| **`GoogleGenerativeAIEmbeddings`** | `langchain_google_genai` |\n",
    "| **`GoogleVertexAIEmbeddings`** | `langchain_google_vertexai` |\n",
    "| **`CohereEmbeddings`** | `langchain_cohere` |\n",
    "| **`OllamaEmbeddings`** | `langchain_ollama` |\n",
    "| **`VoyageEmbeddings`** | `langchain_voyageai` |\n",
    "| **`JinaEmbeddings`** | `langchain_community.embeddings.jina` |\n",
    "| **`FakeEmbeddings`** | `langchain_core.embeddings.fake` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd3645",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the following example that uses `OllamaEmbeddings`. It uses ollama as inference of the model, so ollama is supposed to be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c614ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "embedder = OllamaEmtbeddings(model=\"all-minilm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb92057",
   "metadata": {},
   "source": [
    "Use the `embed_documents` method to obtain the embeddings for a givel list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc0890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = embedder.embed_documents(\n",
    "    [\"Test embeddings\", \"some more complex text\"]\n",
    ")\n",
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0154cf1",
   "metadata": {},
   "source": [
    "An embedding is provided for each of the given documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc82ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611897ad",
   "metadata": {},
   "source": [
    "And a dimentionality of embeddings depemends on the model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09e960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
