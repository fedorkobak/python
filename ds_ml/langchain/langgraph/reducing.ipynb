{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e4fcfa-277f-40c3-966e-9f8cd912c8bf",
   "metadata": {},
   "source": [
    "# Reducing\n",
    "\n",
    "Reducing is a principles that will be used to merge two different states, when both are supposed to be used in the following nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e8c406-d667-4d10-8ffb-f4b5d4f7c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import START, END, StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda6c6b-a6be-4377-8924-03dcfb3487c4",
   "metadata": {},
   "source": [
    "### Sequential\n",
    "\n",
    "Note that if you've defined the reducer for the state attribute of the graph, the sequential state updates will also be merged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80bb32-012f-4af6-ae63-5c3d4e046de3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the following example: the `attr1` does not have a reducer function, but to the `attr2` does. Sequentially connected nodes simply return state updates with a list with a single random value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23a546c-d62a-4bfb-820d-7f12b1623d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    attr1: list[int]\n",
    "    attr2: Annotated[list[int], operator.add]\n",
    "\n",
    "\n",
    "def gen_value():\n",
    "    return random.randint(5, 10)\n",
    "\n",
    "\n",
    "def node1(state: State) -> dict:\n",
    "    return {\"attr1\": [gen_value()], \"attr2\": [gen_value()]}\n",
    "\n",
    "\n",
    "def node2(state: State) -> State:\n",
    "    return State(attr1=[gen_value()], attr2=[gen_value()])\n",
    "\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(\"node1\", node1)\n",
    "    .add_node(\"node2\", node2)\n",
    "\n",
    "    .add_edge(START, \"node1\")\n",
    "    .add_edge(\"node1\", \"node2\")\n",
    "    .add_edge(\"node2\", END)\n",
    "    .compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b98ac-c765-430d-9995-fc925f3d67ef",
   "metadata": {},
   "source": [
    "The following cell applies the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2727772-dea9-46d8-afb2-1431888b4115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attr1': [9], 'attr2': [2, 5, 10]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(State(attr1=[1], attr2=[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67692e87-2510-472a-8b41-f2a06ec37054",
   "metadata": {},
   "source": [
    "Despite the fact that there is no branching in the graph, the generated values are **appended** to attributes that have reducers, rather than replacing them. For attributes without reducers, `InvalidUpdateError` is not raised because there is no **ambiguous** update - the new value just replaces the previous value in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8d004-d9bb-4130-b459-cb460a493dfa",
   "metadata": {},
   "source": [
    "### Messages\n",
    "\n",
    "In agent flow development, it is common practice to merge the messages from the different nodes. To add new messages to the list of messages, use `langcahin.graph.message.add_messages` as a reduce function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c273d3-93ec-4a6d-831b-33fe56fae62d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell generates the graph using the `langgraph.graph.message.add_message` as a reducer function. The only node that the graph uses simply adds an extra message to the messages list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396b673-8d4c-4631-9486-287ad1448094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "def a(state: State) -> State:\n",
    "    return State(messages=[HumanMessage(\"Message from the a\")])\n",
    "\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(\"a\", a)\n",
    "    .add_edge(\"__start__\", \"a\")\n",
    "    .add_edge(\"a\", \"__end__\")\n",
    "    .compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84742ab-d315-4046-bed8-e30e85f16978",
   "metadata": {},
   "source": [
    "The following cell shows how an additional message from node \"a\" is added to the input message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d091d24-8bb9-4ace-9de6-56ad7f8f43ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Input message', additional_kwargs={}, response_metadata={}, id='373072fe-498a-45c2-8979-d7765e1c3392'),\n",
       " HumanMessage(content='Message from the a', additional_kwargs={}, response_metadata={}, id='41f3346a-af40-493a-b854-01df32747e7d')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(State(messages=[HumanMessage(\"Input message\")]))[\"messages\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython HTTP",
   "language": "python3",
   "name": "http_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
