{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d548bd96",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "The DS/ML section discusses the python packages/frameworks specialised for building database systems and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e7dad",
   "metadata": {},
   "source": [
    "## Hugging Face\n",
    "\n",
    "Huggingface is an ecosystem of packages that are related to all aspects of working with deep learning objects.\n",
    "\n",
    "The first thing you need to do is log in:\n",
    "\n",
    "`huggingface-cli login --token <your HF token>`\n",
    "\n",
    "The following table shows the structure of the ecosystem:\n",
    "\n",
    "| Package                           | Purpose                                                                                                                              |\n",
    "| --------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **🤗 Hub (`huggingface_hub`)**    | Central repository for models, datasets, and Spaces. Lets you push/pull models and datasets.                                         |\n",
    "| **Transformers (`transformers`)** | High-level library with pretrained NLP, vision, and multimodal models. Handles training, inference, and tokenization (via wrappers). |\n",
    "| **Tokenizers (`tokenizers`)**     | Fast, low-level text tokenization library (written in Rust). Often used inside `transformers`.                                       |\n",
    "| **Datasets (`datasets`)**         | Efficient dataset loading, processing, and streaming. Optimized for large ML datasets.                                               |\n",
    "| **Evaluate (`evaluate`)**         | Standardized evaluation metrics library. Works well with `datasets` and `transformers`.                                              |\n",
    "| **Diffusers (`diffusers`)**       | Library for diffusion models (e.g., Stable Diffusion) for images, audio, video.                                                      |\n",
    "| **Accelerate (`accelerate`)**     | Utility for running training on any hardware setup (CPU, GPU, multi-GPU, TPU) with minimal code changes.                             |\n",
    "| **PEFT (`peft`)**                 | Parameter-Efficient Fine-Tuning library (LoRA, adapters, etc.) for large models.                                                     |\n",
    "| **Optimum (`optimum`)**           | Optimizations for transformers (ONNX, quantization, hardware-specific acceleration).                                                 |\n",
    "| **Smollagents (`smolagents`)**    | Building agentic systems.                                                                                                            |\n",
    "| **Gradio (`gradio`)** (partnered) | Simple UI framework to demo models in the browser.                                                                                   |\n",
    "\n",
    "Find out more: \n",
    "\n",
    "- [LLM course](https://huggingface.co/learn/llm-course/chapter0/1) from hugging face.\n",
    "- The [Hugging Face](hugging_face.ipynb) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61485bb0",
   "metadata": {},
   "source": [
    "## Spark\n",
    "\n",
    "Spark is a framework for processing large amounts of data. This section covers its Python SDK.\n",
    "\n",
    "For more details, check the [Spark](spark.ipynb) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0e546",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell demonstrates how to create a Spark session, define a data frame, and display it in the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8029f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| Name|Salary|\n",
      "+-----+------+\n",
      "|Fedor|   500|\n",
      "|Alice|   700|\n",
      "|  Bob|  1400|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = SparkSession.builder.appName(\"Temp\").getOrCreate()\n",
    "spark_session.createDataFrame(\n",
    "    data=[\n",
    "        (\"Fedor\", 500),\n",
    "        (\"Alice\", 700),\n",
    "        (\"Bob\", 1400)\n",
    "    ],\n",
    "    schema=(\"Name\", \"Salary\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aec035",
   "metadata": {},
   "source": [
    "## Sentence transformer\n",
    "\n",
    "The sentence transformer package implements models for building embeddings from sets of texts. Check [SBERT](https://sbert.net/) page for mode details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0cb764",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider a basic example of using the `sentence_transformers` package.\n",
    "\n",
    "The following cell loads the model and displays the type. It's a special object that build to privide specific interfaces associated with building embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bbe2a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_transformers.SentenceTransformer.SentenceTransformer"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a7fcf",
   "metadata": {},
   "source": [
    "The obtained object have an `encode` method - that takes a range of texts and returns `numpy.array` of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85442a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01919573,  0.12008536,  0.15959828, ..., -0.0053629 ,\n",
       "        -0.08109505,  0.05021338],\n",
       "       [-0.01869039,  0.04151868,  0.07431544, ...,  0.00486597,\n",
       "        -0.06190442,  0.03187514],\n",
       "       [ 0.136502  ,  0.08227322, -0.02526165, ...,  0.08762047,\n",
       "         0.03045845, -0.01075752]], shape=(3, 384), dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99d079",
   "metadata": {},
   "source": [
    "The following cell uses the `similarity` method to create a matrix of the embeddings' similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ead365c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.6660, 0.1046],\n",
       "        [0.6660, 1.0000, 0.1411],\n",
       "        [0.1046, 0.1411, 1.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = model.similarity(embeddings, embeddings)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddf043",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "\n",
    "The Lang chain is the core library for developing modern, agent-based solutions. The following table lists and describes the central components of the lang chain package.\n",
    "\n",
    "| Component | Analogy | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| **Models** | The brains | These are the core language models (LLMs) that handle the actual work, like generating text, holding conversations, or creating embeddings. |\n",
    "| **Prompts** | The instructions | These are the templates used to provide specific instructions and context to the models. They ensure the model responds in a consistent and desired format. |\n",
    "| **Chains** | The workflow | A way to link multiple components together into a single, automated sequence. This allows you to perform multi-step tasks, like combining a prompt with a model call. |\n",
    "| **Agents** | The reasoning engine | A more advanced chain that uses an LLM to decide which external **Tools** to use to achieve a goal. It can think, act, and observe, repeating the process until the task is complete. |\n",
    "| **Tools** | The external capabilities | These are functionalities an agent can use to interact with the world. Examples include a search engine, a calculator, or a database lookup. |\n",
    "\n",
    "\n",
    "Check more in [Lang Chain](langchain.ipynb) package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc7d44",
   "metadata": {},
   "source": [
    "## MCP SDK\n",
    "\n",
    "There is an MCP SDK for python. It is provided by the `mcp[cli]` package.\n",
    "\n",
    "Define the assign a server object using the `mcp.server.fastmcp.FastMCP` class. Use decorators: `tool`, `resource`, `prompt`, and `sampling` to wrap the funcitons that implement the corresponding facilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c3667",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In the following cell we will consider how to run the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ee76b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting intro_files/mcp_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile intro_files/mcp_server.py\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Some service\")\n",
    "\n",
    "@mcp.tool()\n",
    "def some_tool(inp: str) -> str:\n",
    "    return f\"Output of some tool for {inp}.\"\n",
    "\n",
    "mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d992570",
   "metadata": {},
   "source": [
    "Run your server using the command `mcp dev intro_files/mcp_server.py`. The following cell runs the server from python using `os.system` command to demonstrate the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f94c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MCP inspector...\n",
      "⚙️ Proxy server listening on localhost:6277\n",
      "🔑 Session token: 4c21942ece36a04554ee01562067c5b129c3b03eaa945ead9d0b8964d9334fe8\n",
      "   Use this token to authenticate requests or set DANGEROUSLY_OMIT_AUTH=true to disable auth\n",
      "\n",
      "🚀 MCP Inspector is up and running at:\n",
      "   http://localhost:6274/?MCP_PROXY_AUTH_TOKEN=4c21942ece36a04554ee01562067c5b129c3b03eaa945ead9d0b8964d9334fe8\n",
      "\n",
      "🌐 Opening browser...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"mcp dev intro_files/mcp_server.py &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a069ac",
   "metadata": {},
   "source": [
    "**Note:** To use an inspector tool, you must install `npm` on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d931b",
   "metadata": {},
   "source": [
    "## MLFlow\n",
    "\n",
    "It is a tool for organizing the lifecycle of machine learning models. It includes four componenets:\n",
    "\n",
    "- Tracking: Record and query experiments: code, data, config, results.\n",
    "- Projects: Packaging format for reproducible runs on any platform.\n",
    "- Models: General model format that support diverse deployment tools.\n",
    "- Model Registry: Centralized and collaborative model lifecycle management.\n",
    "\n",
    "For more information, check out the [MLFlow](mlflow.ipynb) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00cd6c",
   "metadata": {},
   "source": [
    "## Databricks SDK\n",
    "\n",
    "Databricks is a platform for developing data applications. It provides the python SKD.\n",
    "\n",
    "As it provides intercation with cloud based platform you have to set up an authentification in the `.databricks` file. Check more on configuration the authentification in:\n",
    "\n",
    "- [Create a Databricks configuration profile file](https://docs.databricks.com/aws/en/dev-tools/auth/config-profiles).\n",
    "- [Databricks personal access token authentification](https://docs.databricks.com/aws/en/dev-tools/auth/pat).\n",
    "\n",
    "\n",
    "Few important packages:\n",
    "\n",
    "- The [databricks-connect](https://pypi.org/project/databricks-connect/) allows to connect to the facilities of the databricks cluster.\n",
    "- The [databricks-feature-engineering](https://pypi.org/project/databricks-feature-engineering/) API for manaing the databricks featurestore. After installing the module `databricks.feature_engineering` will be awailable from the environment.\n",
    "\n",
    "For more details check: \n",
    "\n",
    "- [Databricks SDK for python](https://databricks-sdk-py.readthedocs.io/en/latest/) documentation.\n",
    "- [Databricks SDK](databricks_sdk.ipynb) page in this website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153e6b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If the configuration is set up correctly, you should be able to run the following cell without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bac2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "databricks.sdk.WorkspaceClient"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "type(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28191e00",
   "metadata": {},
   "source": [
    "## Optuna\n",
    "\n",
    "[Optuna](https://optuna.org/) is a package that enables a hyber parameter optimization.\n",
    "\n",
    "For more information, check out the [Optuna](optuna.ipynb) page on this website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374940d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the function:\n",
    "\n",
    "$$f(x) = (x-2)^2$$\n",
    "\n",
    "The minimum would be the solution of the equasion:\n",
    "\n",
    "$$\\frac{df}{dx} = 0 \\\\\n",
    "2x-4 = 0 \\\\\n",
    "x = 2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b9fca",
   "metadata": {},
   "source": [
    "The following cell performs the same task, but uses Optuna to do so numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cacf783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 2.0017855120396995}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    x = trial.suggest_float('x', -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
