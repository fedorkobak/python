{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e24c21",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "LangCain is software that enables the development of applications based on LLMs. Since all models/providers/inference servers have a slightly it different input/ouput format. Langchain builds a set of unified APIs. The same or nearly the same code can be used to build systems with different models and their hosting principles.\n",
    "\n",
    "There is a set of packages that implement a typical integrations of the langchain. The following table lists the most typical of them.\n",
    "\n",
    "| Package Name | Description |\n",
    "| :--- | :--- |\n",
    "| `langchain-community` | A general package for a wide variety of community-contributed tools and integrations, including web search (DuckDuckGo, Tavily), Python REPL, and various database connectors. |\n",
    "| `langchain-core` | The foundational package with the core tool abstractions and base classes. |\n",
    "| `langchain-experimental` | A package for new and experimental tools, which may not yet be stable. |\n",
    "| `langchain-tavily` | A dedicated package for the Tavily search tool. |\n",
    "| `langchain-brave-search` | A dedicated package for the Brave Search tool. |\n",
    "| `langchain-google-genai` | Includes tools for interacting with Google's Generative AI services. |\n",
    "| `langchain-anthropic` | Includes tools for interacting with the Anthropic API. |\n",
    "| `langchain-openai` | Contains integrations for OpenAI's models and services. |\n",
    "| `langchain-mongodb` | A package for interacting with MongoDB. |\n",
    "| `langchain-postgres` | A package for interacting with PostgreSQL. |\n",
    "| `langchain-ollama` | A package implements tools to request models lanched with ollama. |\n",
    "| `langchain-huggingface` | A package implements tools to interact with models from hugging face. |\n",
    "\n",
    "Check the [LangChain Python reference](https://reference.langchain.com/python/langchain/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30554ee",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Typically, you must export the API key corresponding to the model type you want to use from your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f7a52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell shows the code that will only work if the \"GOOGLE_API_KEY\" variable exists in your environment with the corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86af27d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide me with the details of your test request.  I need information such as:\n",
      "\n",
      "* **What kind of test are you requesting?** (e.g., a unit test, an integration test, a performance test, a stress test, a usability test, a grammar test, a logic test, a factual accuracy test, etc.)\n",
      "* **What is the subject of the test?** (e.g., a piece of code, a website, a document, a sentence, an argument, etc.)\n",
      "* **What are the inputs or data for the test?** (If applicable)\n",
      "* **What are the expected outputs or results?** (If applicable)\n",
      "* **What are the acceptance criteria?** (How will you know if the test passed or failed?)\n",
      "\n",
      "The more information you give me, the better I can assist you.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "ans = llm.invoke(\"Test request\")\n",
    "print(ans.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d85853",
   "metadata": {},
   "source": [
    "Some examles use ollama-specfic tools. Therefore, you must have have Ollama launched in your system. The most usitable option for me is to launch the Ollama in Docker. The following command lauches Ollama with the most basic settings in Docker:\n",
    "\n",
    "```bash\n",
    "docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n",
    "```\n",
    "\n",
    "After launching ollama, you should also pull the models you're interested in:\n",
    "\n",
    "```bash\n",
    "docker exec ollama ollama pull <model name>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d59384",
   "metadata": {},
   "source": [
    "## Texts transforming\n",
    "\n",
    "There is a set of tools in the langchain for texts transforming. They are includes:\n",
    "\n",
    "- [Document loaders](https://python.langchain.com/docs/integrations/document_loaders/): For loading documents into the standard LangChain document format.\n",
    "- [Text splitters](https://python.langchain.com/docs/concepts/text_splitters/): Useful for splitting documents, especially for chunking.\n",
    "- [Embedding models](https://python.langchain.com/docs/integrations/text_embedding/): Builds a vector representation of the embeddings.\n",
    "\n",
    "Check [Texts transforming](langchain/texts_processing.ipynb) page for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5bb048",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For example, consider the process of loading, chunking, and building embeddings for the [GNU Opearting System](https://www.gnu.org/gnu/gnu-history.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b36bab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f6d56",
   "metadata": {},
   "source": [
    "The following cell uses the `WebBaseLoader` to load the HTML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a8c9f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onym for “GNU's Not\n",
      "Unix,” second, because it was a real word, and third, it was fun\n",
      "to say (or\n",
      "\n",
      "sing).\n",
      "\n",
      "The word “free” in “free software” pertains to\n",
      "freedom, not price.  You may or\n",
      "may not pay a price to get GNU software.  Either way, once you have\n",
      "the software you have four specific freedoms in using it.  The freedom\n",
      "to run the program as you wish; the freedom to copy the program and\n",
      "give it away to your friends and co-workers; the freedom to change the\n",
      "program as you wish, by having full access to source code; the freedom\n",
      "to distribute an improved version and thus help build the community.\n",
      "(If you redistribute GNU software, you may charge a fee for the\n",
      "physical act of transferring a copy, or you may give away copies.)\n",
      "\n",
      "The project to develop the GNU system is called the “GNU\n",
      "Project.”  The GNU Project was conceived in 1983 as a way of\n",
      "bringing back the cooperative spirit that prevailed in the computing\n",
      "community in earlier days—to make cooperation possible once again by\n",
      "removing t\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://www.gnu.org/gnu/gnu-history.html\"\n",
    ")\n",
    "page = loader.load()[0]\n",
    "print(page.page_content[1000:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f3447",
   "metadata": {},
   "source": [
    "Following cell splits the input text to chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "952ac9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.gnu.org/gnu/gnu-history.html', 'title': 'Overview of the GNU System\\n- GNU Project - Free Software Foundation', 'language': 'en'}, page_content=\"Overview of the GNU System\\n- GNU Project - Free Software Foundation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main text\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFree Software Supporter:\\n  \\n\\n\\n\\n\\nJOIN\\xa0THE\\xa0FSF\\n\\n\\n\\n\\n\\nGNU Operating System\\nSupported by the\\n Free Software Foundation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSite navigation\\nSkip\\n\\n\\n=\\nABOUT\\xa0GNU\\n\\n=\\n\\nPHILOSOPHY\\nLICENSES\\nEDUCATION\\nSOFTWARE\\nDISTROS\\nDOCS\\nMALWARE\\nHELP\\xa0GNU\\nAUDIO\\xa0&\\xa0VIDEO\\nGNU\\xa0ART\\nFUN\\nGNU'S\\xa0WHO?\\nSOFTWARE\\xa0DIRECTORY\\nHARDWARE\\nSITEMAP\\n\\n\\n\\n\\n\\n\\n\\n\\xa0/\\nAbout\\xa0GNU\\xa0/\\nGNU\\xa0history\\xa0/\\n\\n\\n\\nOverview of the GNU System\\n\\n\\nThe GNU operating system is a complete free software system,\\nupward-compatible with Unix.  GNU stands for “GNU's Not Unix.”\\nIt is pronounced as one syllable with a\\nhard g.\\nRichard Stallman made the\\nInitial Announcement of\\nthe GNU Project in September 1983.  A longer version called\\nthe GNU Manifesto was published in\\nMarch 1985.  It has been translated into several\\nother languages.\"),\n",
       " Document(metadata={'source': 'https://www.gnu.org/gnu/gnu-history.html', 'title': 'Overview of the GNU System\\n- GNU Project - Free Software Foundation', 'language': 'en'}, page_content=\"The name “GNU” was chosen because it met a few\\nrequirements; first, it was a recursive acronym for “GNU's Not\\nUnix,” second, because it was a real word, and third, it was fun\\nto say (or\\n\\nsing).\\n\\nThe word “free” in “free software” pertains to\\nfreedom, not price.  You may or\\nmay not pay a price to get GNU software.  Either way, once you have\\nthe software you have four specific freedoms in using it.  The freedom\\nto run the program as you wish; the freedom to copy the program and\\ngive it away to your friends and co-workers; the freedom to change the\\nprogram as you wish, by having full access to source code; the freedom\\nto distribute an improved version and thus help build the community.\\n(If you redistribute GNU software, you may charge a fee for the\\nphysical act of transferring a copy, or you may give away copies.)\"),\n",
       " Document(metadata={'source': 'https://www.gnu.org/gnu/gnu-history.html', 'title': 'Overview of the GNU System\\n- GNU Project - Free Software Foundation', 'language': 'en'}, page_content='The project to develop the GNU system is called the “GNU\\nProject.”  The GNU Project was conceived in 1983 as a way of\\nbringing back the cooperative spirit that prevailed in the computing\\ncommunity in earlier days—to make cooperation possible once again by\\nremoving the obstacles to cooperation imposed by the owners of\\nproprietary software.\\n\\nIn 1971, when Richard Stallman started his career at MIT, he worked in\\na group which used free\\nsoftware exclusively.  Even computer companies often distributed\\nfree software.  Programmers were free to cooperate with each other,\\nand often did.\\n\\nBy the 1980s, almost all software was\\nproprietary,\\nwhich means that it had owners who forbid and\\nprevent cooperation by users.  This made the GNU Project necessary.'),\n",
       " Document(metadata={'source': 'https://www.gnu.org/gnu/gnu-history.html', 'title': 'Overview of the GNU System\\n- GNU Project - Free Software Foundation', 'language': 'en'}, page_content=\"By the 1980s, almost all software was\\nproprietary,\\nwhich means that it had owners who forbid and\\nprevent cooperation by users.  This made the GNU Project necessary.\\n\\nEvery computer user needs an operating system; if there is no free\\noperating system, then you can't even get started using a computer\\nwithout resorting to proprietary software.  So the first item on the\\nfree software agenda obviously had to be a free operating system.\\n\\nWe decided to make the operating system compatible with Unix because\\nthe overall design was already proven and portable, and because\\ncompatibility makes it easy for Unix users to switch from Unix to GNU.\"),\n",
       " Document(metadata={'source': 'https://www.gnu.org/gnu/gnu-history.html', 'title': 'Overview of the GNU System\\n- GNU Project - Free Software Foundation', 'language': 'en'}, page_content='A Unix-like operating system includes a kernel, compilers, editors,\\ntext formatters, mail software, graphical interfaces, libraries, games\\nand many other things.  Thus, writing a whole operating system is a\\nvery large job.  We started in January 1984.\\nThe  Free Software Foundation was\\nfounded in October 1985, initially to raise funds to help develop\\nGNU.\\nBy 1990 we had either found or written all the major components\\nexcept one—the kernel.  Then Linux, a Unix-like kernel, was\\ndeveloped by Linus Torvalds in 1991 and made free software in 1992.\\nCombining Linux with the almost-complete GNU system resulted in a\\ncomplete operating system: the GNU/Linux system.  Estimates are that\\ntens of millions of people now use GNU/Linux systems, typically\\nvia GNU/Linux distributions.  The principal\\nversion of Linux now contains nonfree firmware “blobs”;\\nfree software activists now maintain a modified free version of Linux,\\ncalled \\nLinux-libre.'),\n",
       " Document(metadata={'source': 'https://www.gnu.org/gnu/gnu-history.html', 'title': 'Overview of the GNU System\\n- GNU Project - Free Software Foundation', 'language': 'en'}, page_content='However, the GNU Project is not limited to the core operating system.\\nWe aim to provide a whole spectrum of software, whatever many users\\nwant to have.  This includes application software.  See\\nthe Free Software Directory for a catalogue\\nof free software application programs.\\n\\nWe also want to provide software for users who are not computer\\nexperts.  Therefore we developed a\\ngraphical desktop (called GNOME) to help\\nbeginners use the GNU system.\\nWe also want to provide games and other recreations.  Plenty of free games are\\nalready available.\\n\\nHow far can free software go?  There are no limits, except\\nwhen laws such as\\nthe patent system prohibit free software.  The ultimate goal is to\\nprovide free software to do all of the jobs computer users want to\\ndo—and thus make proprietary software a thing of the past.\\n\\n\\n\\n\\n\\n\\n\\n▲\\n\\n\\n\\nBACK TO TOP\\n\\n\\n\\n\\n   Set language\\n   \\n\\n\\nAvailable for this page:'),\n",
       " Document(metadata={'source': 'https://www.gnu.org/gnu/gnu-history.html', 'title': 'Overview of the GNU System\\n- GNU Project - Free Software Foundation', 'language': 'en'}, page_content='▲\\n\\n\\n\\nBACK TO TOP\\n\\n\\n\\n\\n   Set language\\n   \\n\\n\\nAvailable for this page:\\n\\n\\n[en]\\xa0English \\xa0\\n[ar]\\xa0العربية \\xa0\\n[bg]\\xa0български \\xa0\\n[ca]\\xa0català \\xa0\\n[cs]\\xa0čeština \\xa0\\n[de]\\xa0Deutsch \\xa0\\n[el]\\xa0ελληνικά \\xa0\\n[es]\\xa0español \\xa0\\n[fa]\\xa0فارسی \\xa0\\n[fr]\\xa0français \\xa0\\n[hr]\\xa0hrvatski \\xa0\\n[it]\\xa0italiano \\xa0\\n[ja]\\xa0日本語 \\xa0\\n[ml]\\xa0മലയാളം \\xa0\\n[nl]\\xa0Nederlands \\xa0\\n[pl]\\xa0polski \\xa0\\n[pt-br]\\xa0português \\xa0\\n[ro]\\xa0română \\xa0\\n[ru]\\xa0русский \\xa0\\n[sq]\\xa0Shqip \\xa0\\n[sr]\\xa0српски \\xa0\\n[tr]\\xa0Türkçe \\xa0\\n[uk]\\xa0українська \\xa0\\n[zh-cn]\\xa0简体中文 \\xa0\\n[zh-tw]\\xa0繁體中文 \\xa0\\n\\n\\n\\n\\n\\n\\n\\nBACK TO TOP ▲\\n\\n\\n\\n\\n“The Free Software Foundation (FSF) is a nonprofit with a worldwide\\nmission to promote computer user freedom. We defend the rights of all\\nsoftware users.”\\n\\n\\nJOIN\\nDONATE\\nSHOP\\n\\n\\n\\n\\n\\nPlease send general FSF & GNU inquiries to\\n<gnu@gnu.org>.\\nThere are also other ways to contact\\nthe FSF.  Broken links and other corrections or suggestions can be sent\\nto <webmasters@gnu.org>.\\n\\nPlease see the Translations\\nREADME for information on coordinating and contributing translations\\nof this article.'),\n",
       " Document(metadata={'source': 'https://www.gnu.org/gnu/gnu-history.html', 'title': 'Overview of the GNU System\\n- GNU Project - Free Software Foundation', 'language': 'en'}, page_content='Please see the Translations\\nREADME for information on coordinating and contributing translations\\nof this article.\\n\\n\\nCopyright © 1996, 1997, 2003, 2005, 2008, 2012, 2017, 2025\\nFree Software Foundation, Inc.\\nThis page is licensed under a Creative\\nCommons Attribution-NoDerivatives 4.0 International License.\\n\\n\\nCopyright Infringement Notification\\n\\n\\n\\n\\nUpdated:\\n\\n$Date: 2025/01/20 10:22:06 $')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splist = recursive_splitter.split_documents([page])\n",
    "splist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7196463",
   "metadata": {},
   "source": [
    "Finally, `OllamaEmbeddings` transforms each chunk into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a805dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0935436 ,  0.02679712, -0.01115783, ..., -0.08409031,\n",
       "         0.05330889,  0.04408916],\n",
       "       [-0.10084906,  0.03020417, -0.00327516, ..., -0.06176688,\n",
       "         0.06849608, -0.04358619],\n",
       "       [-0.11154472,  0.04795909, -0.02063497, ..., -0.01737392,\n",
       "         0.01384512,  0.02849417],\n",
       "       ...,\n",
       "       [-0.05303629, -0.01137888,  0.03749163, ..., -0.07315554,\n",
       "         0.04760291,  0.02396866],\n",
       "       [-0.03733822, -0.04157385, -0.06982869, ..., -0.06890925,\n",
       "         0.04996402, -0.01484258],\n",
       "       [-0.05137261,  0.02855329, -0.05077768, ..., -0.0165134 ,\n",
       "        -0.03141483, -0.08961581]], shape=(8, 384))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"all-minilm\")\n",
    "np.array(embeddings.embed_documents([doc.page_content for doc in splist]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4378fd4",
   "metadata": {},
   "source": [
    "## Vector stores\n",
    "\n",
    "Langchain integrates with various vector stores. The following table shows a few of them:\n",
    "\n",
    "| Class name                            | Package                                                                     |\n",
    "| ------------------------------------- | --------------------------------------------------------------------------- |\n",
    "| `InMemoryVectorStore`                 | `langchain-core.vectorstores`                                               |\n",
    "| `FAISS`                               | `langchain_community.vectorstores.faiss`                                    |\n",
    "| `PGVector`                            | `langchain-postgres` (`langchain.vectorstores.pgvector`)                    |\n",
    "| `ElasticsearchStore`                  | `langchain-elasticsearch` (`langchain.vectorstores.elasticsearch`)          |\n",
    "| `AzureCosmosDBMongoVCoreVectorSearch` | `langchain-azure-ai` (`langchain.vectorstores.azure_cosmos_db_mongo_vcore`) |\n",
    "| `AzureCosmosDBNoSqlVectorSearch`      | `langchain-azure-ai` (`langchain.vectorstores.azure_cosmos_db_no_sql`)      |\n",
    "| `AzureSearch`                         | `langchain-azure-ai` (`langchain.vectorstores.azuresearch`)                 |\n",
    "| `SQLServer_VectorStore`               | `langchain-sqlserver` (`langchain.vectorstores.sqlserver`)                  |\n",
    "\n",
    "For more details check: \n",
    "\n",
    "- [Vector stores](https://python.langchain.com/docs/integrations/vectorstores/) of the official documentation.\n",
    "- The description [`langchain_core.vectorstores.base.VectorStore`](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.base.VectorStore.html) which defines interface for the vector stores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac29a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the simpliest launch option option `InMemoryVectorStore`, for basic opeartions.\n",
    "\n",
    "In order to initialize the corresponding object, you must first create the embedding object. In this case, we will use `OllamaEmbeddings`, so you're supposed to launch Ollama locally first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16512cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.documents.base import Document\n",
    "vector_store = InMemoryVectorStore(OllamaEmbeddings(model=\"all-minilm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f4625",
   "metadata": {},
   "source": [
    "Use the `add_documents` method to add items to the vector storage. This method takes a list of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2961c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5895b10e-af40-4263-b0c6-ff4803bd49a6',\n",
       " '4ed7ff85-4f40-4881-8dae-59158b608c62',\n",
       " 'bac54e30-a7f8-4d7e-b682-d312b29c580c']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    Document(s) for s in [\n",
    "        \"This is dog\",\n",
    "        \"This is cat.\",\n",
    "        \"My car was crased\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f6cb4",
   "metadata": {},
   "source": [
    "The `similarity_search` method locates documents that are similar to the provided text. The following cells show some outputs for selected examles to make the outputs easier to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf32abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5895b10e-af40-4263-b0c6-ff4803bd49a6', metadata={}, page_content='This is dog'),\n",
       " Document(id='4ed7ff85-4f40-4881-8dae-59158b608c62', metadata={}, page_content='This is cat.'),\n",
       " Document(id='bac54e30-a7f8-4d7e-b682-d312b29c580c', metadata={}, page_content='My car was crased')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"This is cow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de61e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='bac54e30-a7f8-4d7e-b682-d312b29c580c', metadata={}, page_content='My car was crased'),\n",
       " Document(id='5895b10e-af40-4263-b0c6-ff4803bd49a6', metadata={}, page_content='This is dog'),\n",
       " Document(id='4ed7ff85-4f40-4881-8dae-59158b608c62', metadata={}, page_content='This is cat.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"Accidents sometimes happens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97db2a3",
   "metadata": {},
   "source": [
    "### Retriever\n",
    "\n",
    "The `as_retriever` function gives you access a special retriever object that can be used for searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808f47b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='bac54e30-a7f8-4d7e-b682-d312b29c580c', metadata={}, page_content='My car was crased'),\n",
       " Document(id='4ed7ff85-4f40-4881-8dae-59158b608c62', metadata={}, page_content='This is cat.'),\n",
       " Document(id='5895b10e-af40-4263-b0c6-ff4803bd49a6', metadata={}, page_content='This is dog')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrievier = vector_store.as_retriever(k=1)\n",
    "retrievier.invoke(\"09.11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b772afd6",
   "metadata": {},
   "source": [
    "## LLMs\n",
    "\n",
    "LangChain has special modules that implement interfaces for different ways of interacting with the language model.\n",
    "\n",
    "| Provider | Type | LangChain Class Name (Python) | Python Package |\n",
    "|---|---|---|---|\n",
    "| OpenAI | Commercial API | `langchain_openai.chat_models.ChatOpenAI`, `langchain_openai.llms.OpenAI` | `langchain-openai` |\n",
    "| Google | Commercial API | `langchain_google_genai.chat_models.ChatGoogleGenerativeAI` | `langchain-google-genai` |\n",
    "| Anthropic | Commercial API | `langchain_anthropic.chat_models.ChatAnthropic`, `langchain_anthropic.llms.AnthropicLLM` | `langchain-anthropic` |\n",
    "| Mistral AI | Commercial API | `langchain_mistralai.chat_models.ChatMistralAI` | `langchain-mistralai` |\n",
    "| Cohere | Commercial API | `langchain_cohere.chat_models.ChatCohere`, `langchain_cohere.llms.CohereLLM` | `langchain-cohere` |\n",
    "| AWS | Cloud Platform | `langchain_aws.chat_models.ChatBedrock`, `langchain_aws.llms.BedrockLLM` | `langchain-aws` |\n",
    "| Hugging Face | Community/Open-Source | `langchain_huggingface.llms.HuggingFaceHub`, `langchain_huggingface.llms.HuggingFacePipeline` | `langchain-huggingface` |\n",
    "| Ollama | On-Premise/Local | `langchain_ollama.ChatOllama`, `langchain_community.llms.OllamaLLM` | `langchain-ollama` |\n",
    "| Llama.cpp | On-Premise/Local | `langchain_community.llms.LlamaCpp` | `llama-cpp-python` |\n",
    "| Replicate | Commercial API | `langchain_replicate.llms.Replicate` | `langchain-replicate` |\n",
    "| Fireworks AI | Commercial API | `langchain_fireworks.chat_models.ChatFireworks`, `langchain_fireworks.llms.FireworksLLM` | `langchain-fireworks` |\n",
    "| Databricks | Cloud Platform | `databricks_langchain.llms.Databricks` | `databricks-langchain` |\n",
    "| Azure OpenAI | Commercial API | `langchain_openai.chat_models.AzureChatOpenAI`, `langchain_openai.llms.AzureOpenAI` | `langchain-openai` |\n",
    "| AI21 Labs | Commercial API | `langchain_ai21.llms.AI21LLM`, `langchain_ai21.chat_models.ChatAI21` | `langchain-ai21` |\n",
    "| Aleph Alpha | Commercial API | `langchain_community.llms.AlephAlpha` | `langchain-aleph-alpha` |\n",
    "| Groq | Commercial API | `langchain_groq.chat_models.ChatGroq` | `langchain-groq` |\n",
    "| Together AI | Commercial API | `langchain_together.llms.TogetherLLM`, `langchain_together.chat_models.ChatTogether` | `langchain-together` |\n",
    "| IBM | Cloud Platform | `langchain_community.chat_models.ChatWatsonx` | `langchain-ibm` |\n",
    "| DeepInfra | Commercial API | `langchain_deepinfra.llms.DeepInfra` | `langchain-deepinfra` |\n",
    "| Yandex | Commercial API | `langchain_community.llms.YandexGPT`, `langchain_community.llms.YandexGPTPredictor` | `langchain-yandex` |\n",
    "\n",
    "For a more detailed description, check out the [Chat models](https://python.langchain.com/docs/concepts/chat_models/) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5411842",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider, for example, using Ollama in the LangChain framework. For the following examples to run, ollama must be awailable on your local host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1aaff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1:latest\")\n",
    "ans = llm.invoke(\"What is the capital of France?\")\n",
    "print(ans.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e324a7",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "There are several classes that represent different aspects of prompting with LangChain.\n",
    "\n",
    "| Class Name    | Role           | General Description                                                                                                                                      |\n",
    "|---------------|----------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| SystemMessage | System         | Provides instructions or context to \"prime\" the model's behavior. It sets the persona, tone, or rules for the entire conversation. Typically the first message in a list. |\n",
    "| HumanMessage  | Human          | Represents the user's input. This is the message that a human sends to the model to ask a question or provide a command.                                  |\n",
    "| AIMessage     | AI (Assistant) | Represents the response from the language model. This is the output you get after invoking a model. It can contain text, tool calls, or other data.       |\n",
    "| ToolMessage   | Tool           | Represents the output or result of a tool function that was invoked by the AI. This is used to pass the outcome of a tool call back to the model for further processing. |\n",
    "\n",
    "The primary design of LangChain is to pass a list of objects to the model. It returns an output of type `AIMessage`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825b45d",
   "metadata": {},
   "source": [
    "All LangChain messages are children of the `langchain_core.messages.BaseMessage` class. The  follwing cell shows the relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5d64ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    ToolMessage,\n",
    "    BaseMessage\n",
    ")\n",
    "\n",
    "(\n",
    "    issubclass(HumanMessage, BaseMessage),\n",
    "    issubclass(SystemMessage, BaseMessage),\n",
    "    issubclass(AIMessage, BaseMessage),\n",
    "    issubclass(ToolMessage, BaseMessage)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7684082",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "In the LangChain paradigm, a prompt is a structured input for a model. It can include a system message, user input, or messaging history. The `lang_chain` package provides various tools for prompt templating. The following cell lists the most popular classes used for templating and their descriptions.\n",
    "\n",
    "| Class / Function                        | Description                                                                 |\n",
    "|----------------------------------------|-----------------------------------------------------------------------------|\n",
    "| **BasePromptTemplate**                 | Abstract base class for all prompt templates.                               |\n",
    "| **StringPromptTemplate**               | Base class for string-based templates (like f-string).                      |\n",
    "| **PromptTemplate**                     | Core template class for generating prompts with variables. Supports methods like `from_template`, `from_file`, `from_examples`, `format`, `invoke`, `ainvoke`, and batching. |\n",
    "| **FewShotPromptTemplate**              | String-based prompt template with few-shot example support.                 |\n",
    "| **FewShotPromptWithTemplates**         | String template variant with embedded few-shot examples.                    |\n",
    "| **PipelinePromptTemplate**             | Combines multiple prompt templates into a pipeline.                         |\n",
    "| **BaseChatPromptTemplate**             | Base class for chat-style prompt templates.                                 |\n",
    "| **ChatPromptTemplate**                 | Template for chat models; build multi-role messages. Supports `from_messages` and dynamic placeholders. |\n",
    "| **AgentScratchPadChatPromptTemplate**  | Specialized chat prompt for agent scratchpad patterns.                      |\n",
    "| **AutoGPTPrompt**                      | Chat prompt variant used in AutoGPT-style workflows.                        |\n",
    "| **BaseMessagePromptTemplate**          | Base for message-level prompt templates.                                    |\n",
    "| **BaseStringMessagePromptTemplate**    | Base class for message templates using string patterns.                     |\n",
    "| **ChatMessagePromptTemplate**          | Generates chat messages (with roles, e.g. system/human/AI) from template strings. |\n",
    "| **HumanMessagePromptTemplate**         | Template specifically for human messages.                                   |\n",
    "| **AIMessagePromptTemplate**            | Template specifically for AI messages.                                      |\n",
    "| **SystemMessagePromptTemplate**        | Template specifically for system messages.                                  |\n",
    "| **MessagesPlaceholder**                | Placeholder to inject dynamic message history into a chat template.         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf67a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the `PromptTemplate` class. You can use the `from_template` method to create a template. A substitutable pattern is specified by the `{}`. The `format` method of the `PromptTempalate` class returns a string with all substituted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "322bf96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your input is: Hello!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "ans = PromptTemplate.from_template(\"Your input is: {here}\")\n",
    "print(type(ans))\n",
    "ans.format(here=\"Hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ab11b",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Agents combine language models and tools to create the systems that can reason about tasks and decide which tools to use, and iteratively work around solution.\n",
    "\n",
    "The `langchain.agents.create_agent` is a function allows you to create an agent.\n",
    "\n",
    "Check more in the [Agents](langchain/agents.ipynb) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e44003",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following code creates an agent with llama in Ollama inference. There is one tool that provides information about the weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\", temperature=0)\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490d917",
   "metadata": {},
   "source": [
    "The invocation of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_history = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568f566",
   "metadata": {},
   "source": [
    "The message history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99badddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage:\n",
      "what is the weather in sf\n",
      "\n",
      "AIMessage:\n",
      "\n",
      "\n",
      "ToolMessage:\n",
      "It's always sunny in sf!\n",
      "\n",
      "AIMessage:\n",
      "I'm not able to provide real-time weather information or access current conditions. My previous response was an error.\n",
      "\n",
      "However, I can suggest some ways for you to find the current weather in San Francisco:\n",
      "\n",
      "1. Check online weather websites: You can visit websites like accuweather.com, weather.com, or wunderground.com to get the current weather conditions and forecast for San Francisco.\n",
      "2. Use a mobile app: There are many mobile apps available that provide real-time weather information, such as Dark Sky, Weather Underground, or The Weather Channel.\n",
      "3. Tune into local news: You can watch local news channels or listen to the radio to get the latest weather updates.\n",
      "\n",
      "I'll make sure to be more accurate in my responses moving forward.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in messages_history[\"messages\"]:\n",
    "    print(type(m).__name__ + \":\")\n",
    "    print(m.content, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d9a6e8",
   "metadata": {},
   "source": [
    "There is at least the tool invocation in the messages history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396d178",
   "metadata": {},
   "source": [
    "## LangGraph\n",
    "\n",
    "The LangGraph is a package allows you to specify text transformation in graph format.\n",
    "\n",
    "The graph is consits of:\n",
    "\n",
    "- **Nodes**: Python functions that transform data.\n",
    "- **Edges**: The connections between nodes.\n",
    "\n",
    "The **State** is the information that passes through the nodes according to the rules specified by the edges.\n",
    "\n",
    "Check more in the [LangGraph](langchain/langgraph.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c8fb4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the process of creating a simple graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853701a9",
   "metadata": {},
   "source": [
    "The following cell defines the `State` class, which describes the format of the data. The `initial_state` instance that defines the state that must be processed by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63244cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    n_list: List[str]\n",
    "\n",
    "initial_state = State(n_list=[\"input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d7b6b",
   "metadata": {},
   "source": [
    "The following cell defines the node that prints the input state and returns the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b1f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_a(state: State) -> State:\n",
    "    print(state[\"n_list\"])\n",
    "    return  State(n_list=[\"returns\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62248e47",
   "metadata": {},
   "source": [
    "Next cell shows the definition of the new graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1db8c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7cadd7aaf100>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"a\", node_a)\n",
    "\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5325b1",
   "metadata": {},
   "source": [
    "You can pass information through the compiled state graph by invoking it and passing data there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42d4d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['value']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_list': ['returns']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
