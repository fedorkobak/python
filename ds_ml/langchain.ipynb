{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e24c21",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "LangCain is software that enables the development of applications based on LLMs. Since all models/providers/inference servers have a slightly it different input/ouput format. Langchain builds a set of unified APIs. The same or nearly the same code can be used to build systems with different models and their hosting principles.\n",
    "\n",
    "There is a set of packages that implement a typical integrations of the langchain. The following table lists the most typical of them.\n",
    "\n",
    "| Package Name | Description |\n",
    "| :--- | :--- |\n",
    "| `langchain-community` | A general package for a wide variety of community-contributed tools and integrations, including web search (DuckDuckGo, Tavily), Python REPL, and various database connectors. |\n",
    "| `langchain-core` | The foundational package with the core tool abstractions and base classes. |\n",
    "| `langchain-experimental` | A package for new and experimental tools, which may not yet be stable. |\n",
    "| `langchain-tavily` | A dedicated package for the Tavily search tool. |\n",
    "| `langchain-brave-search` | A dedicated package for the Brave Search tool. |\n",
    "| `langchain-google-genai` | Includes tools for interacting with Google's Generative AI services. |\n",
    "| `langchain-anthropic` | Includes tools for interacting with the Anthropic API. |\n",
    "| `langchain-openai` | Contains integrations for OpenAI's models and services. |\n",
    "| `langchain-mongodb` | A package for interacting with MongoDB. |\n",
    "| `langchain-postgres` | A package for interacting with PostgreSQL. |\n",
    "| `langchain-ollama` | A package implements tools to request models lanched with ollama. |\n",
    "| `langchain-huggingface` | A package implements tools to interact with models from hugging face. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30554ee",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Typically, you must export the API key corresponding to the model type you want to use from your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f7a52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell shows the code that will only work if the \"GOOGLE_API_KEY\" variable exists in your environment with the corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86af27d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide me with the details of your test request.  I need information such as:\n",
      "\n",
      "* **What kind of test are you requesting?** (e.g., a unit test, an integration test, a performance test, a stress test, a usability test, a grammar test, a logic test, a factual accuracy test, etc.)\n",
      "* **What is the subject of the test?** (e.g., a piece of code, a website, a document, a sentence, an argument, etc.)\n",
      "* **What are the inputs or data for the test?** (If applicable)\n",
      "* **What are the expected outputs or results?** (If applicable)\n",
      "* **What are the acceptance criteria?** (How will you know if the test passed or failed?)\n",
      "\n",
      "The more information you give me, the better I can assist you.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "ans = llm.invoke(\"Test request\")\n",
    "print(ans.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972a782",
   "metadata": {},
   "source": [
    "## Text splitters\n",
    "\n",
    "Langchain contains module `text_splitter` which contains implementations of approaches to split texts into pieces. Can be usefull, for example for chunking in RAG pipeline.\n",
    "\n",
    "The following table shows the awailable text splitters.\n",
    "\n",
    "| Class Name | Description | Common Use Case |\n",
    "| :--- | :--- | :--- |\n",
    "| `CharacterTextSplitter` | Splits text based on a specified character (e.g., `\\n`, ` `). | Simple, quick splitting where structural integrity is not a major concern. |\n",
    "| `RecursiveCharacterTextSplitter` | The recommended default. Splits text based on a list of characters in a hierarchical order (e.g., `[\"\\n\\n\", \"\\n\", \" \"]`) to maintain logical chunks. | General-purpose text, such as articles, essays, and unstructured documents. |\n",
    "| `TokenTextSplitter` | Splits text based on the number of tokens, using a specific tokenizer (e.g., `tiktoken` for OpenAI models). | Preparing text to fit within a specific LLM's context window. |\n",
    "| `HTMLHeaderTextSplitter` | Splits HTML documents based on specified header tags (`h1`, `h2`, etc.). | Processing HTML content where you want to preserve sections defined by headers. |\n",
    "| `MarkdownTextSplitter` | Splits Markdown documents based on Markdown syntax, such as headers and code blocks. | Processing Markdown files while keeping logical sections together. |\n",
    "| `SentenceTransformersTokenTextSplitter` | Splits text using a tokenizer from the `sentence-transformers` library, based on a token count. | Working with models from the `sentence-transformers` library. |\n",
    "| `NLTKTextSplitter` | Splits text into sentences using the `NLTK` library's sentence tokenizer. | Splitting a document into individual sentences for fine-grained processing. |\n",
    "| `SpacyTextSplitter` | Splits text into sentences using the `spaCy` library. | Similar to NLTK, but leverages `spaCy` for sentence boundary detection, which can be more robust for some languages. |\n",
    "| `SemanticChunker` | A more advanced splitter that uses an embedding model to identify semantic breakpoints (topic shifts) in the text. | Creating semantically coherent chunks for more effective retrieval-augmented generation. |\n",
    "| `Language-specific Code Splitters` | A family of splitters for various programming languages (e.g., `PythonCodeTextSplitter`, `JavaScriptCodeTextSplitter`). | Processing code files to keep functions, classes, and other logical blocks intact. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0850d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "After initializing the splitter, use the `sprit_text` method to split the given text. The following cell demonstrates the application of the recursive text splitter to a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last people\n",
      "you’d expect to be involved in anything strange or mysterious, because they just\n",
      "didn’t hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did have a\n",
      "very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the\n",
      "usual amount of neck, which came in very useful as she spent so much of her\n",
      "time craning over garden fences, spying on the neighbors. The Dursleys had a\n",
      "small son called Dudley and in their opinion there was no finer boy anywhere.\n",
      "\n",
      "The Dursleys had everything they wanted, but they also had a secret, and\n",
      "their greatest fear was that somebody would discover it. They didn’t think they\n",
      "could bear it if anyone found out about the Potters. Mrs. Potter was Mrs.\n",
      "Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley\n",
      "pretended she didn’t have a sister, because her sister and her good-for-nothing\n",
      "husband were as unDursleyish as it was possible to be. The Dursleys shuddered\n",
      "\n",
      "to think what the neighbors would say if the Potters arrived in the street. The\n",
      "Dursleys knew that the Potters had a small son, too, but they had never even\n",
      "seen him. This boy was another good reason for keeping the Potters away; they\n",
      "didn’t want Dudley mixing with a child like that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "data = \"\"\"M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
    "that they were perfectly normal, thank you very much. They were the last people\n",
    "you’d expect to be involved in anything strange or mysterious, because they just\n",
    "didn’t hold with such nonsense.\n",
    "\n",
    "Mr. Dursley was the director of a firm called Grunnings, which made\n",
    "drills. He was a big, beefy man with hardly any neck, although he did have a\n",
    "very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the\n",
    "usual amount of neck, which came in very useful as she spent so much of her\n",
    "time craning over garden fences, spying on the neighbors. The Dursleys had a\n",
    "small son called Dudley and in their opinion there was no finer boy anywhere.\n",
    "\n",
    "The Dursleys had everything they wanted, but they also had a secret, and\n",
    "their greatest fear was that somebody would discover it. They didn’t think they\n",
    "could bear it if anyone found out about the Potters. Mrs. Potter was Mrs.\n",
    "Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley\n",
    "pretended she didn’t have a sister, because her sister and her good-for-nothing\n",
    "husband were as unDursleyish as it was possible to be. The Dursleys shuddered\n",
    "to think what the neighbors would say if the Potters arrived in the street. The\n",
    "Dursleys knew that the Potters had a small son, too, but they had never even\n",
    "seen him. This boy was another good reason for keeping the Potters away; they\n",
    "didn’t want Dudley mixing with a child like that.\"\"\"\n",
    "\n",
    "out = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=20\n",
    ").split_text(data)\n",
    "\n",
    "for t in out:\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f867e9b",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "LangChain porvides interfaces for interacting with embedding models. The core class here is `langchain_core.embeddings.Embeddings`, the api reference [here](https://api.python.langchain.com/en/latest/embeddings/langchain_core.embeddings.Embeddings.html).\n",
    "\n",
    "The following table shows the classes that implement the different embeddings model interfaces.\n",
    "\n",
    "| Class Name | Package |\n",
    "| :--- | :--- |\n",
    "| **`Embeddings`** | `langchain_core.embeddings` |\n",
    "| **`OpenAIEmbeddings`** | `langchain_openai` |\n",
    "| **`AzureOpenAIEmbeddings`** | `langchain_openai` |\n",
    "| **`HuggingFaceEmbeddings`** | `langchain_community.embeddings.huggingface` |\n",
    "| **`GoogleGenerativeAIEmbeddings`** | `langchain_google_genai` |\n",
    "| **`GoogleVertexAIEmbeddings`** | `langchain_google_vertexai` |\n",
    "| **`CohereEmbeddings`** | `langchain_cohere` |\n",
    "| **`OllamaEmbeddings`** | `langchain_ollama` |\n",
    "| **`VoyageEmbeddings`** | `langchain_voyageai` |\n",
    "| **`JinaEmbeddings`** | `langchain_community.embeddings.jina` |\n",
    "| **`FakeEmbeddings`** | `langchain_core.embeddings.fake` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a546f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the following example that uses `OllamaEmbeddings`. It uses ollama as inference of the model, so ollama is supposed to be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "embedder = OllamaEmtbeddings(model=\"all-minilm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd6871",
   "metadata": {},
   "source": [
    "Use the `embed_documents` method to obtain the embeddings for a givel list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "195a55e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embedder.embed_documents(\n",
    "    [\"Test embeddings\", \"some more complex text\"]\n",
    ")\n",
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e897605b",
   "metadata": {},
   "source": [
    "An embedding is provided for each of the given documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "532b06c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7cf842",
   "metadata": {},
   "source": [
    "And a dimentionality of embeddings depemends on the model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6855a135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4378fd4",
   "metadata": {},
   "source": [
    "## Vector stores\n",
    "\n",
    "Langchain integrates with various vector stores. The following table shows a few of them:\n",
    "\n",
    "| Class name                            | Package                                                                     |\n",
    "| ------------------------------------- | --------------------------------------------------------------------------- |\n",
    "| `InMemoryVectorStore`                 | `langchain-core.vectorstores`                                               |\n",
    "| `FAISS`                               | `langchain_community.vectorstores.faiss`                                    |\n",
    "| `PGVector`                            | `langchain-postgres` (`langchain.vectorstores.pgvector`)                    |\n",
    "| `ElasticsearchStore`                  | `langchain-elasticsearch` (`langchain.vectorstores.elasticsearch`)          |\n",
    "| `AzureCosmosDBMongoVCoreVectorSearch` | `langchain-azure-ai` (`langchain.vectorstores.azure_cosmos_db_mongo_vcore`) |\n",
    "| `AzureCosmosDBNoSqlVectorSearch`      | `langchain-azure-ai` (`langchain.vectorstores.azure_cosmos_db_no_sql`)      |\n",
    "| `AzureSearch`                         | `langchain-azure-ai` (`langchain.vectorstores.azuresearch`)                 |\n",
    "| `SQLServer_VectorStore`               | `langchain-sqlserver` (`langchain.vectorstores.sqlserver`)                  |\n",
    "\n",
    "Check more details in the page [vector stores](https://python.langchain.com/docs/integrations/vectorstores/) of the official documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac29a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the simpliest launch option option `InMemoryVectorStore`, for basic opeartions.\n",
    "\n",
    "In order to initialize the corresponding object, you must first create the embedding object. In this case, we will use `OllamaEmbeddings`, so you're supposed to launch Ollama locally first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16512cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.documents.base import Document\n",
    "vector_store = InMemoryVectorStore(OllamaEmbeddings(model=\"all-minilm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f4625",
   "metadata": {},
   "source": [
    "Use the `add_documents` method to add items to the vector storage. This method takes a list of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2961c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0ab9b5d0-8063-49fa-9b96-3bf11d710ef4',\n",
       " 'ad1fa14b-0c3d-4238-bef2-aca75162542a',\n",
       " '84c794bf-106b-48e2-9221-fce9f50dfead']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    Document(s) for s in [\n",
    "        \"This is dog\",\n",
    "        \"This is cat.\",\n",
    "        \"My car was crased\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f6cb4",
   "metadata": {},
   "source": [
    "The `similarity_search` method locates documents that are similar to the provided text. The following cells show some outputs for selected examles to make the outputs easier to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf32abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0ab9b5d0-8063-49fa-9b96-3bf11d710ef4', metadata={}, page_content='This is dog'),\n",
       " Document(id='ad1fa14b-0c3d-4238-bef2-aca75162542a', metadata={}, page_content='This is cat.'),\n",
       " Document(id='84c794bf-106b-48e2-9221-fce9f50dfead', metadata={}, page_content='My car was crased')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"This is cow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de61e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='84c794bf-106b-48e2-9221-fce9f50dfead', metadata={}, page_content='My car was crased'),\n",
       " Document(id='0ab9b5d0-8063-49fa-9b96-3bf11d710ef4', metadata={}, page_content='This is dog'),\n",
       " Document(id='ad1fa14b-0c3d-4238-bef2-aca75162542a', metadata={}, page_content='This is cat.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"Accidents sometimes happens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b772afd6",
   "metadata": {},
   "source": [
    "## LLMs\n",
    "\n",
    "That's an excellent point. It's crucial to know the specific package needed for each integration to correctly set up the environment. LLM is a core component of the any agent based system the following cell shows the classes that implement different LLMs into the LangChain module.\n",
    "\n",
    "| Provider | Type | LangChain Class Name (Python) | Python Package |\n",
    "|---|---|---|---|\n",
    "| OpenAI | Commercial API | `langchain_openai.chat_models.ChatOpenAI`, `langchain_openai.llms.OpenAI` | `langchain-openai` |\n",
    "| Google | Commercial API | `langchain_google_genai.chat_models.ChatGoogleGenerativeAI` | `langchain-google-genai` |\n",
    "| Anthropic | Commercial API | `langchain_anthropic.chat_models.ChatAnthropic`, `langchain_anthropic.llms.AnthropicLLM` | `langchain-anthropic` |\n",
    "| Mistral AI | Commercial API | `langchain_mistralai.chat_models.ChatMistralAI` | `langchain-mistralai` |\n",
    "| Cohere | Commercial API | `langchain_cohere.chat_models.ChatCohere`, `langchain_cohere.llms.CohereLLM` | `langchain-cohere` |\n",
    "| AWS | Cloud Platform | `langchain_aws.chat_models.ChatBedrock`, `langchain_aws.llms.BedrockLLM` | `langchain-aws` |\n",
    "| Hugging Face | Community/Open-Source | `langchain_huggingface.llms.HuggingFaceHub`, `langchain_huggingface.llms.HuggingFacePipeline` | `langchain-huggingface` |\n",
    "| Ollama | On-Premise/Local | `langchain_ollama.ChatOllama`, `langchain_community.llms.OllamaLLM` | `langchain-ollama` |\n",
    "| Llama.cpp | On-Premise/Local | `langchain_community.llms.LlamaCpp` | `llama-cpp-python` |\n",
    "| Replicate | Commercial API | `langchain_replicate.llms.Replicate` | `langchain-replicate` |\n",
    "| Fireworks AI | Commercial API | `langchain_fireworks.chat_models.ChatFireworks`, `langchain_fireworks.llms.FireworksLLM` | `langchain-fireworks` |\n",
    "| Databricks | Cloud Platform | `databricks_langchain.llms.Databricks` | `databricks-langchain` |\n",
    "| Azure OpenAI | Commercial API | `langchain_openai.chat_models.AzureChatOpenAI`, `langchain_openai.llms.AzureOpenAI` | `langchain-openai` |\n",
    "| AI21 Labs | Commercial API | `langchain_ai21.llms.AI21LLM`, `langchain_ai21.chat_models.ChatAI21` | `langchain-ai21` |\n",
    "| Aleph Alpha | Commercial API | `langchain_community.llms.AlephAlpha` | `langchain-aleph-alpha` |\n",
    "| Groq | Commercial API | `langchain_groq.chat_models.ChatGroq` | `langchain-groq` |\n",
    "| Together AI | Commercial API | `langchain_together.llms.TogetherLLM`, `langchain_together.chat_models.ChatTogether` | `langchain-together` |\n",
    "| IBM | Cloud Platform | `langchain_community.chat_models.ChatWatsonx` | `langchain-ibm` |\n",
    "| DeepInfra | Commercial API | `langchain_deepinfra.llms.DeepInfra` | `langchain-deepinfra` |\n",
    "| Yandex | Commercial API | `langchain_community.llms.YandexGPT`, `langchain_community.llms.YandexGPTPredictor` | `langchain-yandex` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5411842",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider, for example, using Ollama in the LangChain framework. For the following examples to run, ollama must be awailable on your local host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1aaff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1:latest\")\n",
    "ans = llm.invoke(\"What is the capital of France?\")\n",
    "print(ans.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e324a7",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "There are several classes that represent different aspects of prompting with LangChain.\n",
    "\n",
    "| Class Name    | Role           | General Description                                                                                                                                      |\n",
    "|---------------|----------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| SystemMessage | System         | Provides instructions or context to \"prime\" the model's behavior. It sets the persona, tone, or rules for the entire conversation. Typically the first message in a list. |\n",
    "| HumanMessage  | Human          | Represents the user's input. This is the message that a human sends to the model to ask a question or provide a command.                                  |\n",
    "| AIMessage     | AI (Assistant) | Represents the response from the language model. This is the output you get after invoking a model. It can contain text, tool calls, or other data.       |\n",
    "| ToolMessage   | Tool           | Represents the output or result of a tool function that was invoked by the AI. This is used to pass the outcome of a tool call back to the model for further processing. |\n",
    "\n",
    "The primary design of LangChain is to pass a list of objects to the model. It returns an output of type `AIMessage`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825b45d",
   "metadata": {},
   "source": [
    "All LangChain messages are children of the `langchain_core.messages.BaseMessage` class. The  follwing cell shows the relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5d64ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    ToolMessage,\n",
    "    BaseMessage\n",
    ")\n",
    "\n",
    "(\n",
    "    issubclass(HumanMessage, BaseMessage),\n",
    "    issubclass(SystemMessage, BaseMessage),\n",
    "    issubclass(AIMessage, BaseMessage),\n",
    "    issubclass(ToolMessage, BaseMessage)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7684082",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "In the LangChain paradigm, a prompt is a structured input for a model. It can include a system message, user input, or messaging history. The `lang_chain` package provides various tools for prompt templating. The following cell lists the most popular classes used for templating and their descriptions.\n",
    "\n",
    "| Class / Function                        | Description                                                                 |\n",
    "|----------------------------------------|-----------------------------------------------------------------------------|\n",
    "| **BasePromptTemplate**                 | Abstract base class for all prompt templates.                               |\n",
    "| **StringPromptTemplate**               | Base class for string-based templates (like f-string).                      |\n",
    "| **PromptTemplate**                     | Core template class for generating prompts with variables. Supports methods like `from_template`, `from_file`, `from_examples`, `format`, `invoke`, `ainvoke`, and batching. |\n",
    "| **FewShotPromptTemplate**              | String-based prompt template with few-shot example support.                 |\n",
    "| **FewShotPromptWithTemplates**         | String template variant with embedded few-shot examples.                    |\n",
    "| **PipelinePromptTemplate**             | Combines multiple prompt templates into a pipeline.                         |\n",
    "| **BaseChatPromptTemplate**             | Base class for chat-style prompt templates.                                 |\n",
    "| **ChatPromptTemplate**                 | Template for chat models; build multi-role messages. Supports `from_messages` and dynamic placeholders. |\n",
    "| **AgentScratchPadChatPromptTemplate**  | Specialized chat prompt for agent scratchpad patterns.                      |\n",
    "| **AutoGPTPrompt**                      | Chat prompt variant used in AutoGPT-style workflows.                        |\n",
    "| **BaseMessagePromptTemplate**          | Base for message-level prompt templates.                                    |\n",
    "| **BaseStringMessagePromptTemplate**    | Base class for message templates using string patterns.                     |\n",
    "| **ChatMessagePromptTemplate**          | Generates chat messages (with roles, e.g. system/human/AI) from template strings. |\n",
    "| **HumanMessagePromptTemplate**         | Template specifically for human messages.                                   |\n",
    "| **AIMessagePromptTemplate**            | Template specifically for AI messages.                                      |\n",
    "| **SystemMessagePromptTemplate**        | Template specifically for system messages.                                  |\n",
    "| **MessagesPlaceholder**                | Placeholder to inject dynamic message history into a chat template.         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf67a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the `PromptTemplate` class. You can use the `from_template` method to create a template. A substitutable pattern is specified by the `{}`. The `format` method of the `PromptTempalate` class returns a string with all substituted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "322bf96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your input is: Hello!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "ans = PromptTemplate.from_template(\"Your input is: {here}\")\n",
    "print(type(ans))\n",
    "ans.format(here=\"Hello!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
