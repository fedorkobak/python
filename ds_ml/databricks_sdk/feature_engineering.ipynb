{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bde309f",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c98963",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "There is a special module in the Databricks SDK `databricks.feature_engineering`. This allows you to manipulate with feature storage. There is a [package](https://pypi.org/project/databricks-feature-engineering/) that adds this module is published in PyPI.\n",
    "\n",
    "Officially, it only works in the Databricks environment. The only way to use this package locally is by using [VSCode databricks extension](https://docs.databricks.com/aws/en/dev-tools/vscode-ext).\n",
    "\n",
    "**Note.** You may be confused by the package `databricks.feature_store`, which has the same purpose. This is a legacy package.\n",
    "\n",
    "Check more in the feature_store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae980a5f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates a client for feature engineering. It will only run if everything is configured correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d7df64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"ts\": \"2025-09-30 11:40:24,344\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.client.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_message:\\\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\\\", grpc_status:13}\\\"\\n>\", \"stacktrace\": [\"Traceback (most recent call last):\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/pyspark/sql/connect/client/core.py\\\", line 2042, in config\", \"    resp = self._stub.Config(req, metadata=self.metadata())\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\\\", line 277, in __call__\", \"    response, ignored_call = self._with_call(\", \"                             ~~~~~~~~~~~~~~~^\", \"        request,\", \"        ^^^^^^^^\", \"    ...<4 lines>...\", \"        compression=compression,\", \"        ^^^^^^^^^^^^^^^^^^^^^^^^\", \"    )\", \"    ^\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\\\", line 332, in _with_call\", \"    return call.result(), call\", \"           ~~~~~~~~~~~^^\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\\\", line 440, in result\", \"    raise self\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\\\", line 315, in continuation\", \"    response, call = self._thunk(new_method).with_call(\", \"                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\", \"        request,\", \"        ^^^^^^^^\", \"    ...<4 lines>...\", \"        compression=new_compression,\", \"        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"    )\", \"    ^\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\\\", line 1195, in with_call\", \"    return _end_unary_response_blocking(state, call, True, None)\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\\\", line 1009, in _end_unary_response_blocking\", \"    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\", \"    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\", \"\\tstatus = StatusCode.INTERNAL\", \"\\tdetails = \\\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\\\"\", \"\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_message:\\\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\\\", grpc_status:13}\\\"\", \">\"]}}\n",
      "{\"ts\": \"2025-09-30 11:40:24,344\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.client.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_message:\\\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\\\", grpc_status:13}\\\"\\n>\", \"stacktrace\": [\"Traceback (most recent call last):\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/pyspark/sql/connect/client/core.py\\\", line 2042, in config\", \"    resp = self._stub.Config(req, metadata=self.metadata())\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\\\", line 277, in __call__\", \"    response, ignored_call = self._with_call(\", \"                             ~~~~~~~~~~~~~~~^\", \"        request,\", \"        ^^^^^^^^\", \"    ...<4 lines>...\", \"        compression=compression,\", \"        ^^^^^^^^^^^^^^^^^^^^^^^^\", \"    )\", \"    ^\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\\\", line 332, in _with_call\", \"    return call.result(), call\", \"           ~~~~~~~~~~~^^\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\\\", line 440, in result\", \"    raise self\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\\\", line 315, in continuation\", \"    response, call = self._thunk(new_method).with_call(\", \"                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\", \"        request,\", \"        ^^^^^^^^\", \"    ...<4 lines>...\", \"        compression=new_compression,\", \"        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"    )\", \"    ^\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\\\", line 1195, in with_call\", \"    return _end_unary_response_blocking(state, call, True, None)\", \"  File \\\"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\\\", line 1009, in _end_unary_response_blocking\", \"    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\", \"    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\", \"\\tstatus = StatusCode.INTERNAL\", \"\\tdetails = \\\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\\\"\", \"\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_message:\\\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\\\", grpc_status:13}\\\"\", \">\"]}}\n",
      "ERROR:pyspark.sql.connect.client.logging:GRPC Error received\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/pyspark/sql/connect/client/core.py\", line 2042, in config\n",
      "    resp = self._stub.Config(req, metadata=self.metadata())\n",
      "  File \"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\", line 277, in __call__\n",
      "    response, ignored_call = self._with_call(\n",
      "                             ~~~~~~~~~~~~~~~^\n",
      "        request,\n",
      "        ^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        compression=compression,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n",
      "    return call.result(), call\n",
      "           ~~~~~~~~~~~^^\n",
      "  File \"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\", line 440, in result\n",
      "    raise self\n",
      "  File \"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_interceptor.py\", line 315, in continuation\n",
      "    response, call = self._thunk(new_method).with_call(\n",
      "                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        request,\n",
      "        ^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        compression=new_compression,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\", line 1195, in with_call\n",
      "    return _end_unary_response_blocking(state, call, True, None)\n",
      "  File \"/home/user/.virtualenvironments/databricks_connect/lib/python3.13/site-packages/grpc/_channel.py\", line 1009, in _end_unary_response_blocking\n",
      "    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.INTERNAL\n",
      "\tdetails = \"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"[CONFIG_NOT_AVAILABLE] Configuration spark.mlflow.modelRegistryUri is not available. SQLSTATE: 42K0I\", grpc_status:13}\"\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient \n",
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab9afa",
   "metadata": {},
   "source": [
    "The log output is scary, but the client works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411af794",
   "metadata": {},
   "source": [
    "## Create table\n",
    "\n",
    "```python\n",
    "fs.create_table(\n",
    "    name=\"name_of_table\",\n",
    "    df=spark_table,\n",
    "    primary_keys=[\"primary_key1\", \"primary_key2\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6a23a",
   "metadata": {},
   "source": [
    "## Feature lookup\n",
    "\n",
    "The feature lookup specifies how features are searched in the storage. Create a feature lookup with the following code:\n",
    "\n",
    "```python\n",
    "from databricks.feature_store import FeatureLookup\n",
    "\n",
    "feature_lookup = FeatureLookup(\n",
    "    table_name=\"load_from\",\n",
    "    lookup_key=\"key\",\n",
    "    features_names=[\"feature1\", \"feature2\"]\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
