{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37bc5d60-6da7-4c2c-a912-3906c4f66dbf",
   "metadata": {},
   "source": [
    "# Kubernetes\n",
    "\n",
    "This is my compilation of tutorial [develop ML model with MLflow and deploy to Kubernetes](https://mlflow.org/docs/latest/deployment/deploy-model-to-kubernetes/tutorial.html) on the official mlflow site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b552eb2-2824-43e7-8520-dd2bafa03bea",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f4752-c872-4573-8186-aebb8c9e1b32",
   "metadata": {},
   "source": [
    "We'll need an instance of mlflow to start the following cell in the docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2dae02-e11d-4438-81ae-b9dd856341c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d9812c0785e9cdde0d64e510a88bb7a379200333f504c160a837742fd132b69e\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker run -p 5000:5000 -dt --name mlflow_deploy --rm \\\n",
    "    ghcr.io/mlflow/mlflow \\\n",
    "    bash -c \"mlflow server --host 0.0.0.0 --port 5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca9d0d-4500-46b0-899a-5fc1ca70c778",
   "metadata": {},
   "source": [
    "We will need place where docker images can be stored - docker registry. It can be Docker Hub. But here we're going to create our local registry. It's a big fun to have docker registry in docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0f2d36-16e3-418d-8d05-48df9b8e1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "079df3f509bf02b6496cbbc23fa3828209ce769b62017d9ccd60c7c263a02fcd\n"
     ]
    }
   ],
   "source": [
    "!docker run -d -p 5001:5000 --rm --name local-registry registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9432c4-9439-4801-b7ed-e5e96f5ee855",
   "metadata": {},
   "source": [
    "Obviously we will need kubernetes cluster to try this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300d65a5-8b95-47e0-97ef-727b28870d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!minikube start &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4901c22-d955-4402-a107-c1bacacb9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import requests\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76c8c1-a012-43a7-a98e-25c6d66061a1",
   "metadata": {},
   "source": [
    "Once you've tried everything on this notebook, it's a good idea to delete all the containers you've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b504b3-c5cb-41f1-87bb-91731355e2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow_deploy\n",
      "local-registry\n",
      "* Deleting \"minikube\" in docker ...\n",
      "* Deleting container \"minikube\" ...\n",
      "* Removing /home/f.kobak@maxbit.local/.minikube/machines/minikube ...\n",
      "* Removed all traces of the \"minikube\" cluster.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker stop mlflow_deploy local-registry\n",
    "minikube delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2156a9-a08f-4205-b143-88e6ef393036",
   "metadata": {},
   "source": [
    "It turns out that in order to run examples in minikube, you need to coimplete the installation tone associated with KServe, see [serverless Installation Guide](https://kserve.github.io/website/latest/admin/serverless/serverless/). You'll need to [install Istio](https://istio.io/latest/docs/setup/getting-started/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d042d-2c33-4b83-acfd-7e1b005159fa",
   "metadata": {},
   "source": [
    "```bash\n",
    "kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.14.1/serving-crds.yaml\n",
    "kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.14.1/serving-core.yaml\n",
    "istioctl install -y\n",
    "kubectl apply -f https://github.com/knative/net-istio/releases/download/knative-v1.14.1/net-istio.yaml\n",
    "kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.15.0/cert-manager.yaml\n",
    "kubectl apply -f https://github.com/kserve/kserve/releases/download/v0.13.0/kserve.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe361d3-2554-4f8d-a104-2796eb638e70",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc89b1d-72a0-4084-b36e-943926058af2",
   "metadata": {},
   "source": [
    "### Creating model\n",
    "\n",
    "As a model, we will use a model built on top of the Docker dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3bb44e-c1bd-44a7-83fb-ff2e57efc195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/10 15:34:18 INFO mlflow.tracking.fluent: Experiment with name 'wine-quality' does not exist. Creating a new experiment.\n",
      "2024/06/10 15:34:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/f.kobak@maxbit.local/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\"\n",
      "Successfully registered model 'wine-quality'.\n",
      "2024/06/10 15:34:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: wine-quality, version 1\n",
      "Created version '1' of model 'wine-quality'.\n"
     ]
    }
   ],
   "source": [
    "def eval_metrics(pred, actual):\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(actual, pred))\n",
    "    mae = metrics.mean_absolute_error(actual, pred)\n",
    "    r2 = metrics.r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Set th experiment name\n",
    "mlflow.set_experiment(\"wine-quality\")\n",
    "\n",
    "# Enable auto-logging to MLflow\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Load wine quality dataset\n",
    "X, y = datasets.load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Start a run and train a model\n",
    "with mlflow.start_run(run_name=\"default-params\") as run:\n",
    "    run_id = run.info.run_id\n",
    "    lr = ElasticNet()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_test)\n",
    "    metr = eval_metrics(y_pred, y_test)\n",
    "\n",
    "model_name = \"wine-quality\"\n",
    "result = mlflow.register_model(\n",
    "    f\"runs:/{run_id}/model\", model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb593d0e-8779-4c61-afee-8e2e7371b2ec",
   "metadata": {},
   "source": [
    "### Check\n",
    "\n",
    "To make sure everything's OK, let's try wrapping our model in an API locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3d8631-16c2-4cc0-bbac-941b20439449",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_api_command = f'MLFLOW_TRACKING_URI=http://localhost:5000 mlflow models serve --no-conda -m \"models:/{model_name}/1\" -p 4242'\n",
    "ans = subprocess.run([\n",
    "    'gnome-terminal', '--', 'bash', '-c', start_api_command\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6397c-6c1a-4b8d-8bec-6036d268434f",
   "metadata": {},
   "source": [
    "And a request to the newly created api will take shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6b0336-3764-436f-91c8-8f7398d05c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [0.4211626972839291]}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:4242/invocations\"\n",
    "headers = {'Content-Type': 'application/json',}\n",
    "data = {\n",
    "    \"inputs\": [[14.23, 1.71, 2.43, 15.6, 127.0, 2.8, 3.06, 0.28, 2.29, 5.64, 1.04, 3.92, 1065.0]]\n",
    "}\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcf29d-dbf3-46bb-99bd-42681f6518d0",
   "metadata": {},
   "source": [
    "## Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916bb3c-2fe8-48d1-9e51-2a258bf0d6ea",
   "metadata": {},
   "source": [
    "Create a Kubernetes namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf378337-0bc3-427a-9c01-6eb6510d2fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/mlflow-kserve-test created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace mlflow-kserve-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bbf567-3fd4-4f80-95b9-fef8bc9dd9f1",
   "metadata": {},
   "source": [
    "You need to create an image for your model. The following command will preform it:\n",
    "\n",
    "```bash\n",
    "MLFLOW_TRACKING_URI=http://localhost:5000 mlflow models build-docker -m \"models:/wine-quality/1\" -n wine_image --enable-mlserver\n",
    "```\n",
    "\n",
    "**Note** this command takes a long time, but you only need to run it once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ec50e-46cf-47fb-b9b0-70a7ba10d7e5",
   "metadata": {},
   "source": [
    "You need to run the following commands to push the image you just created to the local Docker registry.\n",
    "```bash\n",
    "docker tag wine_image:latest localhost:5001/wine_image:latest\n",
    "docker push localhost:5001/wine_image:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19ddcda-ca76-45d5-a344-d9b96bdca9f7",
   "metadata": {},
   "source": [
    "### Service config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df6209e4-9dbb-4830-99f7-354c2c865c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kubernetes_files/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile kubernetes_files/config.yaml\n",
    "apiVersion: \"serving.kserve.io/v1beta1\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"mlflow-wine-classifier\"\n",
    "  namespace: \"mlflow-kserve-test\"\n",
    "spec:\n",
    "  predictor:\n",
    "    containers:\n",
    "      - name: \"mlflow-wine-classifier\"\n",
    "        image: \"localhost:5001/wine_image\"\n",
    "        ports:\n",
    "          - containerPort: 8080\n",
    "            protocol: TCP\n",
    "        env:\n",
    "          - name: PROTOCOL\n",
    "            value: \"v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418ece24-f179-4d18-a9af-5418539e7049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io/mlflow-wine-classifier created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f kubernetes_files/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f907e04c-f159-4dfa-b2b7-97909bc12eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     URL   READY   PREV   LATEST   PREVROLLEDOUTREVISION   LATESTREADYREVISION   AGE\n",
      "mlflow-wine-classifier         False                                                                 4s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservices -n mlflow-kserve-test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
