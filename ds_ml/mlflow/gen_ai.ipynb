{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd2f7d3b",
   "metadata": {},
   "source": [
    "# Gen AI\n",
    "\n",
    "This page provides the details on the mlflow gen AI module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a75a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "from mlflow.tracking import MlflowClient\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "!rm -f /tmp/llm_mlflow.db\n",
    "mlflow.set_registry_uri(\"sqlite:////tmp/llm_mlflow.db\")\n",
    "mlflow.set_tracking_uri(\"sqlite:////tmp/llm_mlflow.db\")\n",
    "chat = ChatOllama(model=\"llama3.2:1b\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb5ddb",
   "metadata": {},
   "source": [
    "## Trace\n",
    "\n",
    "Each invocation to the LLM based pipeline is called \"trace\".\n",
    "\n",
    "Trace cosits of:\n",
    "\n",
    "- [**Trace info**](https://mlflow.org/docs/3.3.0/genai/tracing/concepts/trace/#traceinfo-metadata-and-context): general information about the trace primarly used for models ordering and selection.\n",
    "- [**Trace data**](https://mlflow.org/docs/3.3.0/genai/tracing/concepts/trace/#tracedata-container-of-spans): detailed information about the pipline run. Consists of spans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f0c13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell runs the experiment that produces the traces we will consider later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9f7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.langchain.autolog()\n",
    "ans = chat.invoke(\"Hello how are you?\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f0715",
   "metadata": {},
   "source": [
    "With `mlflow.search_traces` you can get the traces registered in your mlflows as `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef1fdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr-06f1ef26ee7df2eee94b73b1af90c415</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-06f1ef26ee7df2eee94b...</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1764150102464</td>\n",
       "      <td>3665</td>\n",
       "      <td>[[{'content': 'Hello how are you?', 'additiona...</td>\n",
       "      <td>{'generations': [[{'text': \"I'm doing well, th...</td>\n",
       "      <td>{'mlflow.user': 'user', 'mlflow.source.name': ...</td>\n",
       "      <td>{'mlflow.artifactLocation': '/home/user/Docume...</td>\n",
       "      <td>[{'trace_id': 'BvHvJu598u7pS3Oxr5DEFQ==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trace_id  \\\n",
       "0  tr-06f1ef26ee7df2eee94b73b1af90c415   \n",
       "\n",
       "                                               trace client_request_id  \\\n",
       "0  {\"info\": {\"trace_id\": \"tr-06f1ef26ee7df2eee94b...              None   \n",
       "\n",
       "           state   request_time  execution_duration  \\\n",
       "0  TraceState.OK  1764150102464                3665   \n",
       "\n",
       "                                             request  \\\n",
       "0  [[{'content': 'Hello how are you?', 'additiona...   \n",
       "\n",
       "                                            response  \\\n",
       "0  {'generations': [[{'text': \"I'm doing well, th...   \n",
       "\n",
       "                                      trace_metadata  \\\n",
       "0  {'mlflow.user': 'user', 'mlflow.source.name': ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  {'mlflow.artifactLocation': '/home/user/Docume...   \n",
       "\n",
       "                                               spans assessments  \n",
       "0  [{'trace_id': 'BvHvJu598u7pS3Oxr5DEFQ==', 'spa...          []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces = mlflow.search_traces()\n",
    "traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c3f9d",
   "metadata": {},
   "source": [
    "The following cell loads a specific trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a66d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_obj = mlflow.get_trace(traces[\"trace_id\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bfa651",
   "metadata": {},
   "source": [
    "The following cell shows loads the `info` of the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da552112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TraceInfo(trace_id='tr-06f1ef26ee7df2eee94b73b1af90c415', trace_location=TraceLocation(type=<TraceLocationType.MLFLOW_EXPERIMENT: 'MLFLOW_EXPERIMENT'>, mlflow_experiment=MlflowExperimentLocation(experiment_id='0'), inference_table=None), request_time=1764150102464, state=<TraceState.OK: 'OK'>, request_preview='[[{\"content\": \"Hello how are you?\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"human\", \"name\": null, \"id\": null}]]', response_preview='{\"generations\": [[{\"text\": \"I\\'m doing well, thank you for asking. Is there anything I can help you with or would you like to talk about something in particular?\", \"generation_info\": {\"model\": \"llama3.2:1b\", \"created_at\": \"2025-11-26T09:41:46.127363708Z\", \"done\": true, \"done_reason\": \"stop\", \"total_duration\": 3658687704, \"load_duration\": 1875642829, \"prompt_eval_count\": 30, \"prompt_eval_duration\": 394490334, \"eval_count\": 30, \"eval_duration\": 1350268885, \"model_name\": \"llama3.2:1b\", \"model_provider\": \"ollama\"}, \"type\": \"ChatGeneration\", \"message\": {\"content\": \"I\\'m doing well, thank you for asking. Is there anything I can help you with or would you like to talk about something in particular?\", \"additional_kwargs\": {}, \"response_metadata\": {\"model\": \"llama3.2:1b\", \"created_at\": \"2025-11-26T09:41:46.127363708Z\", \"done\": true, \"done_reason\": \"stop\", \"total_duration\": 3658687704, \"load_duration\": 1875642829, \"prompt_eval_count\": 30, \"prompt_eval_duration\": 394490334, \"eval_count\": 30, \"ev...', client_request_id=None, execution_duration=3665, trace_metadata={'mlflow.user': 'user', 'mlflow.source.name': '/home/user/.virtualenvironments/python/lib/python3.13/site-packages/ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.source.git.commit': 'be083a43d6047491e3b0b41bdc5a34c561d79cb6', 'mlflow.source.git.repoURL': 'git@github.com:fedorkobak/python.git', 'mlflow.source.git.branch': 'main', 'mlflow.trace_schema.version': '3', 'mlflow.traceInputs': '[[{\"content\": \"Hello how are you?\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"human\", \"name\": null, \"id\": null}]]', 'mlflow.traceOutputs': '{\"generations\": [[{\"text\": \"I\\'m doing well, thank you for asking. Is there anything I can help you with or would you like to talk about something in particular?\", \"generation_info\": {\"model\": \"llama3.2:1b\", \"created_at\": \"2025-11-26T09:41:46.12736...', 'mlflow.trace.tokenUsage': '{\"input_tokens\": 30, \"output_tokens\": 30, \"total_tokens\": 60}', 'mlflow.trace.sizeStats': '{\"total_size_bytes\": 21122, \"num_spans\": 1, \"max\": 18572, \"p25\": 18572, \"p50\": 18572, \"p75\": 18572}', 'mlflow.trace.sizeBytes': '21122'}, tags={'mlflow.artifactLocation': '/home/user/Documents/code/python/ds_ml/mlflow/mlruns/0/traces/tr-06f1ef26ee7df2eee94b73b1af90c415/artifacts', 'mlflow.traceName': 'ChatOllama'}, assessments=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_obj.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951ec72",
   "metadata": {},
   "source": [
    "This cell displays the `data` from the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b646195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TraceData(spans=[Span(name='ChatOllama', trace_id='tr-06f1ef26ee7df2eee94b73b1af90c415', span_id='c9eca46a0a240231', parent_id=None)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_obj.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7a0da",
   "metadata": {},
   "source": [
    "## Custom tracing\n",
    "\n",
    "To build a custom tracing framework you have to specify specify the spans creation logic and which information have to be logged to them:\n",
    "\n",
    "- The `mlflow.tracing` decorator to make a span each time the function is called.\n",
    "- The `mlflow.start_span` context manager to track everything that happens inside the span.\n",
    "\n",
    "**Note**: Some spans can be nested to the other spans.\n",
    "\n",
    "Check more in the:\n",
    "\n",
    "- [Manual Tracing](https://mlflow.org/docs/latest/genai/tracing/app-instrumentation/manual-tracing/) guide.\n",
    "- [mlflow.trace](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.html#mlflow.trace) decorator API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a95bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates the traced `some_tracing` function which simply wraps the input in special wrapped text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898c3200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/26 15:08:42 INFO mlflow.tracking.fluent: Experiment with name 'custom_tracing' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "ans = mlflow.set_experiment(\"custom_tracing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888fac9d",
   "metadata": {},
   "source": [
    "The following cell uses context manager syntax to create the span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6ee323",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_span() as span:\n",
    "    span.set_inputs(\"Input request\")\n",
    "    span.attributes[\"hello\"] = \"new_value\"\n",
    "    span.set_outputs(\"Span outputs\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c9cce",
   "metadata": {},
   "source": [
    "An alternative approach is to wrap the function with `mlflow.trace` decorator, so that its invocation is tracked as a span. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c1f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@mlflow.trace\n",
    "def some_tracing(inp: str) -> str:\n",
    "    return f\"<extra information>{inp}<the data>\"\n",
    "\n",
    "some_tracing(\"hello\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227776d4",
   "metadata": {},
   "source": [
    "The following cell shows the kind of span that would be obtained from the corresponding trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0a25465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inp': 'hello'} -> <extra information>hello<the data>\n"
     ]
    }
   ],
   "source": [
    "trace_id = mlflow.search_traces()[\"trace_id\"].iloc[0]\n",
    "trace = mlflow.get_trace(trace_id=trace_id)\n",
    "\n",
    "span = trace.data.spans[0]\n",
    "print(f\"{span.inputs} -> {span.outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813792d",
   "metadata": {},
   "source": [
    "### Customizing spans\n",
    "\n",
    "You can attach the following to each span:\n",
    "\n",
    "- `name`.\n",
    "- `span_type`: specified as value from predefined `mlflow.entities.SpanType`.\n",
    "- `attrributes`: key-value pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b3498",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates the span as the context, and invokes there some functions that are decorated as spans. Each span have different setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faf3a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import SpanType\n",
    "\n",
    "@mlflow.trace(\n",
    "    name=\"my_span\",\n",
    "    span_type=SpanType.LLM,\n",
    "    attributes={\"attr1\": \"value1\"}\n",
    ")\n",
    "def llm_span(input: str) -> str:\n",
    "    return \"some value\"\n",
    "\n",
    "@mlflow.trace(span_type=SpanType.RERANKER)\n",
    "def reranker_span(input: str) -> str:\n",
    "    return \"output of rerunker span\"\n",
    "\n",
    "with mlflow.start_span(span_type=\"custom span\", name=\"my_cool_span\"):\n",
    "    llm_span(\"input\")\n",
    "    reranker_span(\"reranker span input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c3ba1",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The MLFlow provides the tool for evaluation is the `mlflow.getia.evaluate` function. You have to provide:\n",
    "\n",
    "- `data`: dataset that would be used for evaluation. \n",
    "- `predict_fn`: function that implements the model. \n",
    "- `scorers`: list of evaluation objects, custom or provided by mlflow.\n",
    "\n",
    "Check more on [evaluation and monitoring](https://mlflow.org/docs/latest/genai/eval-monitor/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf5802",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell performs the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185abae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.genai import scorer\n",
    "from langchain.messages import AIMessage\n",
    "\n",
    "mlflow.set_experiment(\"evaluation_test\")\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is the Scotland's national animal?\"},\n",
    "        \"expectations\": {\"expected_response\": \"Unicorn\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Who was the first person to build an airplane?\"},\n",
    "        \"expectations\": {\"expected_response\": \"Wright Brothers\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Who wrote Romeo and Juliet?\"},\n",
    "        \"expectations\": {\"expected_response\": \"William Shakespeare\"},\n",
    "    },\n",
    "]\n",
    "\n",
    "def predict_fn(question: str) -> str:\n",
    "    return chat.invoke(question)\n",
    "\n",
    "\n",
    "@scorer\n",
    "def some_check(outputs: AIMessage) -> bool:\n",
    "    return len(outputs.content) < 10\n",
    "\n",
    "mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=predict_fn,\n",
    "    scorers=[some_check]\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49fb67",
   "metadata": {},
   "source": [
    "After that, you should see the corresponding interface in the MLFlow UI that describes the outputs of the evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
