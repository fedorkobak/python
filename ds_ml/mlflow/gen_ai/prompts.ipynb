{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4898448b-8f94-404e-9600-ff3d0fd237eb",
   "metadata": {},
   "source": [
    "# Promts\n",
    "\n",
    "MLflow has its own prompts registry for storing and versioning prompts and associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6818e98e-2277-47a0-8259-fc21b85c675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "from mlflow.tracking import MlflowClient\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "DATABASE_NAME = \"mlflow_prompts.db\"\n",
    "\n",
    "mlflow.set_registry_uri(f\"sqlite:////tmp/{DATABASE_NAME}\")\n",
    "mlflow.set_tracking_uri(f\"sqlite:////tmp/{DATABASE_NAME}\")\n",
    "chat = ChatOllama(model=\"llama3.2:1b\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d88b0d-501a-4877-a94a-47758649a0dd",
   "metadata": {},
   "source": [
    "## Alias\n",
    "\n",
    "An alias is a short name assigned to a specific version of a prompt. It usually reflects the unique role or status of that version. In the code that retrieves the prompt, you only need to reference the alias, so you donâ€™t have to modify the code when switching to a new version for a particular purpose - just assign the alias to the desired version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928bcf0-7370-4c5f-a0e3-db3650683b76",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell registers the two versions of the prompt that will be used for the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e232ad70-8b43-44ac-8ac0-80e713cb0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_name = \"alias_prompt\"\n",
    "mlflow.genai.register_prompt(name=prompt_name, template=\"Prompt1\")\n",
    "mlflow.genai.register_prompt(name=prompt_name, template=\"Prompt2\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b2c5c9-968e-48bd-957f-71a3d393abf4",
   "metadata": {},
   "source": [
    "You can use `mlflow.genai.set_prompt_alias` to assign an alias to the second model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64373e59-1bf1-4e9c-b325-2b16f7297004",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.genai.set_prompt_alias(\n",
    "    alias=\"production\",\n",
    "    name=prompt_name,\n",
    "    version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da92a5-98ba-4cef-89d7-eb19aba82b3f",
   "metadata": {},
   "source": [
    "The following cell shows the aliases for the second version of the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8814076c-ea8f-4cec-99f4-cc9f2b40d8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['production']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.genai.load_prompt(f\"prompts:/{prompt_name}/2\").aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5c28c-850c-4286-9040-18d002578ab9",
   "metadata": {},
   "source": [
    "It also shows that you can refer to the corresponding version of the prompt by alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251c510a-844c-4163-a38a-024fc67bcbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptVersion(name=alias_prompt, version=2, template=Prompt2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.genai.load_prompt(f\"prompts:/{prompt_name}@production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb2f03d-dec1-49eb-b886-fb2c4e828d83",
   "metadata": {},
   "source": [
    "## Format\n",
    "\n",
    "You can specify where something is supposed to be substituted using pattern `{{ var_name }}`. Use the `format` method with the substitutions provided as keyword arguments to get a string with a substituted patterns. Some popular framewokrs as `langchain` or `llamaIndex` support the subtitution patterns but use single bracket syntax. The prompt object's `to_single_brace_format` method can be used to confirm this requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eecda0-3d27-4a5f-ba1f-c4f198ae3d32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911fff36-70b8-4ec8-ba4e-101180601942",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.genai.register_prompt(\n",
    "    name=\"format_prompt\",\n",
    "    template=\"This is {{ some_pattern }}\"\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6b2a1-46ba-4cf6-8910-322691ce742a",
   "metadata": {},
   "source": [
    "And substitutes the infromation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8898bb9-0ec5-4703-862d-eaff80f8f4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is <inserted information>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = mlflow.genai.load_prompt(\"prompts:/format_prompt/1\")\n",
    "prompt.format(some_pattern=\"<inserted information>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6cd665-3859-439f-a49a-1844bf01f500",
   "metadata": {},
   "source": [
    "The example of reducing to the single bracket syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec2d44aa-1bd4-4277-9818-2c76d8a91896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is {some_pattern}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_single_brace_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af414a-e9f5-4a62-9838-224f6f62b98f",
   "metadata": {},
   "source": [
    "## Structured output\n",
    "\n",
    "You can save the expected format alongside prompt by using the `response_format` argument. You can provide either a Pydantic model or a JSON schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687f464-4dd7-440e-aac7-24a703e80d2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell defines the PyDantic model and saves it with the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55f393e-d7bf-460d-a19e-98eff28fad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ExampleModel(BaseModel):\n",
    "    str_var: str\n",
    "    int_var: int\n",
    "\n",
    "mlflow.genai.register_prompt(\n",
    "    name=\"strucutred_output\",\n",
    "    template=\"\",\n",
    "    response_format=ExampleModel\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383245d1-46db-4361-9b21-e920a0fc2c5d",
   "metadata": {},
   "source": [
    "You can retrieve the response format in form of JSON-schema by using the `response_format` attribute of the prompt object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae4cd32-c0b3-48ea-a391-fe5bcae51797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'str_var': {'title': 'Str Var', 'type': 'string'},\n",
       "  'int_var': {'title': 'Int Var', 'type': 'integer'}},\n",
       " 'required': ['str_var', 'int_var'],\n",
       " 'title': 'ExampleModel',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.genai.load_prompt(\"prompts:/strucutred_output/1\").response_format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
