{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7621934-2f80-4d7a-8478-ddb77e9d70ca",
   "metadata": {},
   "source": [
    "# Deploy\n",
    "\n",
    "**Sources**\n",
    "\n",
    "- [Tutorial by Tobias Starbak](https://www.youtube.com/watch?v=IUF4s9SXnd4);\n",
    "- [Deployment](https://mlflow.org/docs/latest/deployment/index.html) page in offcial MLflow documentation;\n",
    "- [Deploy mlflow model to Kubernetes](https://mlflow.org/docs/latest/deployment/deploy-model-to-kubernetes/index.html#build-docker-for-deployment) article in the official site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8b5cc-388c-4495-b431-e86e025da6ef",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bdcdb12-c7c1-4906-b5df-c9b0df24539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e289e1-b6b4-4767-b522-35ffc0765726",
   "metadata": {},
   "source": [
    "We need docker containers with mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b92a34-5e45-4937-aa24-3fa56f23ca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ea5fdd3eeab8fa057ad9c1ad1575039129e8e4b75a187f0c0449d9986c41156\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker run -p 5000:5000 -dt --name mlflow_deploy --rm \\\n",
    "    ghcr.io/mlflow/mlflow \\\n",
    "    bash -c \"mlflow server --host 0.0.0.0 --port 5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025488ce-3b61-462c-9f47-0759a165d1f7",
   "metadata": {},
   "source": [
    "To be able to work with these started mlflow, we need some setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d059614c-fa9a-4e5e-b864-ab26524a8fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'448934722381259260'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "exp_name = \"penguin_classification\"\n",
    "mlflow.create_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1c092-4614-4b6b-9768-1232065fcab1",
   "metadata": {},
   "source": [
    "When you have finished playing with the notebook, do not forget to stop the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42d03bdf-869d-4d24-9f8c-2a3909babef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow_deploy\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker stop mlflow_deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ca019-4710-47c9-bfbd-fecd4b7035ef",
   "metadata": {},
   "source": [
    "## Add model to registry\n",
    "\n",
    "We will consider simple example - model that callasify penguins based on parameters of their \"culmen\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17fd7a-f998-4621-ae7d-fc3465cd70dd",
   "metadata": {},
   "source": [
    "### Create run\n",
    "\n",
    "Create a run with the model in question. Everything is basic except the `signature` parameter of the `sklearn.log_model` method.\n",
    "\n",
    "So by code:\n",
    "\n",
    "```python\n",
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"Culmen Length (mm)\"),\n",
    "  ColSpec(\"double\", \"Culmen Depth (mm)\"),\n",
    "])\n",
    "```\n",
    "\n",
    "We have defined that the model takes two parameters: `Culmen Length (mm)` and `Culmen Depth (mm)`. This is important because it's exactly the number that should be passed to the model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35661813-01db-46f4-ab2a-928ebb6db69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 1d48d9284dd141018bba82d5cf84ef9f\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"Culmen Length (mm)\"),\n",
    "  ColSpec(\"double\", \"Culmen Depth (mm)\"),\n",
    "])\n",
    "output_schema = Schema([ColSpec(\"string\")])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Started run {run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data = pd.read_csv(\n",
    "        Path(\"deploy_files\")/\"penguins_classification.csv\"\n",
    "    )\n",
    "\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\", signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42f26e-9780-4eca-8ec8-542f63f29a8f",
   "metadata": {},
   "source": [
    "### Add run to registry\n",
    "\n",
    "There is a special storage for models - the model registry, so the following cell adds the model from the previous run to the registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da41f01-3058-4fdf-8e36-becf9176facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'penguins_clf'.\n",
      "2024/06/07 17:27:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: penguins_clf, version 1\n",
      "Created version '1' of model 'penguins_clf'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"penguins_clf\"\n",
    "result = mlflow.register_model(\n",
    "    f\"runs:/{run_id}/model\", model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99f1a3-fbf1-4b2e-900b-1541b4dd6499",
   "metadata": {},
   "source": [
    "## Run MLFlow side API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796c328-771b-4412-8381-48a4ce4fddc3",
   "metadata": {},
   "source": [
    "Now you can run a Flask-based API that will render the model by executing a command:\n",
    "\n",
    "```bash\n",
    "MLFLOW_TRACKING_URI=http://localhost:5000 mlflow models serve --no-conda -m \"models:/penguins_clf/1\" -p 4242\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a3688-f9fa-4a9e-8e03-763cc30a45c1",
   "metadata": {},
   "source": [
    "The following cell starts a new termilan window that will handle the api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f101a9dd-86ad-4521-be4a-dbfa7a9f61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_api_command = 'MLFLOW_TRACKING_URI=http://localhost:5000 mlflow models serve --no-conda -m \"models:/penguins_clf/1\" -p 4242'\n",
    "ans = subprocess.run([\n",
    "    'gnome-terminal', '--', 'bash', '-c', start_api_command\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1100f1e-f04d-4e77-be46-02e7ccf59223",
   "metadata": {},
   "source": [
    "After running the api, you can access it. So here is curl asking it - as a result we got a list with classes of penguins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf921ece-22f0-4190-897a-5785f100b57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"Adelie\", \"Adelie\", \"Chinstrap\"]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl http://127.0.0.1:4242/invocations -s -H 'Content-Type: application/json' -d '{\n",
    "    \"inputs\":[\n",
    "    {\"Culmen Length (mm)\": 1,\"Culmen Depth (mm)\": 3},\n",
    "    {\"Culmen Length (mm)\": 14,\"Culmen Depth (mm)\": 120},\n",
    "    {\"Culmen Length (mm)\": 200,\"Culmen Depth (mm)\": 100}\n",
    "]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01dea0-f7d2-41bd-91b0-b7407c891630",
   "metadata": {},
   "source": [
    "Or identical request using python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0277b6f8-42ec-4d71-ac48-509b7b2432dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"Adelie\", \"Adelie\", \"Chinstrap\"]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:4242/invocations\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "data = {\n",
    "    \"inputs\": [\n",
    "        {\"Culmen Length (mm)\": 1, \"Culmen Depth (mm)\": 3},\n",
    "        {\"Culmen Length (mm)\": 14, \"Culmen Depth (mm)\": 120},\n",
    "        {\"Culmen Length (mm)\": 200, \"Culmen Depth (mm)\": 100}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3777646c-a58b-44aa-8e8f-e559ffc55aa1",
   "metadata": {},
   "source": [
    "## Build docker image\n",
    "\n",
    "You can create a docker image that represents an api by using command `mlflow models build-docker`. full command will take veiw:\n",
    "\n",
    "```bash\n",
    "MLFLOW_TRACKING_URI=http://localhost:5000 mlflow models build-docker -m \"models:/penguins_clf/1\" -n penguins_image --enable-mlserver\n",
    "```\n",
    "\n",
    "**Note** The `--enable-mlserver` option tells the container to use `MLServer` as a wrapper. Flask is the default option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86248923-3bba-4020-9052-1d8e3c382415",
   "metadata": {},
   "source": [
    "After running the previous command, you'll have the image `penguins_container` in the local docker demon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95eebfe9-6154-48f6-82ce-c1d877ff2e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penguins_image           latest    dddd7cdc5ca2   2 minutes ago    1.25GB\n"
     ]
    }
   ],
   "source": [
    "!docker images | grep penguins_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d7be4-5663-4510-84e7-3822d6dad3ee",
   "metadata": {},
   "source": [
    "Now let's try to run this container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b348f235-9ce8-4525-b6b1-a66ca97871cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69c8c7939075e083c5e5e76bc1c669dbb5982332a6679925920685f23bb42500\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm -p 4243:8080 -d --name penguins_container penguins_image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868cb2a-034b-47a1-93a4-c19224b7f011",
   "metadata": {},
   "source": [
    "**Note** We refer to port 8080 of the container docker because this is the default in mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b745167c-ca8b-4de9-82ea-78270ab58ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"Adelie\", \"Adelie\", \"Chinstrap\"]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl http://127.0.0.1:4243/invocations -s -H 'Content-Type: application/json' -d '{\n",
    "    \"inputs\":[\n",
    "    {\"Culmen Length (mm)\": 1,\"Culmen Depth (mm)\": 3},\n",
    "    {\"Culmen Length (mm)\": 14,\"Culmen Depth (mm)\": 120},\n",
    "    {\"Culmen Length (mm)\": 200,\"Culmen Depth (mm)\": 100}\n",
    "]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668deb8-6466-4548-9579-314dcbce4285",
   "metadata": {},
   "source": [
    "Don't forget to stop the container with model API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b3bb4f5-a774-4b49-b29b-822611a94ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penguins_container\n"
     ]
    }
   ],
   "source": [
    "!docker stop penguins_container"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
