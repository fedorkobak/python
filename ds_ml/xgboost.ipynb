{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbfb957",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "[XGBoost](https://xgboost.readthedocs.io/en/stable/index.html) a popular package that implements a gradient boosting algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18476ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xgboost.config_context(verbosity=0)\n",
    "from pprint import pformat\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477bae2",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "XGBoost has built-in evaluation tools. You can:\n",
    "\n",
    "- Set the `eval_metric` for the object that implements the model. Look for description in the [Learning Task Parameters](https://xgboost.readthedocs.io/en/stable/parameter.html#learning-task-parameters).\n",
    "- Set the `eval_set` for `fit` method, which will be used to evaluate the model the fitting process.\n",
    "- Use the `evals_result` attribute of the fitted model to access its outputs.\n",
    "\n",
    "**Note.** the `eval_metric` doesn't influence the optimisation problem: \"objective function\" (in terns of XGBoost it is a loss function with regularisation component) does this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeba602",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell defines the model, that would be evaluated using `rmse` and `mae`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf2ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=5, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model = xgboost.XGBRegressor(\n",
    "    n_estimators=10,\n",
    "    eval_metric=['rmse', 'mae']\n",
    ").fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07edae12",
   "metadata": {},
   "source": [
    "The following code invokes the validation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93884ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_0': OrderedDict([('rmse',\n",
       "               [88.36185611431438,\n",
       "                85.5619274553268,\n",
       "                82.15710350923845,\n",
       "                83.82585462742627,\n",
       "                85.4184908720323,\n",
       "                87.2008393703865,\n",
       "                87.60270608669752,\n",
       "                87.69609884330428,\n",
       "                87.66542240780693,\n",
       "                88.09251860390917]),\n",
       "              ('mae',\n",
       "               [68.94008346557617,\n",
       "                64.97411354064941,\n",
       "                59.32854522705078,\n",
       "                61.621359786987306,\n",
       "                64.64699867248535,\n",
       "                67.44699798583984,\n",
       "                68.72293533325195,\n",
       "                69.23456924438477,\n",
       "                69.49240661621094,\n",
       "                70.03242248535156])])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evals_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617b2636",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Use the `save_model` method of the model's object.\n",
    "\n",
    "For more details check the [Introduction to Model IO](https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html) official tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed994e3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell just fits a XGBoost and saves it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb6885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=5)\n",
    "model = xgboost.XGBRegressor(n_estimators=10, seed=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "model.save_model(\"/tmp/xgb_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d6ce2",
   "metadata": {},
   "source": [
    "The next cell displays some lines from the result JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learner': {'attributes': {'scikit_learn': '{\"_estimator_type\": \"regressor\"}'},\n",
      "             'feature_names': [],\n",
      "             'feature_types': [],\n",
      "             'gradient_booster': {'model': {'gbtree_model_param': {'num_parallel_tree': '1',\n",
      "                                                                   'num_trees': '10'},\n",
      "                                            'iteration_indptr': [0,\n",
      "                                                                 1,\n",
      "                                                                 2,\n",
      "                                                                 3,\n",
      "                                                                 4,\n",
      "                                                                 5,\n",
      "                                                                 6,\n",
      "                                                                 7,\n",
      "                                                                 8,\n",
      "                                                           \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"/tmp/xgb_model.json\", \"r\") as f:\n",
    "    model_json = json.load(f)\n",
    "print(pformat(model_json)[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04529d56",
   "metadata": {},
   "source": [
    "Get just config of the booster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12358793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"learner\":{\"generic_param\":{\"device\":\"cpu\",\"fail_ ... ram\":{\"scale_pos_weight\":\"1\"}}},\"version\":[3,0,5]}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.get_booster().save_config()\n",
    "out[:50] + \" ... \"+ out[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4392d593",
   "metadata": {},
   "source": [
    "## Booster type\n",
    "\n",
    "For gradient boosting, you can specify the `booster` argument, which determines the algorithm used. You can specify the following options:\n",
    "\n",
    "- `gbtree`: for typical tree-based boosting.\n",
    "- `gblinear`: each estimator would be based on a regression model.\n",
    "- `dart`: adds a dropout mechanism that regulates the overfitting of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676021a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell defines the dataset that will be used as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45387f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02f97d",
   "metadata": {},
   "source": [
    "The next cell fits a tree-based model and prints its text representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db8982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[f3<-0.299755722] yes=1,no=2,missing=2\n",
      "\t1:[f2<-0.612705946] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-47.1132851\n",
      "\t\t4:leaf=-12.5197821\n",
      "\t2:[f2<0.0449830927] yes=5,no=6,missing=6\n",
      "\t\t5:leaf=-5.050488\n",
      "\t\t6:leaf=31.3139687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_model = xgboost.XGBRegressor(\n",
    "    max_depth=2,\n",
    "    n_estimators=10,\n",
    "    booster='gbtree'\n",
    ").fit(X, y)\n",
    "\n",
    "booster = tree_model.get_booster()\n",
    "print(booster.get_dump()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24f15e",
   "metadata": {},
   "source": [
    "The result is a set of principles that the tree uses to make a decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49103b55",
   "metadata": {},
   "source": [
    "In contrast, the following cell fits `gblinear` boosting, and shows the coefficients of the specific estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90189d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias:\n",
      "-7.45684\n",
      "weight:\n",
      "46.7333\n",
      "25.2602\n",
      "58.0306\n",
      "67.4508\n",
      "33.0191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_model = xgboost.XGBRegressor(\n",
    "    n_estimators=10,\n",
    "    booster='gblinear'\n",
    ").fit(X, y)\n",
    "\n",
    "booster = linear_model.get_booster()\n",
    "print(booster.get_dump()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
