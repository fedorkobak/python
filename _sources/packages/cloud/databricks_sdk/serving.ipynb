{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08c4ddd",
   "metadata": {},
   "source": [
    "# Serving\n",
    "\n",
    "Databricks provides many tools for serving ml models, as well as ready-deployed solutions. This page discusses how to use them through the Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4144c1",
   "metadata": {},
   "source": [
    "## OpenAI client\n",
    "\n",
    "The method `serving_endpoints.get_open_ai_client.get_open_ai_client` returns the  `openai.OpenAI` client, which you can use to requiest some served models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20d7c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates the `open_ai_client` and shows that it is really open ai client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db144289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.OpenAI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()\n",
    "\n",
    "open_ai_client = w.serving_endpoints.get_open_ai_client()\n",
    "type(open_ai_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da373f6",
   "metadata": {},
   "source": [
    "The following cell illustrates the invocation of the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f7bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.create_embedding_response.CreateEmbeddingResponse"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "embedding = open_ai_client.embeddings.create(\n",
    "   model=\"databricks-gte-large-en\",\n",
    "   input=\"hello\"\n",
    ")\n",
    "type(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feecbb5",
   "metadata": {},
   "source": [
    "The result is an `openai` embedding response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65947ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9521484375,\n",
       " -0.7998046875,\n",
       " -0.79931640625,\n",
       " -0.138427734375,\n",
       " -0.79150390625,\n",
       " -0.31787109375,\n",
       " -0.55810546875,\n",
       " 0.392333984375,\n",
       " -0.36767578125,\n",
       " 0.4013671875,\n",
       " -0.0791015625,\n",
       " -0.78515625,\n",
       " -0.4599609375,\n",
       " 0.4189453125,\n",
       " 0.418212890625,\n",
       " -0.36767578125,\n",
       " -0.587890625,\n",
       " -0.466796875,\n",
       " 0.159423828125,\n",
       " -0.359130859375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding.data[0].embedding[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d949f",
   "metadata": {},
   "source": [
    "## Serving endpoint\n",
    "\n",
    "With Databricks, you can launch an endpoint with a registered model. You can do this through the UI Databricks interface, but here we show the option of using the Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c823a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell registers the simple function that is logged as an ML model in MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072ea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.knowledge.serving_example' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db37474964f04d149059dfccf5f7038f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'workspace.knowledge.serving_example'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run whimsical-smelt-614 at: https://dbc-6bc9e7c2-e867.cloud.databricks.com/ml/experiments/2555847948754149/runs/f2ecb60bae784c7f8fea0e9bf1c6c456\n",
      "ðŸ§ª View experiment at: https://dbc-6bc9e7c2-e867.cloud.databricks.com/ml/experiments/2555847948754149\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "experiment_name = \"/Users/fedor.kobak@innowise.com/serving_tests\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "@mlflow.pyfunc.utils.pyfunc\n",
    "def model(model_input: list[float]) -> list[float]:\n",
    "    return [x * 2 for x in model_input]\n",
    "\n",
    "model_name = \"workspace.knowledge.serving_example\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        name=\"model\",\n",
    "        python_model=model,\n",
    "        pip_requirements=[],\n",
    "        registered_model_name=model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d8523",
   "metadata": {},
   "source": [
    "The following cell defines the endpoint configuration and endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacaf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EndpointCoreConfigInput(auto_capture_config=None, name=None, served_entities=[], served_models=[ServedModelInput(scale_to_zero_enabled=True, model_name='workspace.knowledge.serving_example', model_version=1, environment_vars=None, instance_profile_arn=None, max_provisioned_concurrency=None, max_provisioned_throughput=None, min_provisioned_concurrency=None, min_provisioned_throughput=None, name=None, provisioned_model_units=None, workload_size='Small', workload_type=None)], traffic_config=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from databricks.sdk.service.serving import EndpointCoreConfigInput\n",
    "config = EndpointCoreConfigInput.from_dict({\n",
    "    \"served_models\": [\n",
    "        {\n",
    "            \"model_name\": model_name,\n",
    "            \"model_version\": 1,\n",
    "            \"scale_to_zero_enabled\": True,\n",
    "            \"workload_size\": \"Small\"\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "endpoint_name = \"serving-example\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288828b8",
   "metadata": {},
   "source": [
    "Use  `WorkspaceClient.serving_endpoitns.create_and_wait` method to create the endpoint, as shown in the following cell.\n",
    "\n",
    "**Note.** This cell may take some time to be executed ~10 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ServingEndpointDetailed(ai_gateway=None, budget_policy_id=None, config=EndpointCoreConfigOutput(auto_capture_config=None, config_version=1, served_entities=[ServedEntityOutput(creation_timestamp=1759322561000, creator='fedor.kobak@innowise.com', entity_name='workspace.knowledge.serving_example', entity_version='1', environment_vars=None, external_model=None, foundation_model=None, instance_profile_arn=None, max_provisioned_concurrency=None, max_provisioned_throughput=None, min_provisioned_concurrency=None, min_provisioned_throughput=None, name='serving_example-1', provisioned_model_units=None, scale_to_zero_enabled=True, state=ServedModelState(deployment=<ServedModelStateDeployment.DEPLOYMENT_READY: 'DEPLOYMENT_READY'>, deployment_state_message=''), workload_size='Small', workload_type=<ServingModelWorkloadType.CPU: 'CPU'>)], served_models=[ServedModelOutput(creation_timestamp=1759322561000, creator='fedor.kobak@innowise.com', environment_vars=None, instance_profile_arn=None, max_provisioned_concurrency=None, min_provisioned_concurrency=None, model_name='workspace.knowledge.serving_example', model_version='1', name='serving_example-1', provisioned_model_units=None, scale_to_zero_enabled=True, state=ServedModelState(deployment=<ServedModelStateDeployment.DEPLOYMENT_READY: 'DEPLOYMENT_READY'>, deployment_state_message=''), workload_size='Small', workload_type=<ServingModelWorkloadType.CPU: 'CPU'>)], traffic_config=TrafficConfig(routes=[Route(traffic_percentage=100, served_entity_name='serving_example-1', served_model_name='serving_example-1')])), creation_timestamp=1759322561000, creator='fedor.kobak@innowise.com', data_plane_info=None, description='', email_notifications=None, endpoint_url=None, id='a4b755e5064c430dba1ef294b40e5010', last_updated_timestamp=1759322561000, name='serving-example', pending_config=None, permission_level=<ServingEndpointDetailedPermissionLevel.CAN_MANAGE: 'CAN_MANAGE'>, route_optimized=False, state=EndpointState(config_update=<EndpointStateConfigUpdate.NOT_UPDATING: 'NOT_UPDATING'>, ready=<EndpointStateReady.READY: 'READY'>), tags=[], task=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = WorkspaceClient()\n",
    "w.serving_endpoints.create_and_wait(\n",
    "    name=endpoint_name,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a9ede",
   "metadata": {},
   "source": [
    "After that your endpoint is awailable in the internet. The following cell throws `curl` to it.\n",
    "\n",
    "To use it you must create the environment variables `DATABRICKS_HOST` and `DATABRICKS_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b0e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [10.0, 20.0]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s\\\n",
    "  -u token:$DATABRICKS_TOKEN \\\n",
    "  -X POST \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"inputs\": [5.0, 10.0]}'\\\n",
    "  $DATABRICKS_HOST/serving-endpoints/serving-example/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25337610",
   "metadata": {},
   "source": [
    "The outputs, just as was specified in \"model\", are twice inputs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
