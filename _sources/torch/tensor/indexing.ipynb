{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "\n",
    "Indexing in PyTorch follows similar patterns to other libraries that handle arrays. Using the `[]` operator, you can select various subsets of the original tensor. This page highlights the options and features available for indexing with the `[]` operator in PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "Slicing is the most popular way to select subsets of the tensor. We will explore these options using the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental = torch.arange(15).reshape(3, 5)\n",
    "experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might seem obvious, but elements defined by slices are independent of the specifications of other axes. When you use slices to define selections across multiple axes, it will include all elements that fall within all slices. This behavior differs from selecting elements using iterable objects, as we will explore further.\n",
    "\n",
    "---\n",
    "\n",
    "The following example shows that if we specified rows 1, 2 and columns 0, 2, 4 with slices we selected elements with all combinations of the indeces specified in slices: [1, 0], [1, 2], [1, 4], [2, 0], [2, 2], [2, 4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  7,  9],\n",
       "        [10, 12, 14]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental[1:3, 0:5:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific case of slicing involves selecting elements along a particular axis, which can be done using the `:` operator for that axis.\n",
    "\n",
    "---\n",
    "\n",
    "The expression functions similarly to a slice applied to all objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental[1:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch does not directly support reverse slicing. However, you can achieve the same result using either the `torch.flip` function or the `torch.Tensor.flip` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following syntax attempts to achieve taking the first two columns of a tensor in reverse order using slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "step must be greater than zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexperimental\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: step must be greater than zero"
     ]
    }
   ],
   "source": [
    "experimental[:, 3:0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encountered an error stating that the step value must be greater than zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can easily achieve our goal using the `flip` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  0],\n",
       "        [ 7,  5],\n",
       "        [12, 10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental[:, :3:2].flip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterable objects\n",
    "\n",
    "The option with iterable objects allows you to specify the exact combinations of elements along different axes that you want to select. We’ll explore different options using the example provided in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental = torch.arange(15).reshape(3, 5)\n",
    "experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying an iterable for selection along one axis, it’s quite straightforward—you simply get a subset along the specified axis.\n",
    "\n",
    "---\n",
    "\n",
    "The following cell selects rows 1 and 2 from the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental[[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when it comes to using iterables as selection along different axes - it'll be interpreted as selection of the combinations of the axes.\n",
    "\n",
    "---\n",
    "\n",
    "In the following cell we specify selection `[[0, 1], [2, 3]]` which istrutcs torch to take elements with idices `[0,2]` and `[1,3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 8])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental[[0, 1], [2, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you specify iterables with a number of elements that does not match the dimensions of the tensor, you'll encounter an `IndexError` in PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "In the following example, we attempt to pass iterables of different sizes to PyTorch for selection, resulting in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [3], [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexperimental\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing tensors could not be broadcast together with shapes [3], [2]"
     ]
    }
   ],
   "source": [
    "experimental[[0, 1, 2], [0, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Selection of single elements behaves slightly differently; it essentially acts as if you're selecting just that one element.\n",
    "\n",
    "---\n",
    "\n",
    "The following example demonstrates that even when selecting a single element for columns, which does not correspond to row selection, everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  6, 11])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental[[0, 1, 2], [1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uspecified axes\n",
    "\n",
    "If you don't specify the inner indices, PyTorch will include all elements along those axes by default - so it equivalent to the `:`. The following cell demonstrates this by creating a 3-dimensional tensor. It shows that the expressions `temp_tensor[i]`, `temp_tensor[i, :]`, and `temp_tensor[i, :, :]` all yield the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "temp_tensor = torch.arange(12).reshape(2, 2, 3)\n",
    "\n",
    "print(temp_tensor[1])\n",
    "print(temp_tensor[1, :])\n",
    "print(temp_tensor[1,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New dimention\n",
    "\n",
    "Using `None` in indexing allows you to add new dimensions to the tensor. It'll add dimetion on the axis `None` displayed on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As example, we'll considering two dimention tensor created in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none_example_tensor = torch.arange(12).reshape(4,3)\n",
    "none_example_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By putting `None` at the top, we've got a new outer axis, so the whole matrix has been wrapped in the extra layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = none_example_tensor[None]\n",
    "print(res)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By placing `None` on the second axis, we'll create a new axis at the second position - each row of the matrix will be wrapped as a separate one-row matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2]],\n",
      "\n",
      "        [[ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "res = none_example_tensor[:, None]\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By placing `None` on the last axis, we create a new axis as the most nested axis - each number of the input tensor is now a small one-element vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0],\n",
      "         [ 1],\n",
      "         [ 2]],\n",
      "\n",
      "        [[ 3],\n",
      "         [ 4],\n",
      "         [ 5]],\n",
      "\n",
      "        [[ 6],\n",
      "         [ 7],\n",
      "         [ 8]],\n",
      "\n",
      "        [[ 9],\n",
      "         [10],\n",
      "         [11]]])\n",
      "torch.Size([4, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "res = none_example_tensor[:, :, None]\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
