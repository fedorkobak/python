{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a3324d-a50e-4f04-ab19-713eba6b619b",
   "metadata": {},
   "source": [
    "# Tensor\n",
    "\n",
    "Here is a description of the basic data type in PyTorch: `torch.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a27590-7460-406f-819a-a5cc789f908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23926ddf-b0be-43da-b7ad-40c83b03c280",
   "metadata": {},
   "source": [
    "## Create tensor\n",
    "\n",
    "Torch has tons of methods to create tensors. [This page](tensor/creating_methods.ipynb) lists the methods I know for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2803f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The most **straightforward** way is to use `torch.tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b0c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00,  1.4013e-45,  0.0000e+00,  1.4013e-45],\n",
       "         [ 0.0000e+00,  9.1084e-44,  0.0000e+00, -3.7852e+06,  3.3707e-41]],\n",
       "\n",
       "        [[-7.6466e+07,  3.3707e-41,  4.4842e-44,  0.0000e+00,  4.4842e-44],\n",
       "         [ 0.0000e+00,  6.3884e-27,  3.3703e-41,  0.0000e+00,  1.4013e-45]],\n",
       "\n",
       "        [[ 1.3004e-42,  0.0000e+00,  1.1210e-43,  0.0000e+00,  6.4326e-27],\n",
       "         [ 3.3703e-41,  4.2427e-08,  1.2964e+16,  2.1707e-18,  7.0952e+22]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.Tensor(3,2,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25859f2e-8d6c-4e3e-8969-8160425e531a",
   "metadata": {},
   "source": [
    "## Dimentionality\n",
    "\n",
    "One of the most important properties of the tensor is it's dimensionality. Torch provides a set of tools to manage tensor dimensionality. Find out more on the [dedicated page](tensor/dimentionality.ipynb).\n",
    "\n",
    "This section overviews tools that allows to work with diemntionality of the tensors. They are listed in the follwing table:\n",
    "\n",
    "\n",
    "| Function/Method  | Description                                                                                       |\n",
    "|------------------|---------------------------------------------------------------------------------------------------|\n",
    "| `shape`          | Returns the shape (dimensions) of a tensor as a tuple.                                             |\n",
    "| `reshape`        | Changes the shape of a tensor while preserving its data. The number of elements must remain the same. |\n",
    "| `transpose`      | Permutes the dimensions of a tensor. Useful for switching axes, like converting between column-major and row-major. |\n",
    "| `squeeze`        | Removes dimensions of size 1 from a tensor.                                                        |\n",
    "| `unsqueeze`      | Adds a dimension of size 1 at the specified position, effectively increasing the tensor's rank.     |\n",
    "| `pad`            | Adds padding to a tensor along specified dimensions. Useful in tasks like image processing.         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ce05d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell shows the usage of `torch.Tensor.shape` to print the dimensionality of the tensor and `torch.Tensor.reshape` to change the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "757661f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Tensor.shape torch.Size([2, 5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.zeros(2, 5, 3)\n",
    "print('torch.Tensor.shape', test_tensor.shape)\n",
    "test_tensor.reshape(6, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03036d",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Indexing in `torch` supports all the classic condepts, just like in `numpy` or `pandas`. But there are some features specific for `torch` findout more in the [specific page](tensor/indexing.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d82487b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following example shows the most basic methods of indexing in Torch. For the first dimensionality it takes all available elements, for the second it takes the slice `0:5:2` and along the last dimensionality it takes the elements counted in `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5df54c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "tensor([[[ 0,  1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10, 11],\n",
      "         [12, 13, 14, 15, 16, 17],\n",
      "         [18, 19, 20, 21, 22, 23],\n",
      "         [24, 25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34, 35]],\n",
      "\n",
      "        [[36, 37, 38, 39, 40, 41],\n",
      "         [42, 43, 44, 45, 46, 47],\n",
      "         [48, 49, 50, 51, 52, 53],\n",
      "         [54, 55, 56, 57, 58, 59],\n",
      "         [60, 61, 62, 63, 64, 65],\n",
      "         [66, 67, 68, 69, 70, 71]]])\n",
      "Sliced tensor\n",
      "tensor([[[ 5,  1,  4],\n",
      "         [17, 13, 16],\n",
      "         [29, 25, 28]],\n",
      "\n",
      "        [[41, 37, 40],\n",
      "         [53, 49, 52],\n",
      "         [65, 61, 64]]])\n"
     ]
    }
   ],
   "source": [
    "dimentionality = (2,6,6)\n",
    "experimental = torch.arange(prod(dimentionality)).reshape(dimentionality)\n",
    "\n",
    "print(\"Original tensor\")\n",
    "print(experimental)\n",
    "print(\"Sliced tensor\")\n",
    "print(experimental[:, 0:5:2, [5,1,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642b507",
   "metadata": {},
   "source": [
    "## Element-wise operations\n",
    "\n",
    "There is a class of operations in Pytorch that are applied element by element - we'll call them element wise operations.\n",
    "\n",
    "The following table lists most of them and corresponding to them operators.\n",
    "\n",
    "| **Operation**       | **Function**                           | **Operator** |\n",
    "|---------------------|----------------------------------------|--------------|\n",
    "| **Addition**        | `torch.add(tensor1, tensor2)`          | `+`          |\n",
    "| **Subtraction**     | `torch.sub(tensor1, tensor2)`          | `-`          |\n",
    "| **Multiplication**  | `torch.mul(tensor1, tensor2)`          | `*`          |\n",
    "| **Division**        | `torch.div(tensor1, tensor2)`          | `/`          |\n",
    "| **Equality**        | `torch.eq(tensor1, tensor2)`           | `==`         |\n",
    "| **Inequality**      | `torch.ne(tensor1, tensor2)`           | `!=`         |\n",
    "| **Greater Than**    | `torch.gt(tensor1, tensor2)`           | `>`          |\n",
    "| **Less Than**       | `torch.lt(tensor1, tensor2)`           | `<`          |\n",
    "| **Greater or Equal**| `torch.ge(tensor1, tensor2)`           | `>=`         |\n",
    "| **Less or Equal**   | `torch.le(tensor1, tensor2)`           | `<=`         |\n",
    "| **Logical AND**     | `torch.logical_and(tensor1, tensor2)` | `&`          |\n",
    "| **Logical OR**      | `torch.logical_or(tensor1, tensor2)`  | `|`          |\n",
    "| **Logical XOR**     | `torch.logical_xor(tensor1, tensor2)` | `^`          |\n",
    "| **Logical NOT**     | `torch.logical_not(tensor)`           | `~`          |\n",
    "| **Exponentiation**  | `torch.pow(tensor1, tensor2)`          | `**` or `^`  |\n",
    "| **Square Root**     | `torch.sqrt(tensor)`                   | N/A          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711403af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As a brief review, consider two matrices $A = [a_{ij}]_{n \\times m}$ and $B = [b_{ij}]_{n \\times m}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45fcb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5, -2,  4,  0, -4],\n",
       "        [-1, -4,  1, -5, -5],\n",
       "        [-4,  1,  4, -5, -5],\n",
       "        [-2,  2,  0,  1,  0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randint(-5,5, [4,5])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e16623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1, -3,  1, -4, -4],\n",
       "        [-4,  4, -4, -4, -3],\n",
       "        [ 3, -2,  0, -1,  0],\n",
       "        [ 4, -2,  0,  2,  1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.randint(-5,5, [4,5])\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac8daca",
   "metadata": {},
   "source": [
    "By applying the `+` operator to matrices we got the matrix $\\left[a_{ij} + b_{ij}\\right]_{n \\times m}$ - so the operation was applied element by element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e400a316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6, -5,  5, -4, -8],\n",
       "        [-5,  0, -3, -9, -8],\n",
       "        [-1, -1,  4, -6, -5],\n",
       "        [ 2,  0,  0,  3,  1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd8dd4b",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Element-wise operations in PyTorch support the incredibly convenient concept of **broadcasting**, allowing you to apply these operations to arrays with different dimensionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c011d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As an example, consider two tensors with different dimensionality, `zero_tensor` and `arange_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e5c823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor = torch.zeros(3,4)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22aaaf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arange_tensor = torch.arange(4)\n",
    "arange_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3b285",
   "metadata": {},
   "source": [
    "By applying the `+` operator to them, we got a result where each row of `zeros_tensor` was added `arange_tensor` element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1331cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3.],\n",
       "        [0., 1., 2., 3.],\n",
       "        [0., 1., 2., 3.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor + arange_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a6ae7",
   "metadata": {},
   "source": [
    "## Algebraic operations\n",
    "\n",
    "The following table lists algebraic operations on `torch.Tensor`.\n",
    "\n",
    "| **Operation**                 | **Function**                  | **Description**                           |\n",
    "|-------------------------------|-------------------------------|-------------------------------------------|\n",
    "| Matrix Multiplication         | `torch.matmul()`              | Matrix multiplication                    |\n",
    "|                               | `tensor1 @ tensor2`           | Matrix multiplication using `@` operator |\n",
    "| Singular Value Decomposition  | `torch.svd()`                 | Singular Value Decomposition (SVD)        |\n",
    "|                               | `torch.linalg.svd()`          | SVD with advanced options                |\n",
    "| Eigenvalues and Eigenvectors  | `torch.eig()`                 | Compute eigenvalues and eigenvectors     |\n",
    "|                               | `torch.linalg.eig()`          | Eigenvalues and eigenvectors (advanced)  |\n",
    "| Matrix Inversion              | `torch.linalg.inv()`          | Matrix inversion                          |\n",
    "|                               | `torch.inverse()`             | Matrix inversion (deprecated)            |\n",
    "| Matrix Norms                  | `torch.norm()`                | Compute the norm of a tensor             |\n",
    "|                               | `torch.linalg.norm()`         | Norm with advanced options               |\n",
    "| Determinants                  | `torch.det()`                 | Compute the determinant of a matrix       |\n",
    "|                               | `torch.linalg.det()`          | Determinant with advanced options        |\n",
    "| Matrix Trace                  | `torch.trace()`               | Compute the trace of a matrix            |\n",
    "| Eigenvalues                   | `torch.linalg.eigvals()`      | Compute eigenvalues of a square matrix   |\n",
    "| Matrix Rank                   | `torch.linalg.matrix_rank()`  | Compute the rank of a matrix             |\n",
    "| Cholesky Decomposition        | `torch.linalg.cholesky()`     | Cholesky decomposition                    |\n",
    "| QR Decomposition              | `torch.linalg.qr()`           | QR decomposition                          |\n",
    "| Solving Linear Systems        | `torch.linalg.solve()`        | Solve a system of linear equations       |\n",
    "|                               | `torch.linalg.lstsq()`        | Solve a least-squares problem            |\n",
    "| Kronecker Product             | `torch.kron()`                | Compute the Kronecker product             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc4a79",
   "metadata": {},
   "source": [
    "## Data type\n",
    "\n",
    "Torch has it's own system of data types. Here is a table that describes the available datatypes.\n",
    "\n",
    "\n",
    "| Type       | Description                                |\n",
    "|------------|--------------------------------------------|\n",
    "| `torch.float16` / `torch.half`  | 16-bit half precision (floating point)       |\n",
    "| `torch.float32` / `torch.float` | 32-bit single precision (floating point)     |\n",
    "| `torch.float64` / `torch.double`| 64-bit double precision (floating point)     |\n",
    "| `torch.int8`                    | 8-bit integer                                |\n",
    "| `torch.int16` / `torch.short`   | 16-bit integer                               |\n",
    "| `torch.int32` / `torch.int`     | 32-bit integer                               |\n",
    "| `torch.int64` / `torch.long`    | 64-bit integer                               |\n",
    "| `torch.uint8`                   | 8-bit unsigned integer                       |\n",
    "| `torch.bool`                    | Boolean type                                 |\n",
    "| `torch.complex64`               | 64-bit complex number (32-bit real and imaginary) |\n",
    "| `torch.complex128`              | 128-bit complex number (64-bit real and imaginary) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44a79f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You can get type of the tensor by using `dtype` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8009c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(3, 3).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737ced4",
   "metadata": {},
   "source": [
    "**Note** there are some functions in torch that have `dtype` parameter. By passing special torch objects as `dtype` arguments, we can get tensors of the specific dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a99e6f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3], dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53bb9f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((3,3), dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89807c",
   "metadata": {},
   "source": [
    "## Inplace methods\n",
    "\n",
    "Some methods of `torch.Tensor` allow you to change the value of the tensor on the fly. It's typical for such methods to have the underscore symbol `_` at the end of the name.\n",
    "\n",
    "| Method                       | Description                                                                                       |\n",
    "|------------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| `add_`                       | Adds the input tensor to the current tensor in place.                                             |\n",
    "| `addcmul_`                   | Performs a component-wise multiplication of two tensors and adds the result to the current tensor in place. |\n",
    "| `addcdiv_`                   | Performs a component-wise division of two tensors and adds the result to the current tensor in place. |\n",
    "| `bernoulli_`                 | Applies the Bernoulli distribution to the tensor in place.                                        |\n",
    "| `bmm_`                       | Performs batch matrix multiplication in place.                                                   |\n",
    "| `clamp_`                     | Clamps all elements in the input tensor to be within the specified range, in place.              |\n",
    "| `copy_`                      | Copies data from another tensor to the current tensor in place.                                    |\n",
    "| `div_`                       | Divides the current tensor by the input tensor in place.                                          |\n",
    "| `fill_`                      | Fills the tensor with the specified value in place.                                               |\n",
    "| `flatten_`                   | Flattens the tensor to a 1D tensor in place.                                                     |\n",
    "| `index_add_`                 | Adds values to the tensor at specified indices in place.                                          |\n",
    "| `index_fill_`                | Fills the tensor at specified indices with the given value in place.                              |\n",
    "| `index_copy_`                | Copies values from another tensor into the current tensor at specified indices, in place.         |\n",
    "| `mask_fill_`                 | Fills elements of the tensor where the mask is `True` with the specified value in place.           |\n",
    "| `mask_scatter_`              | Scatters values into the tensor at indices specified by the mask in place.                        |\n",
    "| `masked_fill_`               | Fills elements of the tensor where the mask is `True` with the specified value in place.           |\n",
    "| `masked_scatter_`            | Scatters values into the tensor where the mask is `True` in place.                                 |\n",
    "| `neg_`                       | Negates the tensor's values in place.                                                             |\n",
    "| `normal_`                    | Fills the tensor with random numbers from a normal distribution in place.                         |\n",
    "| `relu_`                      | Applies the ReLU activation function in place.                                                    |\n",
    "| `renorm_`                    | Renormalizes the tensor along a specified dimension in place.                                     |\n",
    "| `scatter_`                   | Scatters values into the tensor at specified indices in place.                                    |\n",
    "| `select_`                    | Selects a sub-tensor in place (used for slicing).                                                 |\n",
    "| `set_`                       | Sets tensor values based on other tensors or values in place.                                      |\n",
    "| `sigmoid_`                   | Applies the sigmoid function in place.                                                            |\n",
    "| `softmax_`                   | Applies the softmax function in place along a specified dimension.                                |\n",
    "| `sub_`                       | Subtracts the input tensor from the current tensor in place.                                      |\n",
    "| `t_`                         | Transposes the tensor in place (2D tensors only).                                                 |\n",
    "| `transpose_`                 | Transposes the tensor along specified dimensions in place.                                        |\n",
    "| `truncate_`                  | Truncates tensor values to a specified precision in place.                                         |\n",
    "| `zero_`                      | Sets all elements of the tensor to zero in place.                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63fbec",
   "metadata": {},
   "source": [
    "Here is an example of applying the `relu` transformation to the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37ca162f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000,\n",
       "        0.8000, 0.9000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = torch.arange(-1,1,0.1)\n",
    "my_tensor.relu_()\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910115c",
   "metadata": {},
   "source": [
    "## Aggregations\n",
    "\n",
    "Torch provides several aggregation methods, which reduce an array of numbers to a single value. The following table shows some of the methods.\n",
    "\n",
    "| Method     | Description                                        |\n",
    "|------------|----------------------------------------------------|\n",
    "| `min()`    | Returns the minimum value of all elements in the tensor. |\n",
    "| `max()`    | Returns the maximum value of all elements in the tensor. |\n",
    "| `argmin()` | Returns the index of the minimum value.                 |\n",
    "| `argmax()` | Returns the index of the maximum value.                 |\n",
    "| `sum()`    | Returns the sum of all elements in the tensor.          |\n",
    "| `mean()`   | Returns the mean of all elements in the tensor.         |\n",
    "| `median()` | Returns the median value of elements in the tensor.     |\n",
    "| `prod()`   | Returns the product of all elements in the tensor.      |\n",
    "| `std()`    | Returns the standard deviation of the tensor elements.  |\n",
    "| `var()`    | Returns the variance of the tensor elements.            |\n",
    "| `all()`    | Tests if all elements evaluate to `True`.               |\n",
    "| `any()`    | Tests if any element evaluates to `True`.               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489deb9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell generates a Torch matrix where each row has larger average elements than the previous one. We’ll use this array to explore the principles of aggregation methods in Torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af4f09e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.6230)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor = torch.cat(\n",
    "    [torch.normal(i, 3, [1, 20]) for i in range(20)],\n",
    "    dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3385be7",
   "metadata": {},
   "source": [
    "Applying the `sum` method to the array returns a zero-dimensional tensor representing the sum of all elements in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af7879b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3794.5530)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf0a3ab",
   "metadata": {},
   "source": [
    "After specifying the `dim` parameter, the aggregation will occur along the chosen axis. The following cell aggregates each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "493aeed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-16.4698,   9.2714,  31.5841,  59.7604,  78.6830, 102.7903, 139.8927,\n",
       "        122.9686, 162.2701, 190.2476, 211.2355, 211.3985, 243.5579, 275.2428,\n",
       "        262.9107, 298.6805, 310.6557, 327.2797, 371.0268, 401.5668])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5078aac",
   "metadata": {},
   "source": [
    "As a result, we obtained an array where each element is larger than the previous one—this aligns with the principles we used during the generation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a74195",
   "metadata": {},
   "source": [
    "## Concatenation/splitting\n",
    "\n",
    "There is a bunch of options that allows to consider set of tensors as unified tensor or vise versa difide one big tensor in to smaller pieces. All these functions have a bit different functional. Find out more in the [particual page](tensor/concatenation_splitting.ipynb).\n",
    "\n",
    "| Function         | Description                                                                 |\n",
    "|------------------|-----------------------------------------------------------------------------|\n",
    "| `torch.stack`    | Concatenates tensors along a new dimension.                                 |\n",
    "| `torch.cat`      | Concatenates tensors along an existing dimension.                           |\n",
    "| `torch.vstack`   | Stacks tensors vertically (along the first dimension).                      |\n",
    "| `torch.hstack`   | Stacks tensors horizontally (along the last dimension).                     |\n",
    "| `torch.dstack`   | Stacks tensors along a new third dimension (for 2D tensors, stacks along depth). |\n",
    "| `torch.chunk`    | Splits a tensor into a specified number of chunks along a given dimension.  |\n",
    "| `torch.split`    | Splits a tensor into sub-tensors based on a list of sizes along a specified dimension. |\n",
    "| `torch.repeat`   | Repeats a tensor along specified dimensions to increase its size.           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85742eb9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As an example, consider the tensor created in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3af5888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7793, -0.2321, -1.1366],\n",
       "        [ 0.4977, -0.3425,  1.0177],\n",
       "        [ 0.1320,  0.8735, -1.2108]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn([3, 3])\n",
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab97428",
   "metadata": {},
   "source": [
    "Using `torch.chunk`, the tensor can be transformed into a tuple of smaller tensors, where each tensor represents a line from the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b07d51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.1286, 0.5528, 0.7930]]),\n",
       " tensor([[-1.9157,  0.3871, -0.5575]]),\n",
       " tensor([[ 0.6818,  0.2752, -1.2651]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = torch.chunk(A, chunks=3)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9e208",
   "metadata": {},
   "source": [
    "Using `torch.stack`, we can join the smaller tensors back into one tensor, but now along a new axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffbf169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1286,  0.5528,  0.7930]],\n",
       "\n",
       "        [[-1.9157,  0.3871, -0.5575]],\n",
       "\n",
       "        [[ 0.6818,  0.2752, -1.2651]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d07571",
   "metadata": {},
   "source": [
    "## Gather\n",
    "\n",
    "`torch.gather` fucntion allows to select some values of the input tensor by indices and speciyf output form.\n",
    "\n",
    "Some notations are required for a more precise description:\n",
    "\n",
    "- $X$: input tensor of shape $(s_0, s_1, \\dots, s_{n-1})$.\n",
    "- An index tesnsor $I$ and output tensor $O$: both having dimentions $(s'_0, s'_1, \\dots, s'_{n-1})$.\n",
    "- $dim$: specified dimentions of the input to which will be substituted indeces from $I$.\n",
    "\n",
    "Operation can be written:\n",
    "\n",
    "$$O \\left[i_0, i_1, \\dots, i_{n-1} \\right] = X\\left[ i_0, i_1, \\dots, i_{dim-1}, I\\left[i_0, i_1, \\dots, i_{n-1} \\right], i_{dim+1}, \\dots, i_{n-1} \\right]$$\n",
    "\n",
    "So values from $I$ is substituted to the $dim$ index of the $X$, it formulates $O$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea94b91",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider example:\n",
    "\n",
    "$$\n",
    "X = \\left( \\begin{array}{cc}\n",
    "    1&2&3 \\\\ \n",
    "    4&5&6\n",
    "\\end{array}\n",
    "\\right),\n",
    "\n",
    "I = \\left( \\begin{array}{cc}\n",
    "    0&1 \\\\ \n",
    "    1&2\n",
    "\\end{array}\n",
    "\\right),\n",
    "\n",
    "dim=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5168b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])\n",
    "I = torch.tensor([\n",
    "    [0, 1],\n",
    "    [1, 2]\n",
    "])\n",
    "\n",
    "torch.gather(X, 1, I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963312d0",
   "metadata": {},
   "source": [
    "$dim=1$ so that all $I$ indices are replaced by the corresponding index of $X$ and form the same shape $O$.\n",
    "\n",
    "$$\n",
    "O = \\left( \\begin{array}{cc}\n",
    "    X[0, I[0,0]]&X[0, I[0,1]] \\\\ \n",
    "    X[1, I[1,0]]&X[1, I[1,1]]\n",
    "\\end{array}\n",
    "\\right)\n",
    "= \\left( \\begin{array}{cc}\n",
    "    X[0, 0]&X[0, 1] \\\\ \n",
    "    X[1, 1]&X[1, 2]\n",
    "\\end{array}\n",
    "\\right)\n",
    "= \\left( \\begin{array}{cc}\n",
    "    1&2 \\\\ \n",
    "    5&6\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
