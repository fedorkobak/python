{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef504414-d50e-4a33-92a9-21280295f977",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "The `sklearn.pipeline.Pipeline` is a tool that allows you to create objects that contain all the necessary stages of model fitting. In other words, you can create your own estimator as a combination of different objects that perform data processing or model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a0bed97-876c-49f9-9a88-94700adedd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b986b55-832c-4ea0-8239-17cc5bd95d30",
   "metadata": {},
   "source": [
    "## Demonstration of benefits\n",
    "\n",
    "Imagine that you need to create a model building pipeline that includes data standardisation and then model fitting. In this section I want to show the difference in code length and convenience of coding all by yourself and using the `sklean.pipeline.Pipeline` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864cc28c-a06b-41ae-9080-57c294f6baff",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "\n",
    "In the following cell I just generate a random regression task for use in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2523fe8a-e248-427a-911b-910696c6ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "features_count = 20\n",
    "np.random.seed(50)\n",
    "\n",
    "X = []\n",
    "\n",
    "for i in range(features_count):\n",
    "\n",
    "    mean = np.random.uniform(0,100)\n",
    "    std = np.abs(np.random.normal(0, 50))\n",
    "    \n",
    "    X.append(np.random.normal(mean, std, [sample_size, 1]))\n",
    "\n",
    "X = np.concatenate(X,axis=1)\n",
    "theoretical_coefs = np.random.normal(0, 20, [features_count, 1])\n",
    "y = np.dot(X, theoretical_coefs) + np.random.normal(0, 500, sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f7f2b-588d-4d9a-8315-9042547e1a13",
   "metadata": {},
   "source": [
    "### Self coding\n",
    "\n",
    "So here is code that does:\n",
    "\n",
    "- 10-fold split cross-validation for the named pipeline;\n",
    "- Display cross-validation results;\n",
    "- Fit model to full data sample;\n",
    "- Compute the mean prediction over the entire data sample.\n",
    "\n",
    "You need to create a cycle that fits `StandardScaler` for current split and fit model to standardised data. After the cycle at the step of fitting the model to the whole data, you need to describe the whole pipeline again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667ed2eb-d0fa-45c4-9a1a-586ca55ceece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 3.5097084970944476e-22\n",
      "Test error: 3.4625913023012295e-22\n",
      "Mean predict 19010.954067406543\n"
     ]
    }
   ],
   "source": [
    "my_split = KFold(n_splits = 10)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "\n",
    "for train_ind, test_ind in my_split.split(X):\n",
    "    \n",
    "    this_scaler = StandardScaler().fit(X[train_ind, :])\n",
    "    \n",
    "    train_X = this_scaler.transform(X[train_ind, :])\n",
    "    train_y = y[train_ind]\n",
    "    \n",
    "    test_X = this_scaler.transform(X[test_ind,:])\n",
    "    test_y = y[test_ind]\n",
    "\n",
    "    model = LinearRegression().fit(train_X, train_y)\n",
    "    train_errors.append(mean_squared_error(train_y, model.predict(train_X)))\n",
    "    test_errors.append(mean_squared_error(test_y, model.predict(test_X)))\n",
    "\n",
    "print(\"Train error:\", np.mean(np.array(train_errors)))\n",
    "print(\"Test error:\", np.mean(np.array(test_errors)))\n",
    "\n",
    "standart_X = StandardScaler().fit_transform(X)\n",
    "final_model = LinearRegression().fit(standart_X, y)\n",
    "print(\"Mean predict\", np.mean(final_model.predict(standart_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43b81a-078a-4dfc-b63b-6625df4e16e6",
   "metadata": {},
   "source": [
    "### Using `sklearn.pipeline`\n",
    "\n",
    "In the following cell, I perform exactly the same calculations using only `sklearn.pipeline.Pipeline`.\n",
    "\n",
    "You just need to define a `my_pipline` object where I describe the steps of the pipeline in the format `[(<name of step 1>,<object performing step 1>), (<name of step 2>,<object performing step 2>), ...]` and then just use it as a normal estimator - it will perform all the steps automatically.\n",
    "\n",
    "So in the following cell it used in combination with  `cross_validate` function to perform cross-validation, and after that just called `fit(...).predict(...)` to run the entire sample through the pipeline.\n",
    "\n",
    "The results are exactly the same.\n",
    "\n",
    "Less code! Easier to manage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52fee285-95ff-4685-bcec-630cbadd6eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: -3.5097084970944476e-22\n",
      "Test error: -3.4625913023012295e-22\n",
      "Mean predict 19010.954067406543\n"
     ]
    }
   ],
   "source": [
    "my_split = KFold(n_splits = 10)\n",
    "\n",
    "my_pipe = Pipeline([\n",
    "    (\"test_scaler\", StandardScaler()),\n",
    "    (\"my_model\", LinearRegression())\n",
    "])\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    estimator = my_pipe,\n",
    "    X = X, y = y,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv = my_split,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"Train error:\", np.mean(cv_results[\"train_score\"]))\n",
    "print(\"Test error:\", np.mean(cv_results[\"test_score\"]))\n",
    "print(\"Mean predict\", np.mean(my_pipe.fit(X,y).predict(X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
