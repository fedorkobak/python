{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9e19ea-e693-4ebc-b578-e24da838c863",
   "metadata": {},
   "source": [
    "# Queries documents entry\n",
    "\n",
    "Sometimes you will have options where your models predict relevance for query/document combinations that don't appear in your observed sample. And sometimes the opposite happens - some methods won't be able to predict some options that are available on the observed information. So behaviour of the runx in such options is interesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa89b702-33bf-4efb-93c2-dfc768b63224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ab931-c758-432b-ade5-fe46282d305c",
   "metadata": {},
   "source": [
    "## Lack of documents\n",
    "\n",
    "If you have missing documents - it's fine ranx will deal with it somehow. To be on the safe side, consider possible cases in the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8c60a-92bc-4f1a-813e-997607a84aba",
   "metadata": {},
   "source": [
    "**Qrels**\n",
    "\n",
    "The follwing cell considers case where there is some documents in `Run` wich weren't defined in the `Qrels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01097d26-b49d-4ac9-9306-d2a61173cc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5848359082471151"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = Qrels({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2},\n",
    "    \"q_2\": {\"d_2\": 1}\n",
    "})\n",
    "\n",
    "run = Run({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2, \"d_3\": 3},\n",
    "    \"q_2\": {\"d_1\": 3, \"d_2\": 1, \"d_3\": 2}\n",
    "}) \n",
    "evaluate(\n",
    "    qrels = qrels, run = run, metrics = \"ndcg@4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89774eb9-d6bf-4a25-81c0-b757c99868ea",
   "metadata": {},
   "source": [
    "**Runs**\n",
    "\n",
    "And in case there are documents that only appear in the `Qrels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d137e825-7213-493f-85ce-652cd9640c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5912532431001917"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = Qrels({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2, \"d_3\": 3},\n",
    "    \"q_2\": {\"d_1\": 3, \"d_2\": 1, \"d_3\": 2}\n",
    "})\n",
    "run = Run({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2},\n",
    "    \"q_2\": {\"d_1\": 3}\n",
    "}) \n",
    "evaluate(\n",
    "    qrels=qrels, run=run, metrics=[\"ndcg@4\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f17cc6-fe8b-477b-8a08-822f0a644c0a",
   "metadata": {},
   "source": [
    "## Lack of queries\n",
    "\n",
    "but if there are queries that occur only in `Runs` or `Qrels`, this leads to an error. The following cell shows both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34a73e4-104f-409d-ac99-8e9b9c142ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got exception - Qrels and Run query ids do not match. Pass `make_comparable=True` to add empty results for queries missing from the run and remove those not appearing in qrels.\n",
      "got exception - Qrels and Run query ids do not match. Pass `make_comparable=True` to add empty results for queries missing from the run and remove those not appearing in qrels.\n"
     ]
    }
   ],
   "source": [
    "qrels = Qrels({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2},\n",
    "    \"q_2\": {\"d_1\": 2, \"d_2\": 1},\n",
    "    \"q_3\": {\"d_1\": 1, \"d_2\": 1}\n",
    "})\n",
    "run = Run({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2},\n",
    "    \"q_2\": {\"d_1\": 3, \"d_2\": 1}\n",
    "})\n",
    "\n",
    "try:\n",
    "    evaluate(\n",
    "        qrels=qrels, run=run, metrics=\"ndcg@4\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"got exception -\", e)\n",
    "\n",
    "qrels = Qrels({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2},\n",
    "    \"q_2\": {\"d_1\": 2, \"d_2\": 1}\n",
    "})\n",
    "run = Run({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2},\n",
    "    \"q_2\": {\"d_1\": 3, \"d_2\": 1},\n",
    "    \"q_3\": {\"d_1\": 1, \"d_2\": 3}\n",
    "})\n",
    "\n",
    "try:\n",
    "    evaluate(\n",
    "        qrels=qrels, run=run, metrics=\"ndcg@4\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"got exception -\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa4859-4e30-453a-9ee5-30758c9cd3a7",
   "metadata": {},
   "source": [
    "You can fix that by passing argument `make_comparable=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9153df5-b75c-4f09-8e86-34e8f38c191a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5399687444280219"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = Qrels({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2},\n",
    "    \"q_2\": {\"d_1\": 2, \"d_2\": 1},\n",
    "    \"q_3\": {\"d_1\": 1, \"d_2\": 1}\n",
    "})\n",
    "\n",
    "run = Run({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2, \"d_3\": 3},\n",
    "    \"q_2\": {\"d_1\" : 3, \"d_2\": 1, \"d_3\": 2}\n",
    "})\n",
    "\n",
    "evaluate(\n",
    "    qrels=qrels, run=run, metrics=\"ndcg@4\", make_comparable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151fbbf-841f-44f3-bb6c-d07b58edd076",
   "metadata": {},
   "source": [
    "Or you can achieve the same result by simply passing an empty dictionary instead of the missing query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b75fb125-755f-4be5-a957-17831b65f27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5399687444280219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = Qrels({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2},\n",
    "    \"q_2\": {\"d_1\": 2, \"d_2\": 1},\n",
    "    \"q_3\": {\"d_1\": 1, \"d_2\": 1}\n",
    "})\n",
    "\n",
    "run = Run({\n",
    "    \"q_1\": {\"d_1\": 1, \"d_2\": 2, \"d_3\": 3},\n",
    "    \"q_2\": {\"d_1\" : 3, \"d_2\": 1, \"d_3\": 2},\n",
    "    \"q_3\": {}\n",
    "})\n",
    "\n",
    "evaluate(\n",
    "    qrels=qrels, run=run, metrics=\"ndcg@4\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}