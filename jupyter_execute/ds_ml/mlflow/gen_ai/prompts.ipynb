{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4898448b-8f94-404e-9600-ff3d0fd237eb",
   "metadata": {},
   "source": [
    "# Promts\n",
    "\n",
    "MLflow has its own prompts registry for storing and versioning prompts and associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6818e98e-2277-47a0-8259-fc21b85c675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "from mlflow.tracking import MlflowClient\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "DATABASE_NAME = \"mlflow_prompts.db\"\n",
    "\n",
    "mlflow.set_registry_uri(f\"sqlite:////tmp/{DATABASE_NAME}\")\n",
    "mlflow.set_tracking_uri(f\"sqlite:////tmp/{DATABASE_NAME}\")\n",
    "chat = ChatOllama(model=\"llama3.2:1b\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d88b0d-501a-4877-a94a-47758649a0dd",
   "metadata": {},
   "source": [
    "## Alias\n",
    "\n",
    "An alias is a short name assigned to a specific version of a prompt. It usually reflects the unique role or status of that version. In the code that retrieves the prompt, you only need to reference the alias, so you donâ€™t have to modify the code when switching to a new version for a particular purpose - just assign the alias to the desired version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928bcf0-7370-4c5f-a0e3-db3650683b76",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell registers the two versions of the prompt that will be used for the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e232ad70-8b43-44ac-8ac0-80e713cb0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_name = \"alias_prompt\"\n",
    "mlflow.genai.register_prompt(name=prompt_name, template=\"Prompt1\")\n",
    "mlflow.genai.register_prompt(name=prompt_name, template=\"Prompt2\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b2c5c9-968e-48bd-957f-71a3d393abf4",
   "metadata": {},
   "source": [
    "You can use `mlflow.genai.set_prompt_alias` to assign an alias to the second model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64373e59-1bf1-4e9c-b325-2b16f7297004",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.genai.set_prompt_alias(\n",
    "    alias=\"production\",\n",
    "    name=prompt_name,\n",
    "    version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da92a5-98ba-4cef-89d7-eb19aba82b3f",
   "metadata": {},
   "source": [
    "The following cell shows the aliases for the second version of the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8814076c-ea8f-4cec-99f4-cc9f2b40d8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['production']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.genai.load_prompt(f\"prompts:/{prompt_name}/2\").aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5c28c-850c-4286-9040-18d002578ab9",
   "metadata": {},
   "source": [
    "It also shows that you can refer to the corresponding version of the prompt by alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251c510a-844c-4163-a38a-024fc67bcbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptVersion(name=alias_prompt, version=2, template=Prompt2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.genai.load_prompt(f\"prompts:/{prompt_name}@production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb2f03d-dec1-49eb-b886-fb2c4e828d83",
   "metadata": {},
   "source": [
    "## Format\n",
    "\n",
    "You can specify where something is supposed to be substituted using pattern `{{ var_name }}`. Use the `format` method with the substitutions provided as keyword arguments to get a string with a substituted patterns. Some popular framewokrs as `langchain` or `llamaIndex` support the subtitution patterns but use single bracket syntax. The prompt object's `to_single_brace_format` method can be used to confirm this requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eecda0-3d27-4a5f-ba1f-c4f198ae3d32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell creates the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911fff36-70b8-4ec8-ba4e-101180601942",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.genai.register_prompt(\n",
    "    name=\"format_prompt\",\n",
    "    template=\"This is {{ some_pattern }}\"\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6b2a1-46ba-4cf6-8910-322691ce742a",
   "metadata": {},
   "source": [
    "And substitutes the infromation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8898bb9-0ec5-4703-862d-eaff80f8f4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is <inserted information>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = mlflow.genai.load_prompt(\"prompts:/format_prompt/1\")\n",
    "prompt.format(some_pattern=\"<inserted information>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6cd665-3859-439f-a49a-1844bf01f500",
   "metadata": {},
   "source": [
    "The example of reducing to the single bracket syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec2d44aa-1bd4-4277-9818-2c76d8a91896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is {some_pattern}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_single_brace_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af414a-e9f5-4a62-9838-224f6f62b98f",
   "metadata": {},
   "source": [
    "## Structured output\n",
    "\n",
    "You can save the expected format alongside prompt by using the `response_format` argument. You can provide either a Pydantic model or a JSON schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687f464-4dd7-440e-aac7-24a703e80d2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell defines the PyDantic model and saves it with the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55f393e-d7bf-460d-a19e-98eff28fad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ExampleModel(BaseModel):\n",
    "    str_var: str\n",
    "    int_var: int\n",
    "\n",
    "mlflow.genai.register_prompt(\n",
    "    name=\"strucutred_output\",\n",
    "    template=\"\",\n",
    "    response_format=ExampleModel\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383245d1-46db-4361-9b21-e920a0fc2c5d",
   "metadata": {},
   "source": [
    "You can retrieve the response format in form of JSON-schema by using the `response_format` attribute of the prompt object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae4cd32-c0b3-48ea-a391-fe5bcae51797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'str_var': {'title': 'Str Var', 'type': 'string'},\n",
       "  'int_var': {'title': 'Int Var', 'type': 'integer'}},\n",
       " 'required': ['str_var', 'int_var'],\n",
       " 'title': 'ExampleModel',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.genai.load_prompt(\"prompts:/strucutred_output/1\").response_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e09a8-1566-4301-b81d-ddbdcc9d1c13",
   "metadata": {},
   "source": [
    "## Registering/serving\n",
    "\n",
    "MLFlow provieds tools for registering and serving LLM-based applications that use a workflow similar to classical ML models.\n",
    "\n",
    "You must inherit inherit `mlflow.pyfunc.ResponsesAgent` object and implement the `predict` method. The `mlflow.pyfunc.ResponseAgent` is just an extension of the `mlflow.pyfunc` flavour specific for LLM-based applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2cac5-e263-4283-bc24-6afc0446dbcb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell defines the `SimpleResponsesAgent`, which simply returns a predifined message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4859109-fb0b-419c-ac0c-9c9697455ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import SpanType\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import ResponsesAgentRequest, ResponsesAgentResponse\n",
    "\n",
    "\n",
    "class SimpleResponsesAgent(ResponsesAgent):\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        return ResponsesAgentResponse(\n",
    "            output=[\n",
    "                self.create_text_output_item(\n",
    "                    text=\"The result of 4 * 3 in Python is 12.\",\n",
    "                    id=\"msg_1\",\n",
    "                )\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a582cd-4443-4b64-9ee9-f9d870a77ef9",
   "metadata": {},
   "source": [
    "The following cell registers the regular models in the model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7edd40-fc04-4b26-a76c-6c89b790a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/27 14:12:00 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/11/27 14:12:00 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025-11-27 14:12:00 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-11-27 14:12:00 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025-11-27 14:12:00 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-11-27 14:12:00 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/11/27 14:12:00 INFO mlflow.pyfunc: Predicting on input example to validate output\n",
      "2025/11/27 14:12:03 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/11/27 14:12:03 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025-11-27 14:12:03 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-11-27 14:12:03 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'agent' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'agent'.\n"
     ]
    }
   ],
   "source": [
    "simple_responses_agent = SimpleResponsesAgent()\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(\n",
    "        python_model=simple_responses_agent,\n",
    "        name=\"agent\",\n",
    "        registered_model_name=\"agent\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3bdfe-4efe-4110-ab66-f0e7402337ca",
   "metadata": {},
   "source": [
    "The following cell loads just registered model. And executes it's `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a76a3b-5d02-41e6-b9bb-37de0c77e391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'response',\n",
       " 'output': [{'type': 'message',\n",
       "   'id': 'msg_1',\n",
       "   'content': [{'text': 'The result of 4 * 3 in Python is 12.',\n",
       "     'type': 'output_text'}],\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(\"models:/agent@latest\")\n",
    "model.predict(\n",
    "    {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"what is 4*3 in python\"}],\n",
    "        \"context\": {\"conversation_id\": \"123\", \"user_id\": \"456\"},\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}