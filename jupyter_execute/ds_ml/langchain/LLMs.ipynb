{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d73836b",
   "metadata": {},
   "source": [
    "# LLMs\n",
    "\n",
    "This page considers LangChain interfaces for LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1270a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model=\"llama3.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63404c8f-186c-44a3-a277-a394a8272602",
   "metadata": {},
   "source": [
    "## Invoke\n",
    "\n",
    "The `invoke` method triggers the request to LLM.\n",
    "\n",
    "In most cases, it returns an `AIMessage`, but in some special cases, it can return some special output. For example, structured output langchain object return `dict` or `Pydantic.BaseModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860106d-14cd-4faf-b36d-7ef6545eb48b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell shows the kind of object `langchain_core.language_models.BaseChatModel` heir returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98213b78-2163-4e68-b1ae-bdb5df8c43a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-12-02T11:01:41.276856893Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2137074106, 'load_duration': 156799771, 'prompt_eval_count': 12, 'prompt_eval_duration': 712669661, 'eval_count': 10, 'eval_duration': 1258515574, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--4d37563e-bae5-4187-bbe2-7e7ccae56dea-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0c115",
   "metadata": {},
   "source": [
    "## Structured ouput\n",
    "\n",
    "Some providers support the structured output. The model will return the data in the specified format.\n",
    "\n",
    "To specify the model to follow the specified format, use the `with_strucutred_ouput` method. It returns the modified chat object that will follow specified rules. \n",
    "\n",
    "Check if the provider supports structured ouput in the JSON mode column of the [provided features](https://docs.langchain.com/oss/python/integrations/chat#featured-providers) section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c22e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell illustrates how the the user characteristics are extracted from the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3957c81c-c0cd-40e2-a10d-ba1d34a8c123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(id='777', name='llm_lover')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    id: str\n",
    "    name: str\n",
    "\n",
    "structured_model = model.with_structured_output(MyModel)\n",
    "response = structured_model.invoke(\n",
    "    \"Extract data: 'User llm_lover with id 777 tries to acess the database.'\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff41534-477f-4431-9620-fd75ff083953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! It looks like you might have accidentally typed \"helloq\" instead of \"hello\". Is there something I can help you with today?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-12-02T10:40:06.669223683Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4541564343, 'load_duration': 151402683, 'prompt_eval_count': 12, 'prompt_eval_duration': 163564374, 'eval_count': 30, 'eval_duration': 4199649693, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--ca2af690-bf99-40d7-b952-0de359a374bc-0', usage_metadata={'input_tokens': 12, 'output_tokens': 30, 'total_tokens': 42})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import AIMessage\n",
    "model.invoke(\"hello\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}