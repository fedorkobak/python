
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Tensor &#8212; Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'torch/tensor';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Creating methods" href="tensor/creating_methods.html" />
    <link rel="prev" title="Intro" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Python - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="Python - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Python
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Core</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../core/intro.html">Intro</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../core/syntax.html">Syntax</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core/syntax/operators.html">Operators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/operators/order.html">Order</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core/syntax/keywords.html">Keywords</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/keywords/in.html">Is in array (in)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/keywords/yield.html">yield</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core/syntax/functions.html">Functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/functions/parameters.html">Parameters</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core/syntax/oop.html">OOP</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/oop/variables.html">Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/oop/inheritance.html">Inheritance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/oop/interface.html">Interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/oop/class_method.html">Class method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/oop/special_methods.html">Special methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/syntax/oop/special_attributes.html">Special attributes</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../core/syntax/exceptions.html">Exceptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core/syntax/decorators.html">Decorators</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../core/datatypes.html">Data types</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core/datatypes/basic.html">Basic</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../core/datatypes/basic/str.html">str</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/datatypes/basic/list.html">list</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/datatypes/basic/dict.html">dict</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/datatypes/basic/set.html">set</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../core/datatypes/datetime.html">Datetime</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../core/imports.html">Imports</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../core/imports/sys_path.html">sys.path list</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core/imports/from_package_import_all.html"><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">&lt;package&gt;</span> <span class="pre">import</span> <span class="pre">*</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../core/imports/find_module.html">Find module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core/imports/importlib.html">Importlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core/imports/relative_import.html">Relative import</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../core/files_folders.html">Files &amp; folders</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../core/files_folders/pathlib.html">Pathlib</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../core/data_classes.html">Data class</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../core/cli_arguments.html">Cli arguments</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../core/cli_arguments/argparse.html">Library <code class="docutils literal notranslate"><span class="pre">argparse</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../core/packages.html">Packages</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core/packages/pip.html">PIP</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../core/packages/pip/install_uninstall.html">Install &amp; uninstall</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../core/packages/pyproject_toml.html">Pyproject.toml</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core/packages/hatch.html">Hatch</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../core/interpreter.html">Interpreter</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../core/interpreter/build.html">Build</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Standard library</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../standard_library/collections.html">collections</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../standard_library/unittest.html">Unittest</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/unittest/run_tests.html">Run tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/unittest/run_before_after.html">Run code before/after</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/unittest/check_error.html">Check error (assertRaises)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../standard_library/unittest/mocking.html">Mocking</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../standard_library/unittest/mocking/call_details.html">Call details</a></li>
<li class="toctree-l3"><a class="reference internal" href="../standard_library/unittest/mocking/syntax.html">Syntax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../standard_library/unittest/mocking/patch.html">Patch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../standard_library/unittest/mocking/raising_errors.html">Raising errors</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../standard_library/logging.html">Logging</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/logging/loggers.html">Loggers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/logging/handlers.html">Handlers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/logging/filters.html">Filters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/logging/configuration.html">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/logging/exception_information.html">Exceptions information</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/logging/logging_to_file.html">Logging to file</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/logging/logger_handler_level.html">Logger/Handler level</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/logging/root_logger.html">Root logger</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../standard_library/type_annotations.html">Type annotations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/type_annotations/annotation_cases.html">Annotation cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/type_annotations/mypy.html">Mypy</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../standard_library/re.html">re</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/re/match_search.html">Match/Search</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../standard_library/concurrency.html">Concurrency</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../standard_library/concurrency/multiprocessing.html">Multiprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../standard_library/concurrency/multiprocessing/pool.html">Pool</a></li>
<li class="toctree-l3"><a class="reference internal" href="../standard_library/concurrency/multiprocessing/start_methods.html">Start methods</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../standard_library/concurrency/threading.html">Threading</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../standard_library/hashlib.html">Hashlib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../standard_library/zipfile.html">Zipfile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../standard_library/socket.html">Socket</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Pandas</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../pandas/intro.html">Intro</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../pandas/data_types.html">Data types</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../pandas/data_types/datetime.html">datetime</a></li>




<li class="toctree-l2"><a class="reference internal" href="../pandas/data_types/columns_by_types.html">Columns by types</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas/creating_loading.html">Creating &amp; loading</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../pandas/data_transformations.html">Data transformations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../pandas/data_transformations/groupby.html">Groupby</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../pandas/data_transformations/groupby/usage_options.html">Usage options</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas/data_selecting.html">Data selecting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas/data_visualisation.html">Data visualisation</a></li>


<li class="toctree-l1"><a class="reference internal" href="../pandas/styles.html">Styles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas/display_options.html">Display options</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas/inline_columns_add.html">Inline column add (assign)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Scikit-learn</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../sklearn/intro.html">Intro</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sklearn/data_transform.html">Data transform</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sklearn/data_transform/pipeline.html">Pipeline</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../sklearn/data_transform/pipeline/features_names.html">Features names</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../sklearn/data_transform/pipeline/memory_parameter.html"><code class="docutils literal notranslate"><span class="pre">memory</span></code> parameter(chacing)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sklearn/data_transform/columns_transformer.html">Specific processing for column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sklearn/data_transform/features_names_out.html">Features names out</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sklearn/data_transform/encoders.html">Encoders</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sklearn/data_transform/developing_transformer.html">Developing transformer</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../sklearn/data_transform/developing_transformer/features_names_out.html">Feature names out</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../sklearn/data_transform/frozen_steps.html">Frozen steps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sklearn/data_transform/estimator_to_transformer.html">Estimator to transformer</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../sklearn/grid_search_cv.html">Grid search CV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sklearn/saving_models.html">Saving models</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sklearn/nearest_neighbors.html">Nearest neighbors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../sklearn/nearest_neighbors/metric.html">Metric</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Torch</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Intro</a></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Tensor</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="tensor/creating_methods.html">Creating methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="tensor/creating_methods/random_distributions.html">Random distributions</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="tensor/dimentionality.html">Dimentionality</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="tensor/dimentionality/reshape_like.html">Reshape like</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensor/dimentionality/transpose_permute.html">Transpose/permute</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensor/dimentionality/add_dimention.html">Add dimention</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensor/dimentionality/squeeze.html">Squeeze</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="tensor/concatenation_splitting.html">Concatenation/splitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor/indexing.html">Indexing</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor/broadcasting.html">Broadcasting</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="loss_functions.html">Loss functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="gradient.html">Gradient</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="layers.html">Layers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="layers/linear.html">Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="layers/dropout.html">Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="layers/normalisation_layers.html">Normalisation layers</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="layers/recurrent_layers.html">Recurrent layers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="layers/recurrent_layers/forward_input.html">Forward input</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="layers/flatten_unflatten.html">Flatten/unflatten</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="managing_network.html">Managing network</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="managing_network/sequential.html">Sequential</a></li>
<li class="toctree-l2"><a class="reference internal" href="managing_network/saving_model.html">Saving model</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="devices.html">Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_primitives.html">Data primitives</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="vision.html">Vision</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="vision/basic.html">Basic</a></li>
<li class="toctree-l2"><a class="reference internal" href="vision/augmentations.html">Augmentations</a></li>
<li class="toctree-l2"><a class="reference internal" href="vision/datasets.html">Datasets</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="examples/logistic_regression.html">Logistic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/multiclass_task.html">Multiclass task</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/texts_classification.html">Text classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/mnist.html">MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/symbols_classification.html">Symbols classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/resnet_finetuning.html">Resnet finetuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/cnn_classification.html">CNN classification</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="examples/unet.html">Unet</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="examples/unet/oxford_pet.html">Oxford pet</a></li>
<li class="toctree-l3"><a class="reference internal" href="examples/unet/voc_segmentation.html">Voc segmentation</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="examples/gan.html">GAN</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/conditional_gan.html">Conditional GAN</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FastAPI</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../fastapi/intro.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fastapi/run_application.html">Run application</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../fastapi/requests.html">Requests</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../fastapi/requests/request_object.html">Request object</a></li>
<li class="toctree-l2"><a class="reference internal" href="../fastapi/requests/pydantic_model.html">Pydantic model</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../fastapi/responses.html">Responses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../fastapi/responses/json.html">JSON</a></li>
<li class="toctree-l2"><a class="reference internal" href="../fastapi/responses/exceptions.html">Exceptions</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../fastapi/logging.html">Logging</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../fastapi/documentation.html">Documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../fastapi/documentation/parameters.html">Parameters</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../fastapi/cache.html">Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fastapi/cors.html">CORS</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Visualisation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../visualisation/matplotlib.html">Matplotlib</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../visualisation/matplotlib/table_in_matplotlib.html">matplotlib tables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualisation/matplotlib/gif_creation.html">Gif creation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../visualisation/plotly.html">Plotly</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../visualisation/plotly/hovers.html">Hovers</a></li>

<li class="toctree-l2"><a class="reference internal" href="../visualisation/plotly/dragmode.html">Dragmode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualisation/plotly/color_from_scheme.html">Color from scheme</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../visualisation/dash.html">Dash</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../visualisation/dash/callbacks.html">Callbacks</a></li>





<li class="toctree-l2"><a class="reference internal" href="../visualisation/dash/components.html">Components</a></li>





<li class="toctree-l2"><a class="reference internal" href="../visualisation/dash/select_clear_all.html">Select/Clear All</a></li>


<li class="toctree-l2"><a class="reference internal" href="../visualisation/dash/multipage_applications.html">Multipage applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../visualisation/dash/empty_figure.html">Empty figure</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SQL</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../sql/psycopg.html">Psycopg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sql/clickhouse.html">Clickhouse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sql/sqlite.html">sqlite</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sql/sqlalchemy.html">SQLAlchemy</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../sql/sqlalchemy/metadata.html">Metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sql/sqlalchemy/create_table.html">Create table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sql/sqlalchemy/query.html">Query</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sql/sqlalchemy/add_record.html">Add record</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sql/sqlalchemy/relations.html">Relations</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Packages</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/numpy.html">Numpy</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages/numpy/norm.html">Norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/numpy/array_splitting.html">Array splitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/numpy/apply_along_axis.html">Apply along axis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/numpy/set_printoptions.html">Print options</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../packages/excel_export.html">To excel import</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/jupyter.html">Jupyter</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../packages/jupyter/ipython.html">IPython</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../packages/jupyter/ipython/syntax.html">Syntax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../packages/jupyter/ipython/reloading_modules.html">Reload modules</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../packages/jupyter/kernel.html">Kernel</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../packages/jupyter/kernel/run_from_jupyter.html">Run from jupyter</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/jupyter/client.html">Client</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../packages/jupyter/traitlets.html">Traitlets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../packages/jupyter/traitlets/application.html">Application</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../packages/jinja.html">Jinja</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/docker_sdk.html">Docker SDK</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages/docker_sdk/containers.html">Containers</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/transformers.html">Transformers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages/transformers/pipeline.html">Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/transformers/tokenizer.html">Tokenizer</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../packages/apscheduler.html">APScheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../packages/selenium.html">Selenium</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/ranx.html">Ranx</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages/ranx/entry_queries_documents.html">Queries documents entry</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../packages/tqdm.html">TQDM</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/redis.html">Redis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages/redis/redis_client.html">Redis client</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../packages/surprise.html">Surprise</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/airflow.html">Airflow</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages/airflow/run_airflow.html">Run airflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/airflow/tutorial_dag.html">Tutorial DAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/airflow/tasks.html">Tasks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/geopy.html">Geopy</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages/geopy/distances.html">Distances</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/geopy/request.html">Request</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../packages/requests.html">Requests</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/mlflow.html">MLflow</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages/mlflow/example_of_use.html">Example of usе</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/mlflow/deploy.html">Deploy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/mlflow/custom_model.html">Custom model</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../packages/tkinter.html">Tkinter</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../packages/tkinter/widgets_overview.html">Widgets overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../packages/tkinter/widgets_overview/scrolling.html">Scrolling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../packages/tkinter/widgets_overview/treeview.html">Treeview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../packages/tkinter/widgets_overview/list_box.html">Listbox</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/tkinter/pack.html">Pack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages/tkinter/change_elements_position.html">Change elements position</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../packages/langchain.html">LangChain</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/fedorkobak/knowledge" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/torch/tensor.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Tensor</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-tensor">Create tensor</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimentionality">Dimentionality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing">Indexing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#element-wise-operations">Element-wise operations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting">Broadcasting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algebraic-operations">Algebraic operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-type">Data type</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inplace-methods">Inplace methods</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aggregations">Aggregations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concatenation-splitting">Concatenation/splitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gather">Gather</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="tensor">
<h1>Tensor<a class="headerlink" href="#tensor" title="Link to this heading">#</a></h1>
<p>Here is a description of the basic data type in PyTorch: <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">prod</span>
</pre></div>
</div>
</div>
</div>
<section id="create-tensor">
<h2>Create tensor<a class="headerlink" href="#create-tensor" title="Link to this heading">#</a></h2>
<p>Torch has tons of methods to create tensors. <a class="reference internal" href="tensor/creating_methods.html"><span class="std std-doc">This page</span></a> lists the methods I know for now.</p>
<hr class="docutils" />
<p>The most <strong>straightforward</strong> way is to use <code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[ 0.0000e+00,  0.0000e+00,  1.4013e-45,  0.0000e+00,  1.4013e-45],
         [ 0.0000e+00,  9.1084e-44,  0.0000e+00, -3.7852e+06,  3.3707e-41]],

        [[-7.6466e+07,  3.3707e-41,  4.4842e-44,  0.0000e+00,  4.4842e-44],
         [ 0.0000e+00,  6.3884e-27,  3.3703e-41,  0.0000e+00,  1.4013e-45]],

        [[ 1.3004e-42,  0.0000e+00,  1.1210e-43,  0.0000e+00,  6.4326e-27],
         [ 3.3703e-41,  4.2427e-08,  1.2964e+16,  2.1707e-18,  7.0952e+22]]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="dimentionality">
<h2>Dimentionality<a class="headerlink" href="#dimentionality" title="Link to this heading">#</a></h2>
<p>One of the most important properties of the tensor is it’s dimensionality. Torch provides a set of tools to manage tensor dimensionality. Find out more on the <a class="reference internal" href="tensor/dimentionality.html"><span class="std std-doc">dedicated page</span></a>.</p>
<p>This section overviews tools that allows to work with diemntionality of the tensors. They are listed in the follwing table:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Function/Method</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">shape</span></code></p></td>
<td><p>Returns the shape (dimensions) of a tensor as a tuple.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">reshape</span></code></p></td>
<td><p>Changes the shape of a tensor while preserving its data. The number of elements must remain the same.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">transpose</span></code></p></td>
<td><p>Permutes the dimensions of a tensor. Useful for switching axes, like converting between column-major and row-major.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">squeeze</span></code></p></td>
<td><p>Removes dimensions of size 1 from a tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">unsqueeze</span></code></p></td>
<td><p>Adds a dimension of size 1 at the specified position, effectively increasing the tensor’s rank.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">pad</span></code></p></td>
<td><p>Adds padding to a tensor along specified dimensions. Useful in tasks like image processing.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<p>The following cell shows the usage of <code class="docutils literal notranslate"><span class="pre">torch.Tensor.shape</span></code> to print the dimensionality of the tensor and <code class="docutils literal notranslate"><span class="pre">torch.Tensor.reshape</span></code> to change the dimensionality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;torch.Tensor.shape&#39;</span><span class="p">,</span> <span class="n">test_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">test_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Tensor.shape torch.Size([2, 5, 3])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="indexing">
<h2>Indexing<a class="headerlink" href="#indexing" title="Link to this heading">#</a></h2>
<p>Indexing in <code class="docutils literal notranslate"><span class="pre">torch</span></code> supports all the classic condepts, just like in <code class="docutils literal notranslate"><span class="pre">numpy</span></code> or <code class="docutils literal notranslate"><span class="pre">pandas</span></code>. But there are some features specific for <code class="docutils literal notranslate"><span class="pre">torch</span></code> findout more in the <a class="reference internal" href="tensor/indexing.html"><span class="std std-doc">specific page</span></a>.</p>
<hr class="docutils" />
<p>The following example shows the most basic methods of indexing in Torch. For the first dimensionality it takes all available elements, for the second it takes the slice <code class="docutils literal notranslate"><span class="pre">0:5:2</span></code> and along the last dimensionality it takes the elements counted in <code class="docutils literal notranslate"><span class="pre">list</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dimentionality</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">experimental</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">prod</span><span class="p">(</span><span class="n">dimentionality</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dimentionality</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original tensor&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">experimental</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sliced tensor&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">experimental</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original tensor
tensor([[[ 0,  1,  2,  3,  4,  5],
         [ 6,  7,  8,  9, 10, 11],
         [12, 13, 14, 15, 16, 17],
         [18, 19, 20, 21, 22, 23],
         [24, 25, 26, 27, 28, 29],
         [30, 31, 32, 33, 34, 35]],

        [[36, 37, 38, 39, 40, 41],
         [42, 43, 44, 45, 46, 47],
         [48, 49, 50, 51, 52, 53],
         [54, 55, 56, 57, 58, 59],
         [60, 61, 62, 63, 64, 65],
         [66, 67, 68, 69, 70, 71]]])
Sliced tensor
tensor([[[ 5,  1,  4],
         [17, 13, 16],
         [29, 25, 28]],

        [[41, 37, 40],
         [53, 49, 52],
         [65, 61, 64]]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="element-wise-operations">
<h2>Element-wise operations<a class="headerlink" href="#element-wise-operations" title="Link to this heading">#</a></h2>
<p>There is a class of operations in Pytorch that are applied element by element - we’ll call them element wise operations.</p>
<p>The following table lists most of them and corresponding to them operators.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Operation</strong></p></th>
<th class="head"><p><strong>Function</strong></p></th>
<th class="head"><p><strong>Operator</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Addition</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.add(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">+</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Subtraction</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.sub(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">-</span></code></p></td>
</tr>
<tr class="row-even"><td><p><strong>Multiplication</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.mul(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">*</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Division</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.div(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/</span></code></p></td>
</tr>
<tr class="row-even"><td><p><strong>Equality</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.eq(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">==</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Inequality</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.ne(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">!=</span></code></p></td>
</tr>
<tr class="row-even"><td><p><strong>Greater Than</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.gt(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&gt;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Less Than</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.lt(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;</span></code></p></td>
</tr>
<tr class="row-even"><td><p><strong>Greater or Equal</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.ge(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&gt;=</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Less or Equal</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.le(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;=</span></code></p></td>
</tr>
<tr class="row-even"><td><p><strong>Logical AND</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.logical_and(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&amp;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Logical OR</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.logical_or(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p>`</p></td>
</tr>
<tr class="row-even"><td><p><strong>Logical XOR</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.logical_xor(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">^</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Logical NOT</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.logical_not(tensor)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">~</span></code></p></td>
</tr>
<tr class="row-even"><td><p><strong>Exponentiation</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.pow(tensor1,</span> <span class="pre">tensor2)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">**</span></code> or <code class="docutils literal notranslate"><span class="pre">^</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Square Root</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.sqrt(tensor)</span></code></p></td>
<td><p>N/A</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<p>As a brief review, consider two matrices <span class="math notranslate nohighlight">\(A = [a_{ij}]_{n \times m}\)</span> and <span class="math notranslate nohighlight">\(B = [b_{ij}]_{n \times m}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">A</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-5, -2,  4,  0, -4],
        [-1, -4,  1, -5, -5],
        [-4,  1,  4, -5, -5],
        [-2,  2,  0,  1,  0]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">B</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-1, -3,  1, -4, -4],
        [-4,  4, -4, -4, -3],
        [ 3, -2,  0, -1,  0],
        [ 4, -2,  0,  2,  1]])
</pre></div>
</div>
</div>
</div>
<p>By applying the <code class="docutils literal notranslate"><span class="pre">+</span></code> operator to matrices we got the matrix <span class="math notranslate nohighlight">\(\left[a_{ij} + b_{ij}\right]_{n \times m}\)</span> - so the operation was applied element by element.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">+</span> <span class="n">B</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-6, -5,  5, -4, -8],
        [-5,  0, -3, -9, -8],
        [-1, -1,  4, -6, -5],
        [ 2,  0,  0,  3,  1]])
</pre></div>
</div>
</div>
</div>
<section id="broadcasting">
<h3>Broadcasting<a class="headerlink" href="#broadcasting" title="Link to this heading">#</a></h3>
<p>Element-wise operations in PyTorch support the incredibly convenient concept of <strong>broadcasting</strong>, allowing you to apply these operations to arrays with different dimensionalities.</p>
<hr class="docutils" />
<p>As an example, consider two tensors with different dimensionality, <code class="docutils literal notranslate"><span class="pre">zero_tensor</span></code> and <code class="docutils literal notranslate"><span class="pre">arange_tensor</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">zero_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">zero_tensor</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">arange_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">arange_tensor</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0, 1, 2, 3])
</pre></div>
</div>
</div>
</div>
<p>By applying the <code class="docutils literal notranslate"><span class="pre">+</span></code> operator to them, we got a result where each row of <code class="docutils literal notranslate"><span class="pre">zeros_tensor</span></code> was added <code class="docutils literal notranslate"><span class="pre">arange_tensor</span></code> element-wise.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">zero_tensor</span> <span class="o">+</span> <span class="n">arange_tensor</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0., 1., 2., 3.],
        [0., 1., 2., 3.],
        [0., 1., 2., 3.]])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="algebraic-operations">
<h2>Algebraic operations<a class="headerlink" href="#algebraic-operations" title="Link to this heading">#</a></h2>
<p>The following table lists algebraic operations on <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Operation</strong></p></th>
<th class="head"><p><strong>Function</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Matrix Multiplication</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.matmul()</span></code></p></td>
<td><p>Matrix multiplication</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">tensor1</span> <span class="pre">&#64;</span> <span class="pre">tensor2</span></code></p></td>
<td><p>Matrix multiplication using <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> operator</p></td>
</tr>
<tr class="row-even"><td><p>Singular Value Decomposition</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.svd()</span></code></p></td>
<td><p>Singular Value Decomposition (SVD)</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.svd()</span></code></p></td>
<td><p>SVD with advanced options</p></td>
</tr>
<tr class="row-even"><td><p>Eigenvalues and Eigenvectors</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.eig()</span></code></p></td>
<td><p>Compute eigenvalues and eigenvectors</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.eig()</span></code></p></td>
<td><p>Eigenvalues and eigenvectors (advanced)</p></td>
</tr>
<tr class="row-even"><td><p>Matrix Inversion</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.inv()</span></code></p></td>
<td><p>Matrix inversion</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.inverse()</span></code></p></td>
<td><p>Matrix inversion (deprecated)</p></td>
</tr>
<tr class="row-even"><td><p>Matrix Norms</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.norm()</span></code></p></td>
<td><p>Compute the norm of a tensor</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.norm()</span></code></p></td>
<td><p>Norm with advanced options</p></td>
</tr>
<tr class="row-even"><td><p>Determinants</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.det()</span></code></p></td>
<td><p>Compute the determinant of a matrix</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.det()</span></code></p></td>
<td><p>Determinant with advanced options</p></td>
</tr>
<tr class="row-even"><td><p>Matrix Trace</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.trace()</span></code></p></td>
<td><p>Compute the trace of a matrix</p></td>
</tr>
<tr class="row-odd"><td><p>Eigenvalues</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.eigvals()</span></code></p></td>
<td><p>Compute eigenvalues of a square matrix</p></td>
</tr>
<tr class="row-even"><td><p>Matrix Rank</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.matrix_rank()</span></code></p></td>
<td><p>Compute the rank of a matrix</p></td>
</tr>
<tr class="row-odd"><td><p>Cholesky Decomposition</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.cholesky()</span></code></p></td>
<td><p>Cholesky decomposition</p></td>
</tr>
<tr class="row-even"><td><p>QR Decomposition</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.qr()</span></code></p></td>
<td><p>QR decomposition</p></td>
</tr>
<tr class="row-odd"><td><p>Solving Linear Systems</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.solve()</span></code></p></td>
<td><p>Solve a system of linear equations</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.linalg.lstsq()</span></code></p></td>
<td><p>Solve a least-squares problem</p></td>
</tr>
<tr class="row-odd"><td><p>Kronecker Product</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.kron()</span></code></p></td>
<td><p>Compute the Kronecker product</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="data-type">
<h2>Data type<a class="headerlink" href="#data-type" title="Link to this heading">#</a></h2>
<p>Torch has it’s own system of data types. Here is a table that describes the available datatypes.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.float16</span></code> / <code class="docutils literal notranslate"><span class="pre">torch.half</span></code></p></td>
<td><p>16-bit half precision (floating point)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.float32</span></code> / <code class="docutils literal notranslate"><span class="pre">torch.float</span></code></p></td>
<td><p>32-bit single precision (floating point)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.float64</span></code> / <code class="docutils literal notranslate"><span class="pre">torch.double</span></code></p></td>
<td><p>64-bit double precision (floating point)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.int8</span></code></p></td>
<td><p>8-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.int16</span></code> / <code class="docutils literal notranslate"><span class="pre">torch.short</span></code></p></td>
<td><p>16-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> / <code class="docutils literal notranslate"><span class="pre">torch.int</span></code></p></td>
<td><p>32-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.int64</span></code> / <code class="docutils literal notranslate"><span class="pre">torch.long</span></code></p></td>
<td><p>64-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.uint8</span></code></p></td>
<td><p>8-bit unsigned integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.bool</span></code></p></td>
<td><p>Boolean type</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.complex64</span></code></p></td>
<td><p>64-bit complex number (32-bit real and imaginary)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.complex128</span></code></p></td>
<td><p>128-bit complex number (64-bit real and imaginary)</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<p>You can get type of the tensor by using <code class="docutils literal notranslate"><span class="pre">dtype</span></code> field.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.float32
</pre></div>
</div>
</div>
</div>
<p><strong>Note</strong> there are some functions in torch that have <code class="docutils literal notranslate"><span class="pre">dtype</span></code> parameter. By passing special torch objects as <code class="docutils literal notranslate"><span class="pre">dtype</span></code> arguments, we can get tensors of the specific dtype.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([1., 2., 3.], dtype=torch.float16)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], dtype=torch.float16)
</pre></div>
</div>
</div>
</div>
</section>
<section id="inplace-methods">
<h2>Inplace methods<a class="headerlink" href="#inplace-methods" title="Link to this heading">#</a></h2>
<p>Some methods of <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> allow you to change the value of the tensor on the fly. It’s typical for such methods to have the underscore symbol <code class="docutils literal notranslate"><span class="pre">_</span></code> at the end of the name.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">add_</span></code></p></td>
<td><p>Adds the input tensor to the current tensor in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">addcmul_</span></code></p></td>
<td><p>Performs a component-wise multiplication of two tensors and adds the result to the current tensor in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">addcdiv_</span></code></p></td>
<td><p>Performs a component-wise division of two tensors and adds the result to the current tensor in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">bernoulli_</span></code></p></td>
<td><p>Applies the Bernoulli distribution to the tensor in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">bmm_</span></code></p></td>
<td><p>Performs batch matrix multiplication in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">clamp_</span></code></p></td>
<td><p>Clamps all elements in the input tensor to be within the specified range, in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">copy_</span></code></p></td>
<td><p>Copies data from another tensor to the current tensor in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">div_</span></code></p></td>
<td><p>Divides the current tensor by the input tensor in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">fill_</span></code></p></td>
<td><p>Fills the tensor with the specified value in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">flatten_</span></code></p></td>
<td><p>Flattens the tensor to a 1D tensor in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">index_add_</span></code></p></td>
<td><p>Adds values to the tensor at specified indices in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">index_fill_</span></code></p></td>
<td><p>Fills the tensor at specified indices with the given value in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">index_copy_</span></code></p></td>
<td><p>Copies values from another tensor into the current tensor at specified indices, in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mask_fill_</span></code></p></td>
<td><p>Fills elements of the tensor where the mask is <code class="docutils literal notranslate"><span class="pre">True</span></code> with the specified value in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mask_scatter_</span></code></p></td>
<td><p>Scatters values into the tensor at indices specified by the mask in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">masked_fill_</span></code></p></td>
<td><p>Fills elements of the tensor where the mask is <code class="docutils literal notranslate"><span class="pre">True</span></code> with the specified value in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">masked_scatter_</span></code></p></td>
<td><p>Scatters values into the tensor where the mask is <code class="docutils literal notranslate"><span class="pre">True</span></code> in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">neg_</span></code></p></td>
<td><p>Negates the tensor’s values in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">normal_</span></code></p></td>
<td><p>Fills the tensor with random numbers from a normal distribution in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">relu_</span></code></p></td>
<td><p>Applies the ReLU activation function in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">renorm_</span></code></p></td>
<td><p>Renormalizes the tensor along a specified dimension in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">scatter_</span></code></p></td>
<td><p>Scatters values into the tensor at specified indices in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">select_</span></code></p></td>
<td><p>Selects a sub-tensor in place (used for slicing).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">set_</span></code></p></td>
<td><p>Sets tensor values based on other tensors or values in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sigmoid_</span></code></p></td>
<td><p>Applies the sigmoid function in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">softmax_</span></code></p></td>
<td><p>Applies the softmax function in place along a specified dimension.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sub_</span></code></p></td>
<td><p>Subtracts the input tensor from the current tensor in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">t_</span></code></p></td>
<td><p>Transposes the tensor in place (2D tensors only).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">transpose_</span></code></p></td>
<td><p>Transposes the tensor along specified dimensions in place.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">truncate_</span></code></p></td>
<td><p>Truncates tensor values to a specified precision in place.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">zero_</span></code></p></td>
<td><p>Sets all elements of the tensor to zero in place.</p></td>
</tr>
</tbody>
</table>
</div>
<p>Here is an example of applying the <code class="docutils literal notranslate"><span class="pre">relu</span></code> transformation to the tensor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">my_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">my_tensor</span><span class="o">.</span><span class="n">relu_</span><span class="p">()</span>
<span class="n">my_tensor</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000,
        0.8000, 0.9000])
</pre></div>
</div>
</div>
</div>
</section>
<section id="aggregations">
<h2>Aggregations<a class="headerlink" href="#aggregations" title="Link to this heading">#</a></h2>
<p>Torch provides several aggregation methods, which reduce an array of numbers to a single value. The following table shows some of the methods.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">min()</span></code></p></td>
<td><p>Returns the minimum value of all elements in the tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">max()</span></code></p></td>
<td><p>Returns the maximum value of all elements in the tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">argmin()</span></code></p></td>
<td><p>Returns the index of the minimum value.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">argmax()</span></code></p></td>
<td><p>Returns the index of the maximum value.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sum()</span></code></p></td>
<td><p>Returns the sum of all elements in the tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mean()</span></code></p></td>
<td><p>Returns the mean of all elements in the tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">median()</span></code></p></td>
<td><p>Returns the median value of elements in the tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">prod()</span></code></p></td>
<td><p>Returns the product of all elements in the tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">std()</span></code></p></td>
<td><p>Returns the standard deviation of the tensor elements.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">var()</span></code></p></td>
<td><p>Returns the variance of the tensor elements.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">all()</span></code></p></td>
<td><p>Tests if all elements evaluate to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">any()</span></code></p></td>
<td><p>Tests if any element evaluates to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<p>The following cell generates a Torch matrix where each row has larger average elements than the previous one. We’ll use this array to explore the principles of aggregation methods in Torch.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)],</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(23.6230)
</pre></div>
</div>
</div>
</div>
<p>Applying the <code class="docutils literal notranslate"><span class="pre">sum</span></code> method to the array returns a zero-dimensional tensor representing the sum of all elements in the tensor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(3794.5530)
</pre></div>
</div>
</div>
</div>
<p>After specifying the <code class="docutils literal notranslate"><span class="pre">dim</span></code> parameter, the aggregation will occur along the chosen axis. The following cell aggregates each row.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([-16.4698,   9.2714,  31.5841,  59.7604,  78.6830, 102.7903, 139.8927,
        122.9686, 162.2701, 190.2476, 211.2355, 211.3985, 243.5579, 275.2428,
        262.9107, 298.6805, 310.6557, 327.2797, 371.0268, 401.5668])
</pre></div>
</div>
</div>
</div>
<p>As a result, we obtained an array where each element is larger than the previous one—this aligns with the principles we used during the generation process.</p>
</section>
<section id="concatenation-splitting">
<h2>Concatenation/splitting<a class="headerlink" href="#concatenation-splitting" title="Link to this heading">#</a></h2>
<p>There is a bunch of options that allows to consider set of tensors as unified tensor or vise versa difide one big tensor in to smaller pieces. All these functions have a bit different functional. Find out more in the <a class="reference internal" href="tensor/concatenation_splitting.html"><span class="std std-doc">particual page</span></a>.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.stack</span></code></p></td>
<td><p>Concatenates tensors along a new dimension.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.cat</span></code></p></td>
<td><p>Concatenates tensors along an existing dimension.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.vstack</span></code></p></td>
<td><p>Stacks tensors vertically (along the first dimension).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.hstack</span></code></p></td>
<td><p>Stacks tensors horizontally (along the last dimension).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.dstack</span></code></p></td>
<td><p>Stacks tensors along a new third dimension (for 2D tensors, stacks along depth).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.chunk</span></code></p></td>
<td><p>Splits a tensor into a specified number of chunks along a given dimension.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.split</span></code></p></td>
<td><p>Splits a tensor into sub-tensors based on a list of sizes along a specified dimension.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.repeat</span></code></p></td>
<td><p>Repeats a tensor along specified dimensions to increase its size.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<p>As an example, consider the tensor created in the following cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nb">input</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.7793, -0.2321, -1.1366],
        [ 0.4977, -0.3425,  1.0177],
        [ 0.1320,  0.8735, -1.2108]])
</pre></div>
</div>
</div>
</div>
<p>Using <code class="docutils literal notranslate"><span class="pre">torch.chunk</span></code>, the tensor can be transformed into a tuple of smaller tensors, where each tensor represents a line from the original tensor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chunks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">chunks</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([[1.1286, 0.5528, 0.7930]]),
 tensor([[-1.9157,  0.3871, -0.5575]]),
 tensor([[ 0.6818,  0.2752, -1.2651]]))
</pre></div>
</div>
</div>
</div>
<p>Using <code class="docutils literal notranslate"><span class="pre">torch.stack</span></code>, we can join the smaller tensors back into one tensor, but now along a new axis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[ 1.1286,  0.5528,  0.7930]],

        [[-1.9157,  0.3871, -0.5575]],

        [[ 0.6818,  0.2752, -1.2651]]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="gather">
<h2>Gather<a class="headerlink" href="#gather" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">torch.gather</span></code> fucntion allows to select some values of the input tensor by indices and speciyf output form.</p>
<p>Some notations are required for a more precise description:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X\)</span>: input tensor of shape <span class="math notranslate nohighlight">\((s_0, s_1, \dots, s_{n-1})\)</span>.</p></li>
<li><p>An index tesnsor <span class="math notranslate nohighlight">\(I\)</span> and output tensor <span class="math notranslate nohighlight">\(O\)</span>: both having dimentions <span class="math notranslate nohighlight">\((s'_0, s'_1, \dots, s'_{n-1})\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(dim\)</span>: specified dimentions of the input to which will be substituted indeces from <span class="math notranslate nohighlight">\(I\)</span>.</p></li>
</ul>
<p>Operation can be written:</p>
<div class="math notranslate nohighlight">
\[O \left[i_0, i_1, \dots, i_{n-1} \right] = X\left[ i_0, i_1, \dots, i_{dim-1}, I\left[i_0, i_1, \dots, i_{n-1} \right], i_{dim+1}, \dots, i_{n-1} \right]\]</div>
<p>So values from <span class="math notranslate nohighlight">\(I\)</span> is substituted to the <span class="math notranslate nohighlight">\(dim\)</span> index of the <span class="math notranslate nohighlight">\(X\)</span>, it formulates <span class="math notranslate nohighlight">\(O\)</span>.</p>
<hr class="docutils" />
<p>Consider example:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}
X = \left( \begin{array}{cc}
    1&amp;2&amp;3 \\ 
    4&amp;5&amp;6
\end{array}
\right),\end{split}\\\begin{split}I = \left( \begin{array}{cc}
    0&amp;1 \\ 
    1&amp;2
\end{array}
\right),\end{split}\\dim=1
\end{aligned}\end{align} \]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">])</span>

<span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1., 2.],
        [5., 6.]])
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(dim=1\)</span> so that all <span class="math notranslate nohighlight">\(I\)</span> indices are replaced by the corresponding index of <span class="math notranslate nohighlight">\(X\)</span> and form the same shape <span class="math notranslate nohighlight">\(O\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
O = \left( \begin{array}{cc}
    X[0, I[0,0]]&amp;X[0, I[0,1]] \\ 
    X[1, I[1,0]]&amp;X[1, I[1,1]]
\end{array}
\right)
= \left( \begin{array}{cc}
    X[0, 0]&amp;X[0, 1] \\ 
    X[1, 1]&amp;X[1, 2]
\end{array}
\right)
= \left( \begin{array}{cc}
    1&amp;2 \\ 
    5&amp;6
\end{array}
\right)
\end{split}\]</div>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./torch"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Intro</p>
      </div>
    </a>
    <a class="right-next"
       href="tensor/creating_methods.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Creating methods</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-tensor">Create tensor</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimentionality">Dimentionality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing">Indexing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#element-wise-operations">Element-wise operations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting">Broadcasting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algebraic-operations">Algebraic operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-type">Data type</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inplace-methods">Inplace methods</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aggregations">Aggregations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concatenation-splitting">Concatenation/splitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gather">Gather</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Fedor Kobak
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>