{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e78e44c-98cc-4059-8ae6-72fb058cabf4",
   "metadata": {
    "id": "6e78e44c-98cc-4059-8ae6-72fb058cabf4"
   },
   "source": [
    "# Managing network\n",
    "\n",
    "Is a class that allows you to define complex neural networks in Torch. Simply use this class as a descendant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb58b03-6c03-4bf4-bed2-be16d2fc2287",
   "metadata": {
    "id": "7cb58b03-6c03-4bf4-bed2-be16d2fc2287"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from pathlib import Path\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b3b93",
   "metadata": {
    "id": "b89b3b93"
   },
   "source": [
    "## Sequential\n",
    "\n",
    "You can use `torch.nn.Sequential` to combine multiple network layers into a sequential chain. Find out more in the [specific page](managing_network/sequential.ipynb).\n",
    "\n",
    "---\n",
    "\n",
    "The following cell demonstrates a basic example where a linear transformation is applied to the input, followed by a ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329df276",
   "metadata": {
    "id": "329df276",
    "outputId": "c1e0ae45-77df-49ac-f646-a9416d80458a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.8781],\n",
       "        [0.4362, 0.0000, 0.7350],\n",
       "        [0.0000, 0.0000, 1.1225]], grad_fn=<ReluBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 3\n",
    "\n",
    "sequential = torch.nn.Sequential(\n",
    "    torch.nn.Linear(size, size, bias=False),\n",
    "    torch.nn.ReLU()\n",
    ")\n",
    "\n",
    "X = torch.randn([3, 3])\n",
    "sequential(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5b73f",
   "metadata": {
    "id": "87b5b73f"
   },
   "source": [
    "## Separate class\n",
    "\n",
    "You can define a neural network as a separate class, which allows you to add custom logic for initialization or network-specific procedures. To create a network class, follow these rules:\n",
    "\n",
    "- **Inherit from `torch.nn.Module`:** This establishes your class as a PyTorch module, providing access to its functionality.\n",
    "- **Call `super().__init__()` in the constructor:** This initializes the base `nn.Module` class, ensuring proper setup.\n",
    "- **Define a `forward` method:** This method implements the computational procedure of your network. It defines how input data flows through your layers to produce output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28f6b2",
   "metadata": {
    "id": "2b28f6b2"
   },
   "source": [
    "---\n",
    "\n",
    "The following cell defines a set of Linear layers whose size is determined during class creation. The forward method standardizes the data before applying the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc0fcf",
   "metadata": {
    "id": "61dc0fcf"
   },
   "outputs": [],
   "source": [
    "class ExampleNetwork(torch.nn.Module):\n",
    "    def __init__(self, layers_number: int, neurons: int):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = torch.nn.Sequential(*[\n",
    "            torch.nn.Linear(neurons, neurons)\n",
    "            for i in range(layers_number)\n",
    "        ])\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        X = (X - X.mean(axis=0, keepdim=True))/X.std(axis=0, keepdim=True)\n",
    "        return self.network(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f24bf",
   "metadata": {
    "id": "0c6f24bf"
   },
   "source": [
    "Let's check if the network we've defined works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32c819",
   "metadata": {
    "id": "3e32c819",
    "outputId": "4dc56fd0-1e08-481c-f0b3-22fc8b6842fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2482,  0.0882,  0.4507],\n",
       "        [-0.2465,  0.0897,  0.4466],\n",
       "        [-0.2531,  0.0827,  0.4587],\n",
       "        [-0.2463,  0.0899,  0.4459],\n",
       "        [-0.2461,  0.0892,  0.4429]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ExampleNetwork(layers_number=10, neurons=3)(X = torch.randn([5, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0f9df-64a9-4613-98da-670e17eb8244",
   "metadata": {
    "id": "66b0f9df-64a9-4613-98da-670e17eb8244"
   },
   "source": [
    "## Parameters\n",
    "\n",
    "To be able to optimize network properly you need tools that allows to access paraterers and manage them. As this section we consider typical methods that help to manage model parameters in torch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f17636",
   "metadata": {
    "id": "28f17636"
   },
   "source": [
    "### Access parameters\n",
    "\n",
    "To access model parameters, use the `torch.nn.Module.parameters` method. This method returns a generator that iterates over the parameters of all layers in the network.\n",
    "\n",
    "Check the official [documentation on the `parameters` method](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7afce-4e96-4d41-b8c6-f5e7a328741d",
   "metadata": {
    "id": "e2d7afce-4e96-4d41-b8c6-f5e7a328741d"
   },
   "source": [
    "---\n",
    "\n",
    "In the following cell we have an empty `nn.Module` - so when we try to unpack it generator to list we have just an empty list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8022cb-2f1d-4a23-a29d-540946fa9cc7",
   "metadata": {
    "id": "ad8022cb-2f1d-4a23-a29d-540946fa9cc7",
    "outputId": "49a1dd18-f2fc-4e5d-92d2-ac4aa772d31f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmptyNetwork(nn.Module):\n",
    "    pass\n",
    "empty_network = EmptyNetwork()\n",
    "[i for i in empty_network.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f585fdc-cd8f-41f6-8075-57899c5a6d49",
   "metadata": {
    "id": "1f585fdc-cd8f-41f6-8075-57899c5a6d49"
   },
   "source": [
    "This cell implements such a descendant of the `nn.Module`, taking some parameters from its files. To be more specific, there are two fully connected layers defined here. So we end up with four tensors, two matrices for fully connected layers and their biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad4179-1ca1-4e10-a24a-3510f80c57f2",
   "metadata": {
    "id": "0bad4179-1ca1-4e10-a24a-3510f80c57f2",
    "outputId": "0f7c1db9-ea9c-4c06-920f-ba818fb005cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4889, -0.2448, -0.1750],\n",
      "        [ 0.0770, -0.0333,  0.2421],\n",
      "        [-0.0755, -0.2302, -0.4851]])\n",
      "tensor([ 0.1668, -0.5771,  0.4508])\n",
      "tensor([[ 0.1828, -0.3526, -0.3598,  0.4468, -0.2286],\n",
      "        [-0.0492,  0.3426,  0.2613,  0.2133, -0.2792],\n",
      "        [-0.2052,  0.2514,  0.0616,  0.4382, -0.2944],\n",
      "        [-0.2796, -0.0471, -0.4185,  0.4359,  0.2697],\n",
      "        [ 0.3577,  0.4372, -0.0179,  0.1575,  0.2003]])\n",
      "tensor([-0.4275,  0.0130,  0.4131, -0.2934,  0.3826])\n"
     ]
    }
   ],
   "source": [
    "class ParametersNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.foo = nn.Linear(3, 3)\n",
    "        self.bar = nn.Linear(5, 5)\n",
    "\n",
    "network = ParametersNetwork()\n",
    "for i in network.parameters():\n",
    "    print(i.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f1b6e",
   "metadata": {
    "id": "319f1b6e"
   },
   "source": [
    "### Requires grad\n",
    "\n",
    "You can manipulate the set of parameters that will compute gradients in a neural network. You can do this directly by accessing the parameters and setting their `requires_grad` attribute to `False`. However, there is a `requires_grad_()` method that allows you to set the gradient property for all weights of an `nn.Module`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e0d1e",
   "metadata": {
    "id": "a97e0d1e"
   },
   "source": [
    "---\n",
    "\n",
    "The following cell defines a network and prints the `requires_grad` attribute of its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8725953",
   "metadata": {
    "id": "b8725953",
    "outputId": "9920f9aa-8932-4590-fc21-69e4ab18a99c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight True\n",
      "0.bias True\n",
      "2.weight True\n",
      "2.bias True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=10, out_features=10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=10, out_features=1),\n",
    ")\n",
    "\n",
    "for name, parameters in model.named_parameters():\n",
    "    print(name, parameters.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb55d2",
   "metadata": {
    "id": "5ebb55d2"
   },
   "source": [
    "By default, all parameters require gradients. The following cell applies `requires_grad_(False)` to the entire network and then sets `requires_grad(True)` for just one of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8fb67",
   "metadata": {
    "id": "35a8fb67",
    "outputId": "6013b113-3ae4-4186-842d-bccdbc38aa30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight False\n",
      "0.bias False\n",
      "2.weight True\n",
      "2.bias True\n"
     ]
    }
   ],
   "source": [
    "model.requires_grad_(False)\n",
    "model[2].requires_grad_(True)\n",
    "\n",
    "for name, parameters in model.named_parameters():\n",
    "    print(name, parameters.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0718f659",
   "metadata": {
    "id": "0718f659"
   },
   "source": [
    "As a result, only the corresponding parameters will require gradients. During the optimization process, only those parameters that require gradients will be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661e99c",
   "metadata": {},
   "source": [
    "## Saving model\n",
    "\n",
    "Saving and loading PyTorch models is crucial because any model you build needs to be transferred and deployed in some way. Check the [official tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html). Here, we'll experiment with the options from the tutorial.\n",
    "\n",
    "There are various ways to save a Torch model:\n",
    "\n",
    "- Convert the model to a state dict and save the state dict.\n",
    "- Apply the `torch.save` function directly to the model.\n",
    "- Use TorchScript.\n",
    "\n",
    "All of these methods are discussed on the [specific page](managing_network/saving_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3ba64c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The preferred method is to save by converting the model into a state dict. The following code shows ways to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b886297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 3),\n",
    "    torch.nn.Linear(3, 3)\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    obj=model.state_dict(),\n",
    "    f=Path(\"/tmp\")/\"model.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d737e",
   "metadata": {},
   "source": [
    "Now, by using `torch.load`, you can extract the state dict you saved earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84513830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.4638, -0.0362, -0.3954],\n",
       "                      [-0.5537, -0.2766, -0.4095],\n",
       "                      [ 0.0272,  0.4614, -0.5757]])),\n",
       "             ('0.bias', tensor([-0.5566, -0.5410, -0.0075])),\n",
       "             ('1.weight',\n",
       "              tensor([[ 0.1332, -0.5475,  0.4317],\n",
       "                      [ 0.1927, -0.4506, -0.2670],\n",
       "                      [-0.3406, -0.4758,  0.4249]])),\n",
       "             ('1.bias', tensor([ 0.4226, -0.5480, -0.3352]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(f=Path(\"/tmp\")/\"model.pth\", weights_only=False)\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb9528b",
   "metadata": {},
   "source": [
    "When you have the state dict, you can easily load it into the model using `torch.nn.Module.load_state_dict`, as shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ba5b8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2df83",
   "metadata": {
    "id": "4fe2df83"
   },
   "source": [
    "## Copying model\n",
    "\n",
    "There are many cases where you will need to make a copy of a torch model. However, there are some issues associated with this. This section discusses those issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df780be",
   "metadata": {
    "id": "5df780be"
   },
   "source": [
    "---\n",
    "\n",
    "An obvious example is that copying through the `=` operator merely assigns a new name to the same object. The following cell creates a simple `torch.nn.Module` and displays its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a0c5ba",
   "metadata": {
    "id": "12a0c5ba",
    "outputId": "45620598-0b73-4432-db97-af46f1daa1e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3469,  0.2282, -0.4584],\n",
       "        [ 0.3923, -0.0788, -0.3660],\n",
       "        [ 0.3362, -0.4471, -0.4651]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(in_features=3, out_features=3, bias=False)\n",
    "next(iter(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17c01b9",
   "metadata": {
    "id": "a17c01b9"
   },
   "source": [
    "Now, suppose, you've made a copy of the model using the `=` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5983884d",
   "metadata": {
    "id": "5983884d"
   },
   "outputs": [],
   "source": [
    "copy_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0df74b",
   "metadata": {
    "id": "3d0df74b"
   },
   "source": [
    "Now, imagine the original object was edited in some way—the following cell assigns a matrix of ones to the parameters we saw before. The key point is that the parameters of the \"copy\" were also edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d878478",
   "metadata": {
    "id": "0d878478",
    "outputId": "e624c3cc-3099-4c44-aa46-df636e46467d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(model.parameters())).data = torch.ones(3, 3)\n",
    "next(iter(copy_model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941ee33",
   "metadata": {
    "id": "b941ee33"
   },
   "source": [
    "### Deep copy\n",
    "\n",
    "One option is to use the \"classical\" Python `copy.deepcopy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfb0ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell demonstrates that a copy made through `deepcopy` preserves all the properties of the original model at the moment of creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4ed1e73",
   "metadata": {
    "id": "b4ed1e73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0346, -0.4097,  0.0998],\n",
       "        [ 0.2439,  0.1766, -0.2577],\n",
       "        [-0.0638, -0.3555,  0.1458]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(in_features=3, out_features=3, bias=False)\n",
    "models_copy = deepcopy(model)\n",
    "next(iter(model.parameters())).data = torch.ones(3, 3)\n",
    "next(iter(models_copy.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1d808",
   "metadata": {},
   "source": [
    "**Note:** `deepcopy` will replicate the model on the device the original model is on. The following cell attempts to `deepcopy` a model on the GPU, and the copied model will also be on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "YG9p7ZSC4ElH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "YG9p7ZSC4ElH",
    "outputId": "94ef7ff4-a786-417b-bef4-edf43d10cd9c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(\n",
    "    in_features=3, \n",
    "    out_features=10, \n",
    "    bias=False\n",
    ").to(\n",
    "    device=torch.device(\"cuda\")\n",
    ")\n",
    "model_copy = deepcopy(model)\n",
    "next(iter(model_copy.parameters())).device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p8QfZUXO4qL0",
   "metadata": {
    "id": "p8QfZUXO4qL0"
   },
   "source": [
    "### State dict\n",
    "\n",
    "Another option is to recreate model and pass to `load_state_dict` of the recreated model, `state_dict` of the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef193e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In the following cell, this trick is demonstrated — `copy_model` still retains the parameters of the copied model as they were at the moment of copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d50a633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2850, -0.3748,  0.5246],\n",
       "        [ 0.0166, -0.5607, -0.5215],\n",
       "        [ 0.4310, -0.5429, -0.2672]], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(\n",
    "    in_features=3,\n",
    "    out_features=3,\n",
    "    bias=False\n",
    ")\n",
    "\n",
    "copy_model = torch.nn.Linear(\n",
    "    in_features=3,\n",
    "    out_features=3,\n",
    "    bias=False\n",
    ")\n",
    "copy_model.load_state_dict(model.state_dict())\n",
    "next(iter(model.parameters())).data = torch.zeros(3, 3)\n",
    "next(iter(copy_model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42add6b8",
   "metadata": {},
   "source": [
    "And there aren’t any issues with GPUs. The copied model will retain the device it had during creation — meaning the state dict will be loaded to the `cpu`, which is the preferable option in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "plyMto1s4vly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "plyMto1s4vly",
    "outputId": "b7fc8520-d405-4082-a81f-fa626c336378"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(\n",
    "    in_features=3,\n",
    "    out_features=10,\n",
    "    bias=False\n",
    ").to(device=torch.device(\"cuda\"))\n",
    "\n",
    "copy_model = torch.nn.Linear(\n",
    "    in_features=3,\n",
    "    out_features=10,\n",
    "    bias=False\n",
    ")\n",
    "copy_model.load_state_dict(state_dict=model.state_dict())\n",
    "next(iter(copy_model.parameters())).device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0ae49",
   "metadata": {},
   "source": [
    "## Float type\n",
    "\n",
    "Torch typically stores tensors of parameters as `float32`. Suppose, for some reason, you want to handle everything in floats with different precision. You can achieve this by changing the `dtype` of each parameter tensor in your network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4d6df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider simpe instance of the `torch.nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ea5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=10, out_features=4),\n",
    "    nn.Linear(in_features=4, out_features=7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436561e8",
   "metadata": {},
   "source": [
    "If you try to pass a tensor with the `torch.float16` dtype, you will essentially get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f904f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat1 and mat2 must have the same dtype, but got Half and Float\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(20, 10, dtype=torch.float16)\n",
    "try:\n",
    "    model(X)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cbe979",
   "metadata": {},
   "source": [
    "But after iterating over all parameters of the network and changing their types to `float16`, everything works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4851d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4626,  0.5537,  0.5444, -0.9111, -0.7881,  0.7598, -0.2137],\n",
       "        [ 0.2803,  0.2041,  0.1069, -0.4792,  0.4983, -0.0650, -0.7432],\n",
       "        [ 0.2164,  0.2216,  0.0839, -0.4746,  0.7012,  0.0741, -0.7227],\n",
       "        [ 0.3647,  0.4707,  0.0446, -0.0297,  0.2322,  0.1843, -0.3499],\n",
       "        [ 0.3674,  0.3972,  0.0907, -0.2739,  0.1069,  0.1489, -0.5220],\n",
       "        [ 0.2817,  0.4045,  0.0179, -0.0303,  0.6118,  0.1503, -0.3899],\n",
       "        [ 0.3469,  0.6929, -0.1037,  0.4578,  0.3857,  0.4629, -0.0354],\n",
       "        [ 0.3003,  0.6733, -0.0101,  0.0889,  0.2793,  0.7119, -0.1522],\n",
       "        [ 0.3501,  0.1066,  0.2686, -0.5713,  0.3899, -0.3650, -0.6670],\n",
       "        [ 0.3330,  0.4702, -0.1165,  0.2805,  0.5518,  0.0474, -0.3538],\n",
       "        [ 0.3865,  0.2443,  0.2698, -0.4753,  0.1649, -0.1420, -0.5107],\n",
       "        [ 0.3003,  0.2277,  0.1753, -0.5820,  0.3350,  0.0219, -0.7061],\n",
       "        [ 0.3093,  0.3950, -0.0828,  0.0101,  0.4932,  0.0659, -0.5503],\n",
       "        [ 0.3025,  0.0906,  0.4180, -1.2441,  0.0133,  0.0803, -0.9263],\n",
       "        [ 0.3074,  0.6479,  0.3215, -0.8247, -0.4050,  1.1904, -0.3408],\n",
       "        [ 0.2764,  0.1730,  0.1339, -0.4465,  0.6064, -0.1582, -0.6943],\n",
       "        [ 0.1396,  0.2974, -0.1041, -0.3875,  0.8413,  0.3357, -0.8579],\n",
       "        [ 0.2384,  0.1720,  0.3137, -0.9600,  0.3567,  0.2079, -0.7729],\n",
       "        [ 0.3989,  0.4893,  0.2861, -0.2346,  0.0409,  0.2910, -0.1187],\n",
       "        [ 0.2690,  0.4705,  0.0439, -0.2369,  0.3794,  0.4604, -0.4500]],\n",
       "       dtype=torch.float16, grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    p.data = p.data.to(torch.float16)\n",
    "\n",
    "model(X)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
